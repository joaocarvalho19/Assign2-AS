[2022-05-15 18:01:57,839] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:01:57,839] WARN config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:01:57,853] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:01:57,853] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:01:57,853] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:01:57,853] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:01:57,856] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 18:01:57,856] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 18:01:57,856] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 18:01:57,856] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2022-05-15 18:01:57,860] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2022-05-15 18:01:57,872] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:01:57,872] WARN config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:01:57,873] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:01:57,873] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:01:57,873] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:01:57,873] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:01:57,873] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2022-05-15 18:01:57,885] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@2cd2a21f (org.apache.zookeeper.server.ServerMetrics)
[2022-05-15 18:01:57,888] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-15 18:01:57,896] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:01:57,896] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:01:57,896] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:01:57,896] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:01:57,903] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:01:57,903] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:01:57,903] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:01:57,903] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:01:57,903] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:01:57,903] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:02:02,447] INFO Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:02:02,447] INFO Server environment:host.name=LAPTOP-S01N1QNU (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:02:02,464] INFO Server environment:java.version=11.0.10 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:02:02,466] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:02:02,473] INFO Server environment:java.home=C:\Program Files\Java\jdk-11.0.10 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:02:02,496] INFO Server environment:java.class.path=C:\Users\joaoc\Documents\kafka\kfk\libs\activation-1.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\aopalliance-repackaged-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\argparse4j-0.7.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\audience-annotations-0.5.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-cli-1.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-lang3-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-basic-auth-extension-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-file-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-json-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-client-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-runtime-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-transforms-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-api-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-locator-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-utils-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-core-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-databind-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-dataformat-csv-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-datatype-jdk8-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-base-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-json-provider-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-jaxb-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-scala_2.12-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.activation-api-1.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.annotation-api-1.3.5.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.inject-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.validation-api-2.0.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javassist-3.27.0-GA.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.servlet-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jaxb-api-2.3.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-client-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-common-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-core-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-hk2-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-server-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-client-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-continuation-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-http-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-io-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-security-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-server-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlet-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlets-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-ajax-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jline-3.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jopt-simple-5.0.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jose4j-0.7.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-clients-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-log4j-appender-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-metadata-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-raft-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-server-common-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-shell-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-examples-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-scala_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-test-utils-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-tools-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\log4j-1.2.17.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\lz4-java-1.8.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\maven-artifact-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-2.2.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-4.1.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-buffer-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-codec-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-handler-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-resolver-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-epoll-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-unix-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\osgi-resource-locator-1.0.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\paranamer-2.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\plexus-utils-3.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\reflections-0.9.12.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\rocksdbjni-6.22.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-collection-compat_2.12-2.4.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-java8-compat_2.12-1.0.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-library-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-logging_2.12-3.9.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-reflect-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-api-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-log4j12-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\snappy-java-1.1.8.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\trogdor-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-jute-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:02:02,516] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-11.0.10\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.10\bin;C:\Program Files\apache-maven-3.6.3\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\sox-14-4-2;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\dotnet\;C:\Users\joaoc\Downloads\apache-zookeeper-3.8.0-bin\bin;C:\Program Files\swipl\bin;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\Scripts\;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\;C:\Users\joaoc\AppData\Local\Microsoft\WindowsApps;C:\Users\joaoc\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\joaoc\AppData\Local\Programs\Julia-1.6.0\bin;C:\Users\joaoc\.dotnet\tools;. (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:02:02,545] INFO Server environment:java.io.tmpdir=C:\Users\joaoc\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:02:02,549] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:02:02,552] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:02:02,556] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:02:02,560] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:02:02,582] INFO Server environment:user.name=joaoc (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:02:02,588] INFO Server environment:user.home=C:\Users\joaoc (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:02:02,592] INFO Server environment:user.dir=C:\Users\joaoc\Documents\kafka\kfk (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:02:02,603] INFO Server environment:os.memory.free=488MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:02:02,608] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:02:02,622] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:02:02,633] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:02:02,646] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:02:02,654] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:02:02,658] INFO zookeeper.flushDelay=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:02:02,671] INFO zookeeper.maxWriteQueuePollTime=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:02:02,687] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:02:02,691] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:02:02,705] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2022-05-15 18:02:02,722] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:02:02,724] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:02:02,740] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-15 18:02:02,741] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-15 18:02:02,761] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 18:02:02,767] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 18:02:02,771] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 18:02:02,781] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 18:02:02,803] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 18:02:02,807] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 18:02:02,833] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:02:02,837] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:02:02,841] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 clientPortListenBacklog -1 datadir C:\Users\joaoc\Documents\kafka\kfk\zookeeper\version-2 snapdir C:\Users\joaoc\Documents\kafka\kfk\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:02:03,020] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-15 18:02:03,033] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-15 18:02:03,051] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-15 18:02:03,133] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-15 18:02:03,348] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2022-05-15 18:02:03,354] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2022-05-15 18:02:03,385] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-15 18:02:03,387] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-15 18:02:03,463] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2022-05-15 18:02:03,466] INFO Snapshotting: 0x0 to C:\Users\joaoc\Documents\kafka\kfk\zookeeper\version-2\snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-15 18:02:03,522] INFO Snapshot loaded in 125 ms, highest zxid is 0x0, digest is 1371985504 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-15 18:02:03,524] INFO Snapshotting: 0x0 to C:\Users\joaoc\Documents\kafka\kfk\zookeeper\version-2\snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-15 18:02:03,578] INFO Snapshot taken in 51 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:02:03,729] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2022-05-15 18:02:03,734] INFO zookeeper.request_throttler.shutdownTimeout = 10000 (org.apache.zookeeper.server.RequestThrottler)
[2022-05-15 18:02:03,919] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2022-05-15 18:02:03,932] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2022-05-15 18:02:11,294] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 18:02:11,299] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 18:02:11,303] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 18:02:11,308] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 18:02:11,309] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 18:02:11,321] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 18:02:11,999] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 18:02:12,000] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 18:02:12,001] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 18:02:12,001] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 18:02:12,001] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 18:02:12,002] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 18:02:12,175] INFO starting (kafka.server.KafkaServer)
[2022-05-15 18:02:12,175] INFO starting (kafka.server.KafkaServer)
[2022-05-15 18:02:12,176] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 18:02:12,176] INFO starting (kafka.server.KafkaServer)
[2022-05-15 18:02:12,176] INFO starting (kafka.server.KafkaServer)
[2022-05-15 18:02:12,176] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 18:02:12,176] INFO starting (kafka.server.KafkaServer)
[2022-05-15 18:02:12,177] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 18:02:12,178] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 18:02:12,178] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 18:02:12,180] INFO starting (kafka.server.KafkaServer)
[2022-05-15 18:02:12,182] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 18:02:12,207] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:02:12,208] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:02:12,208] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:02:12,208] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:02:12,210] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:02:12,210] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:02:16,731] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,731] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,731] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,731] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,731] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,731] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,732] INFO Client environment:host.name=LAPTOP-S01N1QNU (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,732] INFO Client environment:host.name=LAPTOP-S01N1QNU (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,733] INFO Client environment:java.version=11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,733] INFO Client environment:java.version=11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,733] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,732] INFO Client environment:host.name=LAPTOP-S01N1QNU (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,732] INFO Client environment:host.name=LAPTOP-S01N1QNU (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,733] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,733] INFO Client environment:java.version=11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,732] INFO Client environment:host.name=LAPTOP-S01N1QNU (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,732] INFO Client environment:host.name=LAPTOP-S01N1QNU (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,733] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,733] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,733] INFO Client environment:java.version=11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,734] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,734] INFO Client environment:java.version=11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,734] INFO Client environment:java.version=11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,734] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,734] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,734] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,734] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,734] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,734] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,734] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,734] INFO Client environment:java.class.path=C:\Users\joaoc\Documents\kafka\kfk\libs\activation-1.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\aopalliance-repackaged-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\argparse4j-0.7.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\audience-annotations-0.5.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-cli-1.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-lang3-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-basic-auth-extension-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-file-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-json-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-client-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-runtime-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-transforms-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-api-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-locator-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-utils-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-core-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-databind-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-dataformat-csv-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-datatype-jdk8-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-base-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-json-provider-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-jaxb-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-scala_2.12-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.activation-api-1.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.annotation-api-1.3.5.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.inject-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.validation-api-2.0.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javassist-3.27.0-GA.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.servlet-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jaxb-api-2.3.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-client-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-common-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-core-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-hk2-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-server-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-client-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-continuation-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-http-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-io-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-security-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-server-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlet-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlets-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-ajax-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jline-3.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jopt-simple-5.0.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jose4j-0.7.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-clients-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-log4j-appender-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-metadata-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-raft-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-server-common-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-shell-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-examples-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-scala_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-test-utils-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-tools-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\log4j-1.2.17.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\lz4-java-1.8.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\maven-artifact-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-2.2.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-4.1.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-buffer-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-codec-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-handler-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-resolver-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-epoll-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-unix-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\osgi-resource-locator-1.0.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\paranamer-2.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\plexus-utils-3.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\reflections-0.9.12.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\rocksdbjni-6.22.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-collection-compat_2.12-2.4.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-java8-compat_2.12-1.0.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-library-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-logging_2.12-3.9.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-reflect-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-api-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-log4j12-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\snappy-java-1.1.8.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\trogdor-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-jute-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,734] INFO Client environment:java.class.path=C:\Users\joaoc\Documents\kafka\kfk\libs\activation-1.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\aopalliance-repackaged-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\argparse4j-0.7.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\audience-annotations-0.5.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-cli-1.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-lang3-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-basic-auth-extension-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-file-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-json-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-client-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-runtime-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-transforms-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-api-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-locator-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-utils-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-core-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-databind-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-dataformat-csv-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-datatype-jdk8-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-base-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-json-provider-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-jaxb-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-scala_2.12-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.activation-api-1.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.annotation-api-1.3.5.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.inject-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.validation-api-2.0.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javassist-3.27.0-GA.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.servlet-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jaxb-api-2.3.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-client-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-common-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-core-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-hk2-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-server-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-client-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-continuation-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-http-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-io-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-security-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-server-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlet-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlets-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-ajax-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jline-3.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jopt-simple-5.0.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jose4j-0.7.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-clients-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-log4j-appender-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-metadata-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-raft-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-server-common-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-shell-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-examples-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-scala_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-test-utils-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-tools-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\log4j-1.2.17.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\lz4-java-1.8.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\maven-artifact-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-2.2.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-4.1.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-buffer-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-codec-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-handler-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-resolver-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-epoll-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-unix-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\osgi-resource-locator-1.0.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\paranamer-2.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\plexus-utils-3.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\reflections-0.9.12.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\rocksdbjni-6.22.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-collection-compat_2.12-2.4.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-java8-compat_2.12-1.0.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-library-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-logging_2.12-3.9.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-reflect-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-api-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-log4j12-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\snappy-java-1.1.8.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\trogdor-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-jute-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,734] INFO Client environment:java.class.path=C:\Users\joaoc\Documents\kafka\kfk\libs\activation-1.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\aopalliance-repackaged-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\argparse4j-0.7.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\audience-annotations-0.5.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-cli-1.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-lang3-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-basic-auth-extension-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-file-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-json-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-client-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-runtime-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-transforms-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-api-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-locator-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-utils-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-core-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-databind-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-dataformat-csv-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-datatype-jdk8-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-base-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-json-provider-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-jaxb-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-scala_2.12-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.activation-api-1.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.annotation-api-1.3.5.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.inject-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.validation-api-2.0.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javassist-3.27.0-GA.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.servlet-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jaxb-api-2.3.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-client-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-common-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-core-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-hk2-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-server-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-client-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-continuation-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-http-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-io-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-security-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-server-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlet-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlets-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-ajax-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jline-3.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jopt-simple-5.0.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jose4j-0.7.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-clients-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-log4j-appender-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-metadata-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-raft-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-server-common-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-shell-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-examples-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-scala_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-test-utils-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-tools-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\log4j-1.2.17.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\lz4-java-1.8.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\maven-artifact-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-2.2.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-4.1.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-buffer-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-codec-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-handler-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-resolver-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-epoll-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-unix-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\osgi-resource-locator-1.0.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\paranamer-2.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\plexus-utils-3.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\reflections-0.9.12.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\rocksdbjni-6.22.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-collection-compat_2.12-2.4.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-java8-compat_2.12-1.0.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-library-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-logging_2.12-3.9.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-reflect-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-api-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-log4j12-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\snappy-java-1.1.8.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\trogdor-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-jute-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,734] INFO Client environment:java.class.path=C:\Users\joaoc\Documents\kafka\kfk\libs\activation-1.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\aopalliance-repackaged-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\argparse4j-0.7.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\audience-annotations-0.5.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-cli-1.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-lang3-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-basic-auth-extension-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-file-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-json-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-client-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-runtime-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-transforms-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-api-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-locator-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-utils-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-core-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-databind-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-dataformat-csv-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-datatype-jdk8-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-base-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-json-provider-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-jaxb-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-scala_2.12-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.activation-api-1.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.annotation-api-1.3.5.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.inject-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.validation-api-2.0.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javassist-3.27.0-GA.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.servlet-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jaxb-api-2.3.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-client-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-common-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-core-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-hk2-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-server-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-client-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-continuation-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-http-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-io-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-security-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-server-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlet-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlets-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-ajax-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jline-3.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jopt-simple-5.0.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jose4j-0.7.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-clients-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-log4j-appender-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-metadata-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-raft-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-server-common-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-shell-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-examples-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-scala_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-test-utils-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-tools-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\log4j-1.2.17.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\lz4-java-1.8.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\maven-artifact-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-2.2.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-4.1.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-buffer-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-codec-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-handler-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-resolver-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-epoll-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-unix-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\osgi-resource-locator-1.0.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\paranamer-2.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\plexus-utils-3.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\reflections-0.9.12.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\rocksdbjni-6.22.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-collection-compat_2.12-2.4.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-java8-compat_2.12-1.0.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-library-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-logging_2.12-3.9.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-reflect-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-api-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-log4j12-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\snappy-java-1.1.8.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\trogdor-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-jute-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,734] INFO Client environment:java.class.path=C:\Users\joaoc\Documents\kafka\kfk\libs\activation-1.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\aopalliance-repackaged-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\argparse4j-0.7.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\audience-annotations-0.5.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-cli-1.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-lang3-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-basic-auth-extension-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-file-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-json-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-client-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-runtime-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-transforms-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-api-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-locator-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-utils-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-core-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-databind-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-dataformat-csv-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-datatype-jdk8-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-base-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-json-provider-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-jaxb-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-scala_2.12-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.activation-api-1.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.annotation-api-1.3.5.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.inject-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.validation-api-2.0.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javassist-3.27.0-GA.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.servlet-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jaxb-api-2.3.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-client-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-common-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-core-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-hk2-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-server-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-client-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-continuation-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-http-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-io-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-security-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-server-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlet-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlets-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-ajax-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jline-3.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jopt-simple-5.0.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jose4j-0.7.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-clients-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-log4j-appender-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-metadata-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-raft-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-server-common-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-shell-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-examples-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-scala_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-test-utils-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-tools-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\log4j-1.2.17.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\lz4-java-1.8.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\maven-artifact-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-2.2.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-4.1.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-buffer-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-codec-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-handler-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-resolver-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-epoll-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-unix-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\osgi-resource-locator-1.0.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\paranamer-2.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\plexus-utils-3.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\reflections-0.9.12.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\rocksdbjni-6.22.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-collection-compat_2.12-2.4.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-java8-compat_2.12-1.0.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-library-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-logging_2.12-3.9.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-reflect-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-api-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-log4j12-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\snappy-java-1.1.8.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\trogdor-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-jute-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,734] INFO Client environment:java.class.path=C:\Users\joaoc\Documents\kafka\kfk\libs\activation-1.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\aopalliance-repackaged-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\argparse4j-0.7.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\audience-annotations-0.5.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-cli-1.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-lang3-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-basic-auth-extension-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-file-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-json-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-client-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-runtime-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-transforms-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-api-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-locator-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-utils-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-core-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-databind-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-dataformat-csv-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-datatype-jdk8-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-base-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-json-provider-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-jaxb-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-scala_2.12-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.activation-api-1.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.annotation-api-1.3.5.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.inject-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.validation-api-2.0.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javassist-3.27.0-GA.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.servlet-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jaxb-api-2.3.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-client-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-common-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-core-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-hk2-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-server-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-client-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-continuation-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-http-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-io-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-security-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-server-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlet-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlets-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-ajax-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jline-3.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jopt-simple-5.0.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jose4j-0.7.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-clients-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-log4j-appender-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-metadata-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-raft-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-server-common-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-shell-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-examples-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-scala_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-test-utils-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-tools-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\log4j-1.2.17.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\lz4-java-1.8.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\maven-artifact-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-2.2.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-4.1.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-buffer-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-codec-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-handler-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-resolver-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-epoll-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-unix-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\osgi-resource-locator-1.0.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\paranamer-2.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\plexus-utils-3.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\reflections-0.9.12.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\rocksdbjni-6.22.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-collection-compat_2.12-2.4.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-java8-compat_2.12-1.0.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-library-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-logging_2.12-3.9.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-reflect-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-api-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-log4j12-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\snappy-java-1.1.8.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\trogdor-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-jute-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,735] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.10\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.10\bin;C:\Program Files\apache-maven-3.6.3\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\sox-14-4-2;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\dotnet\;C:\Users\joaoc\Downloads\apache-zookeeper-3.8.0-bin\bin;C:\Program Files\swipl\bin;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\Scripts\;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\;C:\Users\joaoc\AppData\Local\Microsoft\WindowsApps;C:\Users\joaoc\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\joaoc\AppData\Local\Programs\Julia-1.6.0\bin;C:\Users\joaoc\.dotnet\tools;. (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,736] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.10\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.10\bin;C:\Program Files\apache-maven-3.6.3\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\sox-14-4-2;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\dotnet\;C:\Users\joaoc\Downloads\apache-zookeeper-3.8.0-bin\bin;C:\Program Files\swipl\bin;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\Scripts\;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\;C:\Users\joaoc\AppData\Local\Microsoft\WindowsApps;C:\Users\joaoc\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\joaoc\AppData\Local\Programs\Julia-1.6.0\bin;C:\Users\joaoc\.dotnet\tools;. (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,739] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.10\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.10\bin;C:\Program Files\apache-maven-3.6.3\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\sox-14-4-2;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\dotnet\;C:\Users\joaoc\Downloads\apache-zookeeper-3.8.0-bin\bin;C:\Program Files\swipl\bin;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\Scripts\;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\;C:\Users\joaoc\AppData\Local\Microsoft\WindowsApps;C:\Users\joaoc\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\joaoc\AppData\Local\Programs\Julia-1.6.0\bin;C:\Users\joaoc\.dotnet\tools;. (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,737] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.10\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.10\bin;C:\Program Files\apache-maven-3.6.3\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\sox-14-4-2;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\dotnet\;C:\Users\joaoc\Downloads\apache-zookeeper-3.8.0-bin\bin;C:\Program Files\swipl\bin;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\Scripts\;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\;C:\Users\joaoc\AppData\Local\Microsoft\WindowsApps;C:\Users\joaoc\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\joaoc\AppData\Local\Programs\Julia-1.6.0\bin;C:\Users\joaoc\.dotnet\tools;. (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,740] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.10\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.10\bin;C:\Program Files\apache-maven-3.6.3\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\sox-14-4-2;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\dotnet\;C:\Users\joaoc\Downloads\apache-zookeeper-3.8.0-bin\bin;C:\Program Files\swipl\bin;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\Scripts\;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\;C:\Users\joaoc\AppData\Local\Microsoft\WindowsApps;C:\Users\joaoc\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\joaoc\AppData\Local\Programs\Julia-1.6.0\bin;C:\Users\joaoc\.dotnet\tools;. (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,740] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.10\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.10\bin;C:\Program Files\apache-maven-3.6.3\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\sox-14-4-2;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\dotnet\;C:\Users\joaoc\Downloads\apache-zookeeper-3.8.0-bin\bin;C:\Program Files\swipl\bin;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\Scripts\;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\;C:\Users\joaoc\AppData\Local\Microsoft\WindowsApps;C:\Users\joaoc\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\joaoc\AppData\Local\Programs\Julia-1.6.0\bin;C:\Users\joaoc\.dotnet\tools;. (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,757] INFO Client environment:java.io.tmpdir=C:\Users\joaoc\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,769] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,769] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,757] INFO Client environment:java.io.tmpdir=C:\Users\joaoc\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,770] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,771] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,758] INFO Client environment:java.io.tmpdir=C:\Users\joaoc\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,758] INFO Client environment:java.io.tmpdir=C:\Users\joaoc\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,759] INFO Client environment:java.io.tmpdir=C:\Users\joaoc\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,759] INFO Client environment:java.io.tmpdir=C:\Users\joaoc\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,774] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,774] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,775] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,775] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,775] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,775] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,776] INFO Client environment:user.name=joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,776] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,776] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,776] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,777] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,778] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,780] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,779] INFO Client environment:user.home=C:\Users\joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,780] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,781] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,782] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,782] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,783] INFO Client environment:user.name=joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,784] INFO Client environment:user.dir=C:\Users\joaoc\Documents\kafka\kfk (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,784] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,785] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,785] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,788] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,788] INFO Client environment:user.home=C:\Users\joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,788] INFO Client environment:os.memory.free=1010MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,788] INFO Client environment:user.name=joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,789] INFO Client environment:user.name=joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,789] INFO Client environment:user.name=joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,791] INFO Client environment:user.name=joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,791] INFO Client environment:user.dir=C:\Users\joaoc\Documents\kafka\kfk (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,792] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,792] INFO Client environment:user.home=C:\Users\joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,793] INFO Client environment:user.home=C:\Users\joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,793] INFO Client environment:user.home=C:\Users\joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,796] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,795] INFO Client environment:user.home=C:\Users\joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,795] INFO Client environment:os.memory.free=1010MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,797] INFO Client environment:user.dir=C:\Users\joaoc\Documents\kafka\kfk (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,799] INFO Client environment:user.dir=C:\Users\joaoc\Documents\kafka\kfk (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,799] INFO Client environment:user.dir=C:\Users\joaoc\Documents\kafka\kfk (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,803] INFO Client environment:user.dir=C:\Users\joaoc\Documents\kafka\kfk (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,807] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2c5529ab (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,804] INFO Client environment:os.memory.free=1010MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,803] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,804] INFO Client environment:os.memory.free=1010MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,804] INFO Client environment:os.memory.free=1009MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,807] INFO Client environment:os.memory.free=1009MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,808] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,808] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,808] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,809] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,809] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,819] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 18:02:16,813] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,819] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2c5529ab (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,817] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,816] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,819] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,826] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2c5529ab (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,827] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:02:16,829] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2c5529ab (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,829] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2c5529ab (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,830] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2c5529ab (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:02:16,830] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:02:16,845] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 18:02:16,842] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 18:02:16,848] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:02:16,851] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 18:02:16,852] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 18:02:16,852] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 18:02:16,849] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:02:16,854] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:02:16,856] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:02:16,857] INFO Socket connection established, initiating session, client: /127.0.0.1:59668, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:02:16,857] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:02:16,860] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:02:16,861] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:02:16,862] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:02:16,864] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:02:16,864] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:02:16,865] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:02:16,871] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2022-05-15 18:02:16,859] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:02:16,875] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:02:16,878] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:02:16,882] INFO Socket connection established, initiating session, client: /127.0.0.1:59669, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:02:16,884] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:02:16,884] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:02:16,884] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:02:16,884] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:02:16,886] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:02:16,886] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:02:16,889] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100011639500000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:02:16,886] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:02:16,886] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:02:16,890] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:59670, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:02:16,893] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100011639500001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:02:16,897] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:02:16,892] INFO Socket connection established, initiating session, client: /127.0.0.1:59671, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:02:16,895] INFO Socket connection established, initiating session, client: /127.0.0.1:59672, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:02:16,895] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:59673, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:02:16,899] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:02:16,903] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, session id = 0x100011639500002, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:02:16,909] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100011639500003, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:02:16,910] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:02:16,912] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100011639500004, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:02:16,913] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, session id = 0x100011639500005, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:02:16,915] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:02:16,918] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:02:16,919] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:02:17,054] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:02:17,054] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:02:17,054] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:02:17,054] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:02:17,055] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:02:17,055] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:02:17,074] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
[2022-05-15 18:02:17,074] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
[2022-05-15 18:02:17,074] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
[2022-05-15 18:02:17,074] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
[2022-05-15 18:02:17,074] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
[2022-05-15 18:02:17,074] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
[2022-05-15 18:02:17,075] INFO Cleared cache (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:02:17,075] INFO Cleared cache (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:02:17,075] INFO Cleared cache (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:02:17,075] INFO Cleared cache (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:02:17,075] INFO Cleared cache (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:02:17,075] INFO Cleared cache (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:02:17,299] INFO Cluster ID = -Ph5flmaRAKDviW5REKQWQ (kafka.server.KafkaServer)
[2022-05-15 18:02:17,306] WARN No meta.properties file under dir C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-05-15 18:02:17,339] INFO Cluster ID = -Ph5flmaRAKDviW5REKQWQ (kafka.server.KafkaServer)
[2022-05-15 18:02:17,339] INFO Cluster ID = -Ph5flmaRAKDviW5REKQWQ (kafka.server.KafkaServer)
[2022-05-15 18:02:17,339] INFO Cluster ID = -Ph5flmaRAKDviW5REKQWQ (kafka.server.KafkaServer)
[2022-05-15 18:02:17,342] INFO Cluster ID = -Ph5flmaRAKDviW5REKQWQ (kafka.server.KafkaServer)
[2022-05-15 18:02:17,342] INFO Cluster ID = -Ph5flmaRAKDviW5REKQWQ (kafka.server.KafkaServer)
[2022-05-15 18:02:17,345] WARN No meta.properties file under dir C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-05-15 18:02:17,345] WARN No meta.properties file under dir C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-05-15 18:02:17,345] WARN No meta.properties file under dir C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-05-15 18:02:17,347] WARN No meta.properties file under dir C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-05-15 18:02:17,347] WARN No meta.properties file under dir C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-05-15 18:02:17,435] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:02:17,458] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:02:17,490] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 3
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:02:17,494] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:02:17,495] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:02:17,496] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 4
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:02:17,504] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs6
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:02:17,513] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 3
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:02:17,533] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:02:17,533] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 4
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:02:17,529] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:02:17,535] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs6
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:02:17,554] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:02:17,557] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:02:17,566] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:02:17,570] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:02:17,586] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:02:17,588] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:02:17,589] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:02:17,592] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:02:17,598] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:02:17,599] INFO Log directory C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3 not found, creating it. (kafka.log.LogManager)
[2022-05-15 18:02:17,604] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:02:17,604] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:02:17,605] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:02:17,604] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:02:17,608] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:02:17,608] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:02:17,610] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:02:17,610] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:02:17,613] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:02:17,613] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:02:17,618] INFO Log directory C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4 not found, creating it. (kafka.log.LogManager)
[2022-05-15 18:02:17,619] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:02:17,613] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:02:17,629] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:02:17,630] INFO Log directory C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1 not found, creating it. (kafka.log.LogManager)
[2022-05-15 18:02:17,632] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:02:17,634] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:02:17,636] INFO Loading logs from log dirs ArrayBuffer(C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3) (kafka.log.LogManager)
[2022-05-15 18:02:17,637] INFO Log directory C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2 not found, creating it. (kafka.log.LogManager)
[2022-05-15 18:02:17,640] INFO Log directory C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5 not found, creating it. (kafka.log.LogManager)
[2022-05-15 18:02:17,643] INFO Attempting recovery for all logs in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3 since no clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 18:02:17,652] INFO Loading logs from log dirs ArrayBuffer(C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4) (kafka.log.LogManager)
[2022-05-15 18:02:17,658] INFO Attempting recovery for all logs in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4 since no clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 18:02:17,660] INFO Log directory C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6 not found, creating it. (kafka.log.LogManager)
[2022-05-15 18:02:17,663] INFO Loaded 0 logs in 27ms. (kafka.log.LogManager)
[2022-05-15 18:02:17,664] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 18:02:17,666] INFO Loading logs from log dirs ArrayBuffer(C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1) (kafka.log.LogManager)
[2022-05-15 18:02:17,668] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 18:02:17,671] INFO Loading logs from log dirs ArrayBuffer(C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2) (kafka.log.LogManager)
[2022-05-15 18:02:17,673] INFO Attempting recovery for all logs in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1 since no clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 18:02:17,677] INFO Loading logs from log dirs ArrayBuffer(C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5) (kafka.log.LogManager)
[2022-05-15 18:02:17,679] INFO Attempting recovery for all logs in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2 since no clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 18:02:17,679] INFO Loaded 0 logs in 26ms. (kafka.log.LogManager)
[2022-05-15 18:02:17,680] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 18:02:17,685] INFO Attempting recovery for all logs in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5 since no clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 18:02:17,691] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 18:02:17,695] INFO Loaded 0 logs in 29ms. (kafka.log.LogManager)
[2022-05-15 18:02:17,698] INFO Loading logs from log dirs ArrayBuffer(C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6) (kafka.log.LogManager)
[2022-05-15 18:02:17,699] INFO Loaded 0 logs in 28ms. (kafka.log.LogManager)
[2022-05-15 18:02:17,697] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 18:02:17,700] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 18:02:17,704] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 18:02:17,705] INFO Attempting recovery for all logs in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6 since no clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 18:02:17,709] INFO Loaded 0 logs in 31ms. (kafka.log.LogManager)
[2022-05-15 18:02:17,709] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 18:02:17,711] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 18:02:17,718] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 18:02:17,732] INFO Loaded 0 logs in 33ms. (kafka.log.LogManager)
[2022-05-15 18:02:17,733] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 18:02:17,741] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 18:02:20,005] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:02:20,015] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:02:20,023] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:02:20,044] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:02:20,062] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:02:20,062] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:02:23,138] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 18:02:23,212] INFO Awaiting socket connections on 0.0.0.0:9096. (kafka.network.Acceptor)
[2022-05-15 18:02:23,498] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 18:02:23,630] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 18:02:23,653] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:02:23,679] INFO Awaiting socket connections on 0.0.0.0:9095. (kafka.network.Acceptor)
[2022-05-15 18:02:23,722] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-05-15 18:02:23,817] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 18:02:23,827] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:02:23,834] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 18:02:23,885] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2022-05-15 18:02:23,891] INFO Awaiting socket connections on 0.0.0.0:9097. (kafka.network.Acceptor)
[2022-05-15 18:02:24,030] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:02:24,122] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:02:24,122] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:02:24,177] INFO [ExpirationReaper-4-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:02:24,230] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 18:02:24,234] INFO [ExpirationReaper-4-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:02:24,235] INFO [ExpirationReaper-4-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:02:24,230] INFO [ExpirationReaper-4-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:02:24,263] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:02:24,291] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:02:24,300] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:02:24,304] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2022-05-15 18:02:24,385] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:02:24,394] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:02:24,396] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:02:24,417] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:02:24,419] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:02:24,437] INFO [ExpirationReaper-3-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:02:24,438] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:02:24,545] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:02:24,560] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:02:24,571] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:02:24,588] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:02:24,601] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:02:24,653] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:02:24,664] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:02:24,668] INFO [ExpirationReaper-5-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:02:24,683] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:02:24,686] INFO [ExpirationReaper-5-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:02:24,685] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:02:24,688] INFO [ExpirationReaper-5-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:02:24,706] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:02:24,721] INFO [ExpirationReaper-5-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:02:24,734] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:02:24,739] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:02:24,832] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:02:24,836] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:02:24,930] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:02:24,940] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:02:24,951] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:02:24,958] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:02:25,068] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:02:29,067] INFO Creating /brokers/ids/4 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 18:02:29,099] INFO Stat of the created znode at /brokers/ids/4 is: 123,123,1652634149084,1652634149084,1,0,0,72058789000380416,214,0,123
 (kafka.zk.KafkaZkClient)
[2022-05-15 18:02:29,099] INFO Registered broker 4 at path /brokers/ids/4 with addresses: PLAINTEXT://LAPTOP-S01N1QNU:9096, czxid (broker epoch): 123 (kafka.zk.KafkaZkClient)
[2022-05-15 18:02:29,162] INFO [ExpirationReaper-4-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:02:29,172] INFO [ExpirationReaper-4-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:02:29,172] INFO [ExpirationReaper-4-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:02:29,183] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2022-05-15 18:02:29,195] INFO [GroupCoordinator 4]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:02:29,195] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
[2022-05-15 18:02:29,195] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
[2022-05-15 18:02:29,195] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
[2022-05-15 18:02:29,195] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
[2022-05-15 18:02:29,195] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
[2022-05-15 18:02:29,195] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
[2022-05-15 18:02:29,204] INFO [GroupCoordinator 4]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:02:29,223] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:02:29,229] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 18:02:29,229] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:02:29,229] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:02:29,229] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:02:29,229] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:02:29,241] INFO [TransactionCoordinator id=4] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:02:29,247] INFO [TransactionCoordinator id=4] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:02:29,247] INFO [Transaction Marker Channel Manager 4]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:02:29,252] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:02:29,257] INFO Stat of the created znode at /brokers/ids/3 is: 127,127,1652634149247,1652634149247,1,0,0,72058789000380418,214,0,127
 (kafka.zk.KafkaZkClient)
[2022-05-15 18:02:29,258] INFO Registered broker 3 at path /brokers/ids/3 with addresses: PLAINTEXT://LAPTOP-S01N1QNU:9095, czxid (broker epoch): 127 (kafka.zk.KafkaZkClient)
[2022-05-15 18:02:29,286] INFO [ExpirationReaper-4-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:02:29,305] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:02:29,321] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:02:29,326] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:02:29,326] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:02:29,332] INFO [ExpirationReaper-3-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:02:29,332] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:02:29,332] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:02:29,337] INFO Kafka startTimeMs: 1652634149326 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:02:29,337] INFO [ExpirationReaper-3-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:02:29,337] INFO [KafkaServer id=4] started (kafka.server.KafkaServer)
[2022-05-15 18:02:29,343] INFO [ExpirationReaper-3-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:02:29,368] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 18:02:29,370] INFO [GroupCoordinator 3]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:02:29,380] INFO [GroupCoordinator 3]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:02:29,396] INFO Stat of the created znode at /brokers/ids/0 is: 129,129,1652634149390,1652634149390,1,0,0,72058789000380419,214,0,129
 (kafka.zk.KafkaZkClient)
[2022-05-15 18:02:29,401] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://LAPTOP-S01N1QNU:9092, czxid (broker epoch): 129 (kafka.zk.KafkaZkClient)
[2022-05-15 18:02:29,412] INFO [TransactionCoordinator id=3] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:02:29,418] INFO [TransactionCoordinator id=3] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:02:29,418] INFO [Transaction Marker Channel Manager 3]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:02:29,451] INFO Creating /brokers/ids/5 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 18:02:29,451] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 18:02:29,460] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU:9096 (id: 4 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:02:29,460] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU:9096 (id: 4 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:02:29,471] INFO [ExpirationReaper-3-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:02:29,485] INFO Stat of the created znode at /brokers/ids/2 is: 130,130,1652634149471,1652634149471,1,0,0,72058789000380417,214,0,130
 (kafka.zk.KafkaZkClient)
[2022-05-15 18:02:29,486] INFO Stat of the created znode at /brokers/ids/5 is: 131,131,1652634149471,1652634149471,1,0,0,72058789000380420,214,0,131
 (kafka.zk.KafkaZkClient)
[2022-05-15 18:02:29,488] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://LAPTOP-S01N1QNU:9094, czxid (broker epoch): 130 (kafka.zk.KafkaZkClient)
[2022-05-15 18:02:29,489] INFO Registered broker 5 at path /brokers/ids/5 with addresses: PLAINTEXT://LAPTOP-S01N1QNU:9097, czxid (broker epoch): 131 (kafka.zk.KafkaZkClient)
[2022-05-15 18:02:29,508] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:02:29,524] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:02:29,527] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:02:29,528] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:02:29,528] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:02:29,535] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:02:29,535] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:02:29,540] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:02:29,540] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:02:29,545] INFO Kafka startTimeMs: 1652634149535 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:02:29,550] INFO [KafkaServer id=3] started (kafka.server.KafkaServer)
[2022-05-15 18:02:29,560] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:02:29,571] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:02:29,596] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:02:29,600] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:02:29,600] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:02:29,600] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:02:29,600] INFO [ExpirationReaper-5-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:02:29,618] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:02:29,618] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:02:29,621] INFO [ExpirationReaper-5-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:02:29,623] INFO [ExpirationReaper-5-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:02:29,641] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:02:29,653] INFO [GroupCoordinator 5]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:02:29,654] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:02:29,662] INFO [GroupCoordinator 5]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:02:29,678] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU:9096 (id: 4 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:02:29,684] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 18:02:29,692] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:02:29,695] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:02:29,700] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:02:29,700] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:02:29,705] INFO [TransactionCoordinator id=5] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:02:29,717] INFO [TransactionCoordinator id=5] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:02:29,721] INFO [Transaction Marker Channel Manager 5]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:02:29,722] INFO Stat of the created znode at /brokers/ids/1 is: 132,132,1652634149705,1652634149705,1,0,0,72058789000380421,214,0,132
 (kafka.zk.KafkaZkClient)
[2022-05-15 18:02:29,725] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://LAPTOP-S01N1QNU:9093, czxid (broker epoch): 132 (kafka.zk.KafkaZkClient)
[2022-05-15 18:02:29,726] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU:9096 (id: 4 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:02:29,742] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:02:29,764] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:02:29,772] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:02:29,772] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:02:29,774] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:02:29,781] INFO [ExpirationReaper-5-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:02:29,785] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:02:29,786] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:02:29,787] INFO Kafka startTimeMs: 1652634149774 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:02:29,793] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2022-05-15 18:02:29,812] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:02:29,820] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:02:29,836] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:02:29,836] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:02:29,849] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:02:29,850] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:02:29,852] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:02:29,852] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:02:29,865] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:02:29,861] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:02:29,867] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:02:29,865] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:02:29,870] INFO Kafka startTimeMs: 1652634149852 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:02:29,870] INFO Kafka startTimeMs: 1652634149855 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:02:29,875] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2022-05-15 18:02:29,877] INFO [KafkaServer id=5] started (kafka.server.KafkaServer)
[2022-05-15 18:02:29,938] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:02:29,941] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU:9096 (id: 4 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:02:29,955] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:02:29,955] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:02:29,987] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:02:29,997] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:02:30,004] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU:9096 (id: 4 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:02:30,033] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:02:30,040] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:02:30,041] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:02:30,099] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:02:30,118] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU:9096 (id: 4 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:02:30,118] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU:9096 (id: 4 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:02:30,118] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU:9096 (id: 4 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:02:30,132] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU:9096 (id: 4 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:02:30,132] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:02:30,146] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:02:30,155] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:02:30,156] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:02:30,163] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:02:30,165] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:02:30,166] INFO Kafka startTimeMs: 1652634150156 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:02:30,171] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2022-05-15 18:02:30,224] INFO Creating topic Sensor with configuration {min.insync.replicas=2} and initial partition assignment Map(2 -> ArrayBuffer(4, 2, 3), 5 -> ArrayBuffer(0, 5, 1), 4 -> ArrayBuffer(3, 0, 5), 1 -> ArrayBuffer(1, 4, 2), 3 -> ArrayBuffer(2, 3, 0), 0 -> ArrayBuffer(5, 1, 4)) (kafka.zk.AdminZkClient)
[2022-05-15 18:02:30,275] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU:9096 (id: 4 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:02:30,338] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU:9096 (id: 4 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:02:30,369] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-2) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:02:30,381] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-5) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:02:30,381] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:02:30,386] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-4) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:02:30,397] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:02:30,404] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:02:30,508] INFO [LogLoader partition=Sensor-2, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:02:30,514] INFO [LogLoader partition=Sensor-5, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:02:30,516] INFO [LogLoader partition=Sensor-1, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:02:30,519] INFO [LogLoader partition=Sensor-4, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:02:30,526] INFO [LogLoader partition=Sensor-3, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:02:30,534] INFO [LogLoader partition=Sensor-0, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:02:30,538] INFO Created log for partition Sensor-2 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:02:30,542] INFO [Partition Sensor-2 broker=4] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-15 18:02:30,545] INFO Created log for partition Sensor-5 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:02:30,546] INFO [Partition Sensor-2 broker=4] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:02:30,549] INFO Created log for partition Sensor-1 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:02:30,550] INFO [Partition Sensor-5 broker=0] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-15 18:02:30,552] INFO Created log for partition Sensor-4 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:02:30,554] INFO [Partition Sensor-1 broker=1] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-15 18:02:30,553] INFO [Partition Sensor-5 broker=0] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:02:30,557] INFO [Partition Sensor-4 broker=3] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-15 18:02:30,556] INFO [Partition Sensor-1 broker=1] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:02:30,561] INFO Created log for partition Sensor-3 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:02:30,559] INFO [Partition Sensor-4 broker=3] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:02:30,566] INFO [Partition Sensor-3 broker=2] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-15 18:02:30,568] INFO [Partition Sensor-3 broker=2] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:02:30,571] INFO Created log for partition Sensor-0 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:02:30,574] INFO [Partition Sensor-0 broker=5] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 18:02:30,575] INFO [Partition Sensor-0 broker=5] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:02:30,621] INFO [LogLoader partition=Sensor-4, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:02:30,623] INFO Created log for partition Sensor-4 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:02:30,623] INFO [Partition Sensor-4 broker=0] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-15 18:02:30,624] INFO [LogLoader partition=Sensor-1, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:02:30,624] INFO [Partition Sensor-4 broker=0] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:02:30,627] INFO Created log for partition Sensor-1 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:02:30,629] INFO [Partition Sensor-1 broker=4] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-15 18:02:30,630] INFO [Partition Sensor-1 broker=4] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:02:30,634] INFO [LogLoader partition=Sensor-5, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:02:30,636] INFO [LogLoader partition=Sensor-2, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:02:30,637] INFO Created log for partition Sensor-5 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:02:30,638] INFO [LogLoader partition=Sensor-1, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:02:30,638] INFO [Partition Sensor-5 broker=1] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-15 18:02:30,639] INFO Created log for partition Sensor-2 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:02:30,643] INFO Created log for partition Sensor-1 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:02:30,646] INFO [Partition Sensor-2 broker=3] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-15 18:02:30,646] INFO [Partition Sensor-5 broker=1] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:02:30,649] INFO [Partition Sensor-1 broker=2] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-15 18:02:30,650] INFO [Partition Sensor-2 broker=3] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:02:30,652] INFO [LogLoader partition=Sensor-3, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:02:30,654] INFO [LogLoader partition=Sensor-4, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:02:30,653] INFO [Partition Sensor-1 broker=2] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:02:30,658] INFO Created log for partition Sensor-4 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:02:30,660] INFO [LogLoader partition=Sensor-0, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:02:30,655] INFO Created log for partition Sensor-3 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:02:30,665] INFO [Partition Sensor-4 broker=5] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-15 18:02:30,668] INFO [Partition Sensor-3 broker=0] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-15 18:02:30,669] INFO Created log for partition Sensor-0 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:02:30,668] INFO [Partition Sensor-4 broker=5] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:02:30,670] INFO [Partition Sensor-3 broker=0] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:02:30,677] INFO [LogLoader partition=Sensor-0, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:02:30,672] INFO [Partition Sensor-0 broker=4] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 18:02:30,678] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-4, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:02:30,682] INFO [LogLoader partition=Sensor-3, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:02:30,680] INFO Created log for partition Sensor-0 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:02:30,681] INFO [Partition Sensor-0 broker=4] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:02:30,685] INFO [Partition Sensor-0 broker=1] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 18:02:30,690] INFO [LogLoader partition=Sensor-2, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:02:30,695] INFO [LogLoader partition=Sensor-5, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:02:30,686] INFO Created log for partition Sensor-3 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:02:30,688] INFO [Partition Sensor-0 broker=1] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:02:30,697] INFO Created log for partition Sensor-5 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:02:30,687] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:02:30,696] INFO [Partition Sensor-3 broker=3] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-15 18:02:30,692] INFO Created log for partition Sensor-2 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:02:30,697] INFO [Partition Sensor-5 broker=5] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-15 18:02:30,698] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-0, Sensor-5) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:02:30,701] INFO [Partition Sensor-3 broker=3] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:02:30,702] INFO [Partition Sensor-2 broker=2] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-15 18:02:30,707] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-3, Sensor-2) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:02:30,703] INFO [Partition Sensor-5 broker=5] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:02:30,707] INFO [Partition Sensor-2 broker=2] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:02:30,711] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-4, Sensor-5) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:02:30,711] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-1, Sensor-2) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:02:30,723] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:02:30,730] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 3 for partitions Map(Sensor-4 -> InitialFetchState(Some(Wchq4ZOJRIK4ViqZBdmcfw),BrokerEndPoint(id=3, host=LAPTOP-S01N1QNU:9095),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:02:30,731] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Truncating partition Sensor-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:02:30,734] INFO [UnifiedLog partition=Sensor-4, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:02:30,735] INFO [ReplicaFetcher replicaId=4, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:02:30,736] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 2 for partitions Map(Sensor-3 -> InitialFetchState(Some(Wchq4ZOJRIK4ViqZBdmcfw),BrokerEndPoint(id=2, host=LAPTOP-S01N1QNU:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:02:30,736] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:02:30,739] INFO [ReplicaFetcherManager on broker 4] Added fetcher to broker 1 for partitions Map(Sensor-1 -> InitialFetchState(Some(Wchq4ZOJRIK4ViqZBdmcfw),BrokerEndPoint(id=1, host=LAPTOP-S01N1QNU:9093),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:02:30,738] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition Sensor-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:02:30,742] INFO [UnifiedLog partition=Sensor-3, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:02:30,744] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:02:30,744] INFO [ReplicaFetcher replicaId=4, leaderId=1, fetcherId=0] Truncating partition Sensor-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:02:30,749] INFO [UnifiedLog partition=Sensor-1, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:02:30,751] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 5 for partitions Map(Sensor-0 -> InitialFetchState(Some(Wchq4ZOJRIK4ViqZBdmcfw),BrokerEndPoint(id=5, host=LAPTOP-S01N1QNU:9097),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:02:30,750] INFO [ReplicaFetcherManager on broker 4] Added fetcher to broker 5 for partitions Map(Sensor-0 -> InitialFetchState(Some(Wchq4ZOJRIK4ViqZBdmcfw),BrokerEndPoint(id=5, host=LAPTOP-S01N1QNU:9097),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:02:30,754] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Truncating partition Sensor-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:02:30,752] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:02:30,755] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Truncating partition Sensor-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:02:30,758] INFO [UnifiedLog partition=Sensor-0, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:02:30,761] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 0 for partitions Map(Sensor-5 -> InitialFetchState(Some(Wchq4ZOJRIK4ViqZBdmcfw),BrokerEndPoint(id=0, host=LAPTOP-S01N1QNU:9092),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:02:30,756] INFO [UnifiedLog partition=Sensor-0, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:02:30,763] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:02:30,790] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition Sensor-5 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:02:30,793] INFO [UnifiedLog partition=Sensor-5, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:02:30,784] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 4 for partitions Map(Sensor-2 -> InitialFetchState(Some(Wchq4ZOJRIK4ViqZBdmcfw),BrokerEndPoint(id=4, host=LAPTOP-S01N1QNU:9096),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:02:30,796] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:02:30,799] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:02:30,801] INFO [ReplicaFetcherManager on broker 5] Added fetcher to broker 3 for partitions Map(Sensor-4 -> InitialFetchState(Some(Wchq4ZOJRIK4ViqZBdmcfw),BrokerEndPoint(id=3, host=LAPTOP-S01N1QNU:9095),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:02:30,807] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Truncating partition Sensor-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:02:30,786] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 1 for partitions Map(Sensor-1 -> InitialFetchState(Some(Wchq4ZOJRIK4ViqZBdmcfw),BrokerEndPoint(id=1, host=LAPTOP-S01N1QNU:9093),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:02:30,810] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 2 for partitions Map(Sensor-3 -> InitialFetchState(Some(Wchq4ZOJRIK4ViqZBdmcfw),BrokerEndPoint(id=2, host=LAPTOP-S01N1QNU:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:02:30,814] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:02:30,813] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Truncating partition Sensor-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:02:30,820] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 4 for partitions Map(Sensor-2 -> InitialFetchState(Some(Wchq4ZOJRIK4ViqZBdmcfw),BrokerEndPoint(id=4, host=LAPTOP-S01N1QNU:9096),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:02:30,812] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:02:30,825] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Truncating partition Sensor-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:02:30,831] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition Sensor-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:02:30,837] INFO [UnifiedLog partition=Sensor-1, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:02:30,830] INFO [UnifiedLog partition=Sensor-2, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:02:30,831] INFO [UnifiedLog partition=Sensor-3, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:02:30,838] INFO [UnifiedLog partition=Sensor-4, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:02:30,843] INFO [ReplicaFetcherManager on broker 5] Added fetcher to broker 0 for partitions Map(Sensor-5 -> InitialFetchState(Some(Wchq4ZOJRIK4ViqZBdmcfw),BrokerEndPoint(id=0, host=LAPTOP-S01N1QNU:9092),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:02:30,865] INFO [ReplicaFetcher replicaId=5, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:02:30,870] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:02:30,890] WARN [ReplicaFetcher replicaId=4, leaderId=1, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-1. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:02:30,885] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Truncating partition Sensor-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:02:30,910] INFO [UnifiedLog partition=Sensor-2, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:02:30,900] WARN [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-4. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:02:30,922] WARN [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-3. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:02:30,878] INFO [ReplicaFetcher replicaId=5, leaderId=0, fetcherId=0] Truncating partition Sensor-5 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:02:30,933] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-3. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:02:30,936] WARN [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-0. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:02:30,938] WARN [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-0. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:02:30,926] INFO [UnifiedLog partition=Sensor-5, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:02:30,962] WARN [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-4. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:03:39,183] INFO Creating topic __consumer_offsets with configuration {compression.type=producer, cleanup.policy=compact, segment.bytes=104857600} and initial partition assignment Map(23 -> ArrayBuffer(1), 32 -> ArrayBuffer(3), 41 -> ArrayBuffer(1), 17 -> ArrayBuffer(1), 8 -> ArrayBuffer(3), 35 -> ArrayBuffer(1), 44 -> ArrayBuffer(3), 26 -> ArrayBuffer(3), 11 -> ArrayBuffer(1), 29 -> ArrayBuffer(1), 38 -> ArrayBuffer(3), 47 -> ArrayBuffer(1), 20 -> ArrayBuffer(3), 2 -> ArrayBuffer(3), 5 -> ArrayBuffer(1), 14 -> ArrayBuffer(3), 46 -> ArrayBuffer(5), 49 -> ArrayBuffer(2), 40 -> ArrayBuffer(5), 13 -> ArrayBuffer(2), 4 -> ArrayBuffer(5), 22 -> ArrayBuffer(5), 31 -> ArrayBuffer(2), 16 -> ArrayBuffer(5), 7 -> ArrayBuffer(2), 43 -> ArrayBuffer(2), 25 -> ArrayBuffer(2), 34 -> ArrayBuffer(5), 10 -> ArrayBuffer(5), 37 -> ArrayBuffer(2), 1 -> ArrayBuffer(2), 19 -> ArrayBuffer(2), 28 -> ArrayBuffer(5), 45 -> ArrayBuffer(0), 27 -> ArrayBuffer(0), 36 -> ArrayBuffer(4), 18 -> ArrayBuffer(4), 9 -> ArrayBuffer(0), 21 -> ArrayBuffer(0), 48 -> ArrayBuffer(4), 3 -> ArrayBuffer(0), 12 -> ArrayBuffer(4), 30 -> ArrayBuffer(4), 39 -> ArrayBuffer(0), 15 -> ArrayBuffer(0), 42 -> ArrayBuffer(4), 24 -> ArrayBuffer(4), 6 -> ArrayBuffer(4), 33 -> ArrayBuffer(0), 0 -> ArrayBuffer(4)) (kafka.zk.AdminZkClient)
[2022-05-15 18:03:39,305] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(__consumer_offsets-30, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-18, __consumer_offsets-24, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-12) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:03:39,308] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(__consumer_offsets-7, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:03:39,309] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-46, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:03:39,311] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(__consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-23, __consumer_offsets-47, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-5, __consumer_offsets-29) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:03:39,312] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(__consumer_offsets-8, __consumer_offsets-38, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44, __consumer_offsets-26, __consumer_offsets-32) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:03:39,312] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-21, __consumer_offsets-27, __consumer_offsets-9, __consumer_offsets-33, __consumer_offsets-3, __consumer_offsets-15, __consumer_offsets-39, __consumer_offsets-45) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:03:39,328] INFO [LogLoader partition=__consumer_offsets-0, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:03:39,330] INFO Created log for partition __consumer_offsets-0 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:03:39,331] INFO [LogLoader partition=__consumer_offsets-7, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:03:39,331] INFO [LogLoader partition=__consumer_offsets-10, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:03:39,332] INFO [LogLoader partition=__consumer_offsets-26, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:03:39,332] INFO [LogLoader partition=__consumer_offsets-29, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:03:39,333] INFO [LogLoader partition=__consumer_offsets-45, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:03:39,335] INFO Created log for partition __consumer_offsets-7 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\__consumer_offsets-7 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:03:39,333] INFO [Partition __consumer_offsets-0 broker=4] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,334] INFO Created log for partition __consumer_offsets-26 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\__consumer_offsets-26 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:03:39,334] INFO Created log for partition __consumer_offsets-10 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\__consumer_offsets-10 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:03:39,337] INFO Created log for partition __consumer_offsets-29 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\__consumer_offsets-29 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:03:39,339] INFO Created log for partition __consumer_offsets-45 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-45 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:03:39,341] INFO [Partition __consumer_offsets-7 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2022-05-15 18:03:39,343] INFO [Partition __consumer_offsets-26 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2022-05-15 18:03:39,340] INFO [Partition __consumer_offsets-0 broker=4] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,343] INFO [Partition __consumer_offsets-10 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2022-05-15 18:03:39,349] INFO [Partition __consumer_offsets-29 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2022-05-15 18:03:39,348] INFO [Partition __consumer_offsets-45 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2022-05-15 18:03:39,348] INFO [Partition __consumer_offsets-7 broker=2] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,348] INFO [Partition __consumer_offsets-26 broker=3] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,350] INFO [Partition __consumer_offsets-10 broker=5] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,352] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,353] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,374] INFO [LogLoader partition=__consumer_offsets-48, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:03:39,376] INFO Created log for partition __consumer_offsets-48 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\__consumer_offsets-48 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:03:39,377] INFO [Partition __consumer_offsets-48 broker=4] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2022-05-15 18:03:39,377] INFO [LogLoader partition=__consumer_offsets-1, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:03:39,377] INFO [Partition __consumer_offsets-48 broker=4] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,379] INFO Created log for partition __consumer_offsets-1 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:03:39,379] INFO [LogLoader partition=__consumer_offsets-23, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:03:39,379] INFO [LogLoader partition=__consumer_offsets-20, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:03:39,381] INFO Created log for partition __consumer_offsets-23 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\__consumer_offsets-23 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:03:39,379] INFO [Partition __consumer_offsets-1 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2022-05-15 18:03:39,382] INFO [LogLoader partition=__consumer_offsets-4, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:03:39,381] INFO Created log for partition __consumer_offsets-20 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\__consumer_offsets-20 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:03:39,382] INFO [Partition __consumer_offsets-23 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2022-05-15 18:03:39,389] INFO [LogLoader partition=__consumer_offsets-39, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:03:39,383] INFO [Partition __consumer_offsets-20 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2022-05-15 18:03:39,383] INFO [Partition __consumer_offsets-1 broker=2] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,385] INFO Created log for partition __consumer_offsets-4 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:03:39,389] INFO [Partition __consumer_offsets-23 broker=1] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,391] INFO [Partition __consumer_offsets-20 broker=3] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,392] INFO [Partition __consumer_offsets-4 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2022-05-15 18:03:39,393] INFO Created log for partition __consumer_offsets-39 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-39 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:03:39,397] INFO [Partition __consumer_offsets-4 broker=5] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,397] INFO [Partition __consumer_offsets-39 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2022-05-15 18:03:39,403] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,406] INFO [LogLoader partition=__consumer_offsets-42, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:03:39,408] INFO Created log for partition __consumer_offsets-42 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\__consumer_offsets-42 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:03:39,408] INFO [Partition __consumer_offsets-42 broker=4] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2022-05-15 18:03:39,410] INFO [Partition __consumer_offsets-42 broker=4] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,417] INFO [LogLoader partition=__consumer_offsets-49, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:03:39,418] INFO [LogLoader partition=__consumer_offsets-17, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:03:39,419] INFO Created log for partition __consumer_offsets-49 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\__consumer_offsets-49 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:03:39,422] INFO Created log for partition __consumer_offsets-17 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\__consumer_offsets-17 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:03:39,426] INFO [LogLoader partition=__consumer_offsets-14, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:03:39,424] INFO [Partition __consumer_offsets-17 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2022-05-15 18:03:39,423] INFO [Partition __consumer_offsets-49 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2022-05-15 18:03:39,427] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,427] INFO [Partition __consumer_offsets-49 broker=2] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,430] INFO Created log for partition __consumer_offsets-14 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\__consumer_offsets-14 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:03:39,431] INFO [LogLoader partition=__consumer_offsets-46, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:03:39,430] INFO [Partition __consumer_offsets-14 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2022-05-15 18:03:39,432] INFO [LogLoader partition=__consumer_offsets-33, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:03:39,433] INFO Created log for partition __consumer_offsets-46 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\__consumer_offsets-46 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:03:39,433] INFO [Partition __consumer_offsets-14 broker=3] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,434] INFO [Partition __consumer_offsets-46 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2022-05-15 18:03:39,435] INFO Created log for partition __consumer_offsets-33 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-33 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:03:39,436] INFO [Partition __consumer_offsets-46 broker=5] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,436] INFO [Partition __consumer_offsets-33 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2022-05-15 18:03:39,438] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,440] INFO [LogLoader partition=__consumer_offsets-36, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:03:39,442] INFO Created log for partition __consumer_offsets-36 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\__consumer_offsets-36 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:03:39,443] INFO [Partition __consumer_offsets-36 broker=4] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2022-05-15 18:03:39,444] INFO [Partition __consumer_offsets-36 broker=4] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,456] INFO [LogLoader partition=__consumer_offsets-43, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:03:39,456] INFO [LogLoader partition=__consumer_offsets-11, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:03:39,462] INFO Created log for partition __consumer_offsets-11 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\__consumer_offsets-11 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:03:39,459] INFO Created log for partition __consumer_offsets-43 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\__consumer_offsets-43 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:03:39,464] INFO [Partition __consumer_offsets-11 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2022-05-15 18:03:39,464] INFO [Partition __consumer_offsets-43 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2022-05-15 18:03:39,465] INFO [Partition __consumer_offsets-11 broker=1] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,465] INFO [LogLoader partition=__consumer_offsets-8, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:03:39,465] INFO [LogLoader partition=__consumer_offsets-40, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:03:39,466] INFO [Partition __consumer_offsets-43 broker=2] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,470] INFO Created log for partition __consumer_offsets-8 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\__consumer_offsets-8 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:03:39,470] INFO [LogLoader partition=__consumer_offsets-27, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:03:39,469] INFO Created log for partition __consumer_offsets-40 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\__consumer_offsets-40 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:03:39,470] INFO [Partition __consumer_offsets-8 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2022-05-15 18:03:39,472] INFO [Partition __consumer_offsets-40 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2022-05-15 18:03:39,474] INFO Created log for partition __consumer_offsets-27 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-27 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:03:39,481] INFO [LogLoader partition=__consumer_offsets-30, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:03:39,479] INFO [Partition __consumer_offsets-40 broker=5] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,482] INFO Created log for partition __consumer_offsets-30 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\__consumer_offsets-30 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:03:39,475] INFO [Partition __consumer_offsets-8 broker=3] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,480] INFO [Partition __consumer_offsets-27 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2022-05-15 18:03:39,484] INFO [Partition __consumer_offsets-30 broker=4] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2022-05-15 18:03:39,489] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,492] INFO [LogLoader partition=__consumer_offsets-5, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:03:39,492] INFO [LogLoader partition=__consumer_offsets-37, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:03:39,495] INFO Created log for partition __consumer_offsets-37 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\__consumer_offsets-37 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:03:39,496] INFO [Partition __consumer_offsets-37 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2022-05-15 18:03:39,495] INFO Created log for partition __consumer_offsets-5 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\__consumer_offsets-5 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:03:39,491] INFO [Partition __consumer_offsets-30 broker=4] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,499] INFO [Partition __consumer_offsets-37 broker=2] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,499] INFO [Partition __consumer_offsets-5 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2022-05-15 18:03:39,502] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,510] INFO [LogLoader partition=__consumer_offsets-34, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:03:39,511] INFO [LogLoader partition=__consumer_offsets-2, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:03:39,517] INFO Created log for partition __consumer_offsets-2 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:03:39,518] INFO [Partition __consumer_offsets-2 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2022-05-15 18:03:39,514] INFO Created log for partition __consumer_offsets-34 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\__consumer_offsets-34 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:03:39,520] INFO [LogLoader partition=__consumer_offsets-21, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:03:39,520] INFO [Partition __consumer_offsets-2 broker=3] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,523] INFO Created log for partition __consumer_offsets-21 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-21 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:03:39,520] INFO [Partition __consumer_offsets-34 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2022-05-15 18:03:39,525] INFO [LogLoader partition=__consumer_offsets-31, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:03:39,525] INFO [Partition __consumer_offsets-34 broker=5] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,525] INFO [Partition __consumer_offsets-21 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2022-05-15 18:03:39,527] INFO [LogLoader partition=__consumer_offsets-24, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:03:39,528] INFO Created log for partition __consumer_offsets-31 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\__consumer_offsets-31 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:03:39,527] INFO [LogLoader partition=__consumer_offsets-47, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:03:39,527] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,530] INFO Created log for partition __consumer_offsets-24 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\__consumer_offsets-24 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:03:39,528] INFO [Partition __consumer_offsets-31 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2022-05-15 18:03:39,530] INFO Created log for partition __consumer_offsets-47 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\__consumer_offsets-47 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:03:39,532] INFO [Partition __consumer_offsets-24 broker=4] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2022-05-15 18:03:39,532] INFO [Partition __consumer_offsets-31 broker=2] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,533] INFO [Partition __consumer_offsets-47 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2022-05-15 18:03:39,533] INFO [Partition __consumer_offsets-24 broker=4] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,534] INFO [Partition __consumer_offsets-47 broker=1] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,548] INFO [LogLoader partition=__consumer_offsets-38, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:03:39,550] INFO Created log for partition __consumer_offsets-38 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\__consumer_offsets-38 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:03:39,550] INFO [Partition __consumer_offsets-38 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2022-05-15 18:03:39,551] INFO [Partition __consumer_offsets-38 broker=3] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,551] INFO [LogLoader partition=__consumer_offsets-28, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:03:39,555] INFO [LogLoader partition=__consumer_offsets-15, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:03:39,554] INFO Created log for partition __consumer_offsets-28 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\__consumer_offsets-28 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:03:39,557] INFO [LogLoader partition=__consumer_offsets-18, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:03:39,558] INFO [LogLoader partition=__consumer_offsets-19, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:03:39,555] INFO [Partition __consumer_offsets-28 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2022-05-15 18:03:39,557] INFO Created log for partition __consumer_offsets-15 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-15 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:03:39,560] INFO Created log for partition __consumer_offsets-19 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\__consumer_offsets-19 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:03:39,559] INFO [Partition __consumer_offsets-28 broker=5] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,561] INFO Created log for partition __consumer_offsets-18 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\__consumer_offsets-18 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:03:39,559] INFO [Partition __consumer_offsets-15 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2022-05-15 18:03:39,562] INFO [LogLoader partition=__consumer_offsets-35, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:03:39,561] INFO [Partition __consumer_offsets-19 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2022-05-15 18:03:39,561] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,561] INFO [Partition __consumer_offsets-18 broker=4] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2022-05-15 18:03:39,562] INFO [Partition __consumer_offsets-19 broker=2] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,565] INFO Created log for partition __consumer_offsets-35 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\__consumer_offsets-35 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:03:39,566] INFO [Partition __consumer_offsets-18 broker=4] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,567] INFO [Partition __consumer_offsets-35 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2022-05-15 18:03:39,575] INFO [LogLoader partition=__consumer_offsets-44, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:03:39,575] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,579] INFO Created log for partition __consumer_offsets-44 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\__consumer_offsets-44 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:03:39,579] INFO [Partition __consumer_offsets-44 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2022-05-15 18:03:39,580] INFO [Partition __consumer_offsets-44 broker=3] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,585] INFO [LogLoader partition=__consumer_offsets-16, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:03:39,587] INFO Created log for partition __consumer_offsets-16 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\__consumer_offsets-16 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:03:39,587] INFO [Partition __consumer_offsets-16 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2022-05-15 18:03:39,589] INFO [LogLoader partition=__consumer_offsets-9, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:03:39,588] INFO [Partition __consumer_offsets-16 broker=5] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,591] INFO [LogLoader partition=__consumer_offsets-25, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:03:39,591] INFO [LogLoader partition=__consumer_offsets-12, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:03:39,591] INFO Created log for partition __consumer_offsets-9 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-9 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:03:39,593] INFO [Partition __consumer_offsets-9 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2022-05-15 18:03:39,595] INFO Created log for partition __consumer_offsets-12 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\__consumer_offsets-12 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:03:39,595] INFO Created log for partition __consumer_offsets-25 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\__consumer_offsets-25 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:03:39,595] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,595] INFO [Partition __consumer_offsets-12 broker=4] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2022-05-15 18:03:39,595] INFO [Partition __consumer_offsets-25 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2022-05-15 18:03:39,597] INFO [Partition __consumer_offsets-12 broker=4] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,603] INFO [LogLoader partition=__consumer_offsets-41, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:03:39,605] INFO [LogLoader partition=__consumer_offsets-32, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:03:39,598] INFO [Partition __consumer_offsets-25 broker=2] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,605] INFO Created log for partition __consumer_offsets-41 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\__consumer_offsets-41 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:03:39,608] INFO Created log for partition __consumer_offsets-32 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\__consumer_offsets-32 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:03:39,607] INFO [Partition __consumer_offsets-41 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2022-05-15 18:03:39,608] INFO [Partition __consumer_offsets-32 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2022-05-15 18:03:39,610] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,611] INFO [Partition __consumer_offsets-32 broker=3] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,615] INFO [LogLoader partition=__consumer_offsets-22, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:03:39,618] INFO Created log for partition __consumer_offsets-22 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\__consumer_offsets-22 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:03:39,620] INFO [LogLoader partition=__consumer_offsets-3, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:03:39,620] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 41 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,620] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 44 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,623] INFO [LogLoader partition=__consumer_offsets-6, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:03:39,619] INFO [Partition __consumer_offsets-22 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2022-05-15 18:03:39,622] INFO Created log for partition __consumer_offsets-3 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:03:39,622] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,623] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,625] INFO Created log for partition __consumer_offsets-6 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\__consumer_offsets-6 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:03:39,624] INFO [Partition __consumer_offsets-22 broker=5] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,624] INFO [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2022-05-15 18:03:39,626] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 47 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,629] INFO [LogLoader partition=__consumer_offsets-13, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:03:39,626] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 2 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,626] INFO [Partition __consumer_offsets-6 broker=4] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2022-05-15 18:03:39,628] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,629] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,635] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 22 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,629] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,632] INFO [Partition __consumer_offsets-6 broker=4] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,631] INFO Created log for partition __consumer_offsets-13 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\__consumer_offsets-13 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:03:39,638] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,643] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,637] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 8 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,636] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 5 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,640] INFO [Partition __consumer_offsets-13 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2022-05-15 18:03:39,642] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 28 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,644] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,646] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 6 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,639] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-44 in 12 milliseconds for epoch 0, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,639] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 12 milliseconds for epoch 0, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,645] INFO [Partition __consumer_offsets-13 broker=2] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:03:39,647] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 9 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,649] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,646] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,645] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,645] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,652] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,653] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 12 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,652] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-22 in 11 milliseconds for epoch 0, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,658] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 25 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,650] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-2 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,651] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 15 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,657] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 15 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,657] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,653] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 34 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,655] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 14 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,660] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,656] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 11 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,662] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-6 in 8 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,658] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 10 milliseconds for epoch 0, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,659] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-8 in 4 milliseconds for epoch 0, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,658] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-28 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,666] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 31 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,660] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,661] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,663] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 18 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,665] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,663] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,672] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 6 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,666] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,671] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,671] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-12 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,676] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 20 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,676] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 40 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,675] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,679] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 17 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,675] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 21 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,676] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,676] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,677] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-34 in 1 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,685] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 37 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,679] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,679] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 4 milliseconds for epoch 0, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,686] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 24 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,680] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,681] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,685] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,685] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,686] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,685] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,690] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 46 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,690] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 26 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,691] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-20 in 1 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,689] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,693] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 23 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,688] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,694] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 27 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,691] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-40 in 1 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,698] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,702] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 30 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,706] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 43 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,693] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,695] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 1 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,707] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 32 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,698] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,703] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-24 in 1 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,706] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,711] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,707] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,706] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,717] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 33 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,705] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,715] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 4 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,707] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,717] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 49 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,713] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,718] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,719] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 29 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,720] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 36 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,715] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-46 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,717] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,721] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 38 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,718] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,719] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,720] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,720] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,722] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 39 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,722] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-32 in 1 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,721] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,722] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,724] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,733] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 10 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,729] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,728] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,735] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 1 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,735] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 35 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,735] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 42 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,733] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,733] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,739] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-38 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,735] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,735] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,735] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,736] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,744] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 45 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,739] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,740] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,739] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,748] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 16 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,744] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,749] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 7 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,751] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 48 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,751] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,748] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,749] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,749] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,751] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,759] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,754] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,751] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,761] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,763] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 13 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,756] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,763] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,766] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 0 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,765] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,766] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,767] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 19 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,767] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,771] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,767] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,769] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,776] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:03:39,840] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group ConsumerGroup in Empty state. Created a new member id consumer-ConsumerGroup-1-aebb1db6-f814-4e34-9a81-591903025caa and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,871] INFO [GroupCoordinator 0]: Preparing to rebalance group ConsumerGroup in state PreparingRebalance with old generation 0 (__consumer_offsets-45) (reason: Adding new member consumer-ConsumerGroup-1-aebb1db6-f814-4e34-9a81-591903025caa with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,880] INFO [GroupCoordinator 0]: Stabilized group ConsumerGroup generation 1 (__consumer_offsets-45) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:03:39,893] INFO [GroupCoordinator 0]: Assignment received from leader consumer-ConsumerGroup-1-aebb1db6-f814-4e34-9a81-591903025caa for group ConsumerGroup for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:04:25,088] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group ConsumerGroup in Stable state. Created a new member id consumer-ConsumerGroup-1-06f83353-95af-4f14-9503-18dbf485037d and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:04:25,091] INFO [GroupCoordinator 0]: Preparing to rebalance group ConsumerGroup in state PreparingRebalance with old generation 1 (__consumer_offsets-45) (reason: Adding new member consumer-ConsumerGroup-1-06f83353-95af-4f14-9503-18dbf485037d with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:05:02,270] INFO [GroupCoordinator 0]: Member consumer-ConsumerGroup-1-aebb1db6-f814-4e34-9a81-591903025caa in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:05:02,272] INFO [GroupCoordinator 0]: Stabilized group ConsumerGroup generation 2 (__consumer_offsets-45) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:05:02,279] INFO [GroupCoordinator 0]: Assignment received from leader consumer-ConsumerGroup-1-06f83353-95af-4f14-9503-18dbf485037d for group ConsumerGroup for generation 2. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:05:36,641] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group ConsumerGroup in Stable state. Created a new member id consumer-ConsumerGroup-1-1e77e4f6-ffc6-464a-9f59-6dd75e724b23 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:05:36,644] INFO [GroupCoordinator 0]: Preparing to rebalance group ConsumerGroup in state PreparingRebalance with old generation 2 (__consumer_offsets-45) (reason: Adding new member consumer-ConsumerGroup-1-1e77e4f6-ffc6-464a-9f59-6dd75e724b23 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:08,521] INFO [GroupCoordinator 0]: Member consumer-ConsumerGroup-1-06f83353-95af-4f14-9503-18dbf485037d in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:08,522] INFO [GroupCoordinator 0]: Stabilized group ConsumerGroup generation 3 (__consumer_offsets-45) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:08,529] INFO [GroupCoordinator 0]: Assignment received from leader consumer-ConsumerGroup-1-1e77e4f6-ffc6-464a-9f59-6dd75e724b23 for group ConsumerGroup for generation 3. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:56,532] INFO [GroupCoordinator 0]: Member consumer-ConsumerGroup-1-1e77e4f6-ffc6-464a-9f59-6dd75e724b23 in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:56,533] INFO [GroupCoordinator 0]: Preparing to rebalance group ConsumerGroup in state PreparingRebalance with old generation 3 (__consumer_offsets-45) (reason: removing member consumer-ConsumerGroup-1-1e77e4f6-ffc6-464a-9f59-6dd75e724b23 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:56,534] INFO [GroupCoordinator 0]: Group ConsumerGroup with generation 4 is now empty (__consumer_offsets-45) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:44:56,965] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group ConsumerGroup in Empty state. Created a new member id consumer-ConsumerGroup-1-6b432602-dd79-4740-8e2d-03645ba75fdf and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:44:56,967] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group ConsumerGroup in Empty state. Created a new member id consumer-ConsumerGroup-3-ba2289cf-c6d3-464a-87b3-6a5e01b6cb06 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:44:56,969] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group ConsumerGroup in Empty state. Created a new member id consumer-ConsumerGroup-5-fc6a6611-d3a4-4025-bf6a-6a0cca610d33 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:44:56,970] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group ConsumerGroup in Empty state. Created a new member id consumer-ConsumerGroup-4-65967cb5-1556-4244-9668-55021a0d4211 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:44:56,971] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group ConsumerGroup in Empty state. Created a new member id consumer-ConsumerGroup-2-87a7f5f6-6589-4c5d-a124-b5eacaddb31d and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:44:56,973] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group ConsumerGroup in Empty state. Created a new member id consumer-ConsumerGroup-6-f5c9dfb8-c2fe-476e-8699-d2243514c534 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:44:56,974] INFO [GroupCoordinator 0]: Preparing to rebalance group ConsumerGroup in state PreparingRebalance with old generation 4 (__consumer_offsets-45) (reason: Adding new member consumer-ConsumerGroup-1-6b432602-dd79-4740-8e2d-03645ba75fdf with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:44:56,978] INFO [GroupCoordinator 0]: Stabilized group ConsumerGroup generation 5 (__consumer_offsets-45) with 5 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:44:56,982] INFO [GroupCoordinator 0]: Preparing to rebalance group ConsumerGroup in state PreparingRebalance with old generation 5 (__consumer_offsets-45) (reason: Adding new member consumer-ConsumerGroup-6-f5c9dfb8-c2fe-476e-8699-d2243514c534 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:44:56,995] INFO [GroupCoordinator 0]: Stabilized group ConsumerGroup generation 6 (__consumer_offsets-45) with 6 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:44:57,002] INFO [GroupCoordinator 0]: Assignment received from leader consumer-ConsumerGroup-1-6b432602-dd79-4740-8e2d-03645ba75fdf for group ConsumerGroup for generation 6. The group has 6 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:47:23,892] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group ConsumerGroup in Stable state. Created a new member id consumer-ConsumerGroup-3-22f5c178-d191-48a4-a451-4ee5264e364f and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:47:23,893] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group ConsumerGroup in Stable state. Created a new member id consumer-ConsumerGroup-1-85f58b37-bd4a-4e9e-b502-da39c04433a6 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:47:23,895] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group ConsumerGroup in Stable state. Created a new member id consumer-ConsumerGroup-2-6725d362-6ea9-4092-9d6b-d744b5969424 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:47:23,896] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group ConsumerGroup in Stable state. Created a new member id consumer-ConsumerGroup-6-af111dd6-8b27-435e-b842-224ca1f834b3 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:47:23,904] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group ConsumerGroup in Stable state. Created a new member id consumer-ConsumerGroup-4-090dbb4a-a7d2-4790-9f0d-e3797765b4df and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:47:23,905] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group ConsumerGroup in Stable state. Created a new member id consumer-ConsumerGroup-5-2a99626b-99e7-4135-b6aa-4f337fe5579e and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:47:23,906] INFO [GroupCoordinator 0]: Preparing to rebalance group ConsumerGroup in state PreparingRebalance with old generation 6 (__consumer_offsets-45) (reason: Adding new member consumer-ConsumerGroup-3-22f5c178-d191-48a4-a451-4ee5264e364f with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:48:02,466] INFO [GroupCoordinator 0]: Member consumer-ConsumerGroup-1-6b432602-dd79-4740-8e2d-03645ba75fdf in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:48:02,512] INFO [GroupCoordinator 0]: Member consumer-ConsumerGroup-5-fc6a6611-d3a4-4025-bf6a-6a0cca610d33 in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:48:02,513] INFO [GroupCoordinator 0]: Member consumer-ConsumerGroup-6-f5c9dfb8-c2fe-476e-8699-d2243514c534 in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:48:02,514] INFO [GroupCoordinator 0]: Member consumer-ConsumerGroup-4-65967cb5-1556-4244-9668-55021a0d4211 in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:48:02,544] INFO [GroupCoordinator 0]: Member consumer-ConsumerGroup-2-87a7f5f6-6589-4c5d-a124-b5eacaddb31d in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:48:02,544] INFO [GroupCoordinator 0]: Member consumer-ConsumerGroup-3-ba2289cf-c6d3-464a-87b3-6a5e01b6cb06 in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:48:02,546] INFO [GroupCoordinator 0]: Stabilized group ConsumerGroup generation 7 (__consumer_offsets-45) with 6 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:48:02,554] INFO [GroupCoordinator 0]: Assignment received from leader consumer-ConsumerGroup-5-2a99626b-99e7-4135-b6aa-4f337fe5579e for group ConsumerGroup for generation 7. The group has 6 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:50:35,236] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group 5 in Empty state. Created a new member id consumer-5-6-21d4ac16-e515-4655-8cb7-3651ef2331a5 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:50:35,240] INFO [GroupCoordinator 0]: Preparing to rebalance group 5 in state PreparingRebalance with old generation 0 (__consumer_offsets-3) (reason: Adding new member consumer-5-6-21d4ac16-e515-4655-8cb7-3651ef2331a5 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:50:35,241] INFO [GroupCoordinator 0]: Stabilized group 5 generation 1 (__consumer_offsets-3) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:50:35,252] INFO [GroupCoordinator 0]: Assignment received from leader consumer-5-6-21d4ac16-e515-4655-8cb7-3651ef2331a5 for group 5 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:50:35,253] INFO [GroupCoordinator 3]: Dynamic member with unknown member id joins group 4 in Empty state. Created a new member id consumer-4-5-17791521-c714-4155-86a6-320e8730a7fe and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:50:35,253] INFO [GroupCoordinator 4]: Dynamic member with unknown member id joins group 0 in Empty state. Created a new member id consumer-0-1-05cc08b9-d727-449a-9635-fc4f4d430213 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:50:35,253] INFO [GroupCoordinator 4]: Dynamic member with unknown member id joins group 2 in Empty state. Created a new member id consumer-2-3-59c3feab-2484-43e2-a914-b7eb8318aef1 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:50:35,260] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group 3 in Empty state. Created a new member id consumer-3-4-6c5f0c8b-18f7-41d4-81a5-6930e7edc1db and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:50:35,260] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group 1 in Empty state. Created a new member id consumer-1-2-2e352e0d-3102-4f84-a5af-e32a45beae2c and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:50:35,275] INFO [GroupCoordinator 4]: Preparing to rebalance group 2 in state PreparingRebalance with old generation 0 (__consumer_offsets-0) (reason: Adding new member consumer-2-3-59c3feab-2484-43e2-a914-b7eb8318aef1 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:50:35,275] INFO [GroupCoordinator 3]: Preparing to rebalance group 4 in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member consumer-4-5-17791521-c714-4155-86a6-320e8730a7fe with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:50:35,275] INFO [GroupCoordinator 4]: Preparing to rebalance group 0 in state PreparingRebalance with old generation 0 (__consumer_offsets-48) (reason: Adding new member consumer-0-1-05cc08b9-d727-449a-9635-fc4f4d430213 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:50:35,281] INFO [GroupCoordinator 2]: Preparing to rebalance group 3 in state PreparingRebalance with old generation 0 (__consumer_offsets-1) (reason: Adding new member consumer-3-4-6c5f0c8b-18f7-41d4-81a5-6930e7edc1db with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:50:35,281] INFO [GroupCoordinator 2]: Preparing to rebalance group 1 in state PreparingRebalance with old generation 0 (__consumer_offsets-49) (reason: Adding new member consumer-1-2-2e352e0d-3102-4f84-a5af-e32a45beae2c with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:50:35,295] INFO [GroupCoordinator 3]: Stabilized group 4 generation 1 (__consumer_offsets-2) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:50:35,296] INFO [GroupCoordinator 4]: Stabilized group 2 generation 1 (__consumer_offsets-0) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:50:35,304] INFO [GroupCoordinator 2]: Stabilized group 3 generation 1 (__consumer_offsets-1) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:50:35,306] INFO [GroupCoordinator 4]: Stabilized group 0 generation 1 (__consumer_offsets-48) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:50:35,312] INFO [GroupCoordinator 4]: Assignment received from leader consumer-2-3-59c3feab-2484-43e2-a914-b7eb8318aef1 for group 2 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:50:35,312] INFO [GroupCoordinator 3]: Assignment received from leader consumer-4-5-17791521-c714-4155-86a6-320e8730a7fe for group 4 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:50:35,312] INFO [GroupCoordinator 4]: Assignment received from leader consumer-0-1-05cc08b9-d727-449a-9635-fc4f4d430213 for group 0 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:50:35,315] INFO [GroupCoordinator 2]: Stabilized group 1 generation 1 (__consumer_offsets-49) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:50:35,321] INFO [GroupCoordinator 2]: Assignment received from leader consumer-3-4-6c5f0c8b-18f7-41d4-81a5-6930e7edc1db for group 3 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:50:35,321] INFO [GroupCoordinator 2]: Assignment received from leader consumer-1-2-2e352e0d-3102-4f84-a5af-e32a45beae2c for group 1 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:51:15,440] INFO [GroupCoordinator 0]: Member consumer-ConsumerGroup-4-090dbb4a-a7d2-4790-9f0d-e3797765b4df in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:51:15,443] INFO [GroupCoordinator 0]: Preparing to rebalance group ConsumerGroup in state PreparingRebalance with old generation 7 (__consumer_offsets-45) (reason: removing member consumer-ConsumerGroup-4-090dbb4a-a7d2-4790-9f0d-e3797765b4df on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:51:15,489] INFO [GroupCoordinator 0]: Member consumer-ConsumerGroup-1-85f58b37-bd4a-4e9e-b502-da39c04433a6 in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:51:15,550] INFO [GroupCoordinator 0]: Member consumer-ConsumerGroup-2-6725d362-6ea9-4092-9d6b-d744b5969424 in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:51:15,583] INFO [GroupCoordinator 0]: Member consumer-ConsumerGroup-5-2a99626b-99e7-4135-b6aa-4f337fe5579e in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:51:15,616] INFO [GroupCoordinator 0]: Member consumer-ConsumerGroup-6-af111dd6-8b27-435e-b842-224ca1f834b3 in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:51:15,649] INFO [GroupCoordinator 0]: Member consumer-ConsumerGroup-3-22f5c178-d191-48a4-a451-4ee5264e364f in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:51:15,678] INFO [GroupCoordinator 0]: Group ConsumerGroup with generation 8 is now empty (__consumer_offsets-45) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:51:16,952] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group 5 in Stable state. Created a new member id consumer-5-6-7d6284a3-4df3-4cb7-9b36-a8ed7147266c and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:51:16,952] INFO [GroupCoordinator 4]: Dynamic member with unknown member id joins group 0 in Stable state. Created a new member id consumer-0-1-697a6573-b159-4599-a4c9-fac3d974fdb0 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:51:16,952] INFO [GroupCoordinator 3]: Dynamic member with unknown member id joins group 4 in Stable state. Created a new member id consumer-4-5-50d59ed6-ef24-4452-ba7c-01115944fc2f and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:51:16,952] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group 3 in Stable state. Created a new member id consumer-3-4-b2e4ff46-658b-46df-92b4-853edec96c54 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:51:16,956] INFO [GroupCoordinator 0]: Preparing to rebalance group 5 in state PreparingRebalance with old generation 1 (__consumer_offsets-3) (reason: Adding new member consumer-5-6-7d6284a3-4df3-4cb7-9b36-a8ed7147266c with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:51:16,956] INFO [GroupCoordinator 3]: Preparing to rebalance group 4 in state PreparingRebalance with old generation 1 (__consumer_offsets-2) (reason: Adding new member consumer-4-5-50d59ed6-ef24-4452-ba7c-01115944fc2f with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:51:16,952] INFO [GroupCoordinator 4]: Dynamic member with unknown member id joins group 2 in Stable state. Created a new member id consumer-2-3-6bd82fa3-8b96-423b-806c-5bafc8da571d and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:51:16,952] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group 1 in Stable state. Created a new member id consumer-1-2-fb5ad8d9-7446-400d-ab7c-6bf59dcf11a6 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:51:16,957] INFO [GroupCoordinator 4]: Preparing to rebalance group 0 in state PreparingRebalance with old generation 1 (__consumer_offsets-48) (reason: Adding new member consumer-0-1-697a6573-b159-4599-a4c9-fac3d974fdb0 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:51:16,957] INFO [GroupCoordinator 2]: Preparing to rebalance group 3 in state PreparingRebalance with old generation 1 (__consumer_offsets-1) (reason: Adding new member consumer-3-4-b2e4ff46-658b-46df-92b4-853edec96c54 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:51:16,962] INFO [GroupCoordinator 4]: Preparing to rebalance group 2 in state PreparingRebalance with old generation 1 (__consumer_offsets-0) (reason: Adding new member consumer-2-3-6bd82fa3-8b96-423b-806c-5bafc8da571d with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:51:16,963] INFO [GroupCoordinator 2]: Preparing to rebalance group 1 in state PreparingRebalance with old generation 1 (__consumer_offsets-49) (reason: Adding new member consumer-1-2-fb5ad8d9-7446-400d-ab7c-6bf59dcf11a6 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:51:32,086] INFO [GroupCoordinator 2]: Member consumer-1-2-2e352e0d-3102-4f84-a5af-e32a45beae2c in group 1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:51:32,088] INFO [GroupCoordinator 2]: Stabilized group 1 generation 2 (__consumer_offsets-49) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:51:32,094] INFO [GroupCoordinator 2]: Assignment received from leader consumer-1-2-fb5ad8d9-7446-400d-ab7c-6bf59dcf11a6 for group 1 for generation 2. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:51:32,116] INFO [GroupCoordinator 0]: Member consumer-5-6-21d4ac16-e515-4655-8cb7-3651ef2331a5 in group 5 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:51:32,117] INFO [GroupCoordinator 0]: Stabilized group 5 generation 2 (__consumer_offsets-3) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:51:32,120] INFO [GroupCoordinator 0]: Assignment received from leader consumer-5-6-7d6284a3-4df3-4cb7-9b36-a8ed7147266c for group 5 for generation 2. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:51:32,162] INFO [GroupCoordinator 2]: Member consumer-3-4-6c5f0c8b-18f7-41d4-81a5-6930e7edc1db in group 3 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:51:32,164] INFO [GroupCoordinator 2]: Stabilized group 3 generation 2 (__consumer_offsets-1) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:51:32,166] INFO [GroupCoordinator 4]: Member consumer-2-3-59c3feab-2484-43e2-a914-b7eb8318aef1 in group 2 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:51:32,166] INFO [GroupCoordinator 3]: Member consumer-4-5-17791521-c714-4155-86a6-320e8730a7fe in group 4 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:51:32,169] INFO [GroupCoordinator 2]: Assignment received from leader consumer-3-4-b2e4ff46-658b-46df-92b4-853edec96c54 for group 3 for generation 2. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:51:32,170] INFO [GroupCoordinator 4]: Stabilized group 2 generation 2 (__consumer_offsets-0) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:51:32,170] INFO [GroupCoordinator 3]: Stabilized group 4 generation 2 (__consumer_offsets-2) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:51:32,186] INFO [GroupCoordinator 3]: Assignment received from leader consumer-4-5-50d59ed6-ef24-4452-ba7c-01115944fc2f for group 4 for generation 2. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:51:32,181] INFO [GroupCoordinator 4]: Member consumer-0-1-05cc08b9-d727-449a-9635-fc4f4d430213 in group 0 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:51:32,185] INFO [GroupCoordinator 4]: Assignment received from leader consumer-2-3-6bd82fa3-8b96-423b-806c-5bafc8da571d for group 2 for generation 2. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:51:32,188] INFO [GroupCoordinator 4]: Stabilized group 0 generation 2 (__consumer_offsets-48) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:51:32,196] INFO [GroupCoordinator 4]: Assignment received from leader consumer-0-1-697a6573-b159-4599-a4c9-fac3d974fdb0 for group 0 for generation 2. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:52:19,202] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group ConsumerGroup in Empty state. Created a new member id consumer-ConsumerGroup-5-bf23ffd5-84c6-4d14-a3a9-71e95acf29fa and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:52:19,206] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group ConsumerGroup in Empty state. Created a new member id consumer-ConsumerGroup-6-ec225d45-fe31-414c-8045-ab2912604294 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:52:19,216] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group ConsumerGroup in Empty state. Created a new member id consumer-ConsumerGroup-2-7b030da3-b690-4259-bdea-ba603d623655 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:52:19,220] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group ConsumerGroup in Empty state. Created a new member id consumer-ConsumerGroup-3-f33e789e-5b3b-4cb6-9c90-2f6405b8c64d and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:52:19,225] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group ConsumerGroup in Empty state. Created a new member id consumer-ConsumerGroup-1-0b934ab7-9d76-436a-a81b-d614091abd8a and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:52:19,231] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group ConsumerGroup in Empty state. Created a new member id consumer-ConsumerGroup-4-4cbaef1c-f620-4439-bca7-df97d3d4b213 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:52:19,247] INFO [GroupCoordinator 0]: Preparing to rebalance group ConsumerGroup in state PreparingRebalance with old generation 8 (__consumer_offsets-45) (reason: Adding new member consumer-ConsumerGroup-5-bf23ffd5-84c6-4d14-a3a9-71e95acf29fa with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:52:19,256] INFO [GroupCoordinator 0]: Stabilized group ConsumerGroup generation 9 (__consumer_offsets-45) with 5 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:52:19,265] INFO [GroupCoordinator 0]: Preparing to rebalance group ConsumerGroup in state PreparingRebalance with old generation 9 (__consumer_offsets-45) (reason: Adding new member consumer-ConsumerGroup-4-4cbaef1c-f620-4439-bca7-df97d3d4b213 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:52:19,346] INFO [GroupCoordinator 0]: Stabilized group ConsumerGroup generation 10 (__consumer_offsets-45) with 6 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:52:19,371] INFO [GroupCoordinator 0]: Assignment received from leader consumer-ConsumerGroup-5-bf23ffd5-84c6-4d14-a3a9-71e95acf29fa for group ConsumerGroup for generation 10. The group has 6 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:52:37,114] INFO [GroupCoordinator 4]: Member consumer-2-3-6bd82fa3-8b96-423b-806c-5bafc8da571d in group 2 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:52:37,114] INFO [GroupCoordinator 4]: Preparing to rebalance group 2 in state PreparingRebalance with old generation 2 (__consumer_offsets-0) (reason: removing member consumer-2-3-6bd82fa3-8b96-423b-806c-5bafc8da571d on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:52:37,118] INFO [GroupCoordinator 4]: Group 2 with generation 3 is now empty (__consumer_offsets-0) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:52:37,119] INFO [GroupCoordinator 4]: Member consumer-0-1-697a6573-b159-4599-a4c9-fac3d974fdb0 in group 0 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:52:37,120] INFO [GroupCoordinator 4]: Preparing to rebalance group 0 in state PreparingRebalance with old generation 2 (__consumer_offsets-48) (reason: removing member consumer-0-1-697a6573-b159-4599-a4c9-fac3d974fdb0 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:52:37,120] INFO [GroupCoordinator 4]: Group 0 with generation 3 is now empty (__consumer_offsets-48) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:52:37,161] INFO [GroupCoordinator 0]: Member consumer-5-6-7d6284a3-4df3-4cb7-9b36-a8ed7147266c in group 5 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:52:37,161] INFO [GroupCoordinator 3]: Member consumer-4-5-50d59ed6-ef24-4452-ba7c-01115944fc2f in group 4 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:52:37,161] INFO [GroupCoordinator 2]: Member consumer-1-2-fb5ad8d9-7446-400d-ab7c-6bf59dcf11a6 in group 1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:52:37,161] INFO [GroupCoordinator 3]: Preparing to rebalance group 4 in state PreparingRebalance with old generation 2 (__consumer_offsets-2) (reason: removing member consumer-4-5-50d59ed6-ef24-4452-ba7c-01115944fc2f on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:52:37,161] INFO [GroupCoordinator 0]: Preparing to rebalance group 5 in state PreparingRebalance with old generation 2 (__consumer_offsets-3) (reason: removing member consumer-5-6-7d6284a3-4df3-4cb7-9b36-a8ed7147266c on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:52:37,163] INFO [GroupCoordinator 3]: Group 4 with generation 3 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:52:37,161] INFO [GroupCoordinator 2]: Preparing to rebalance group 1 in state PreparingRebalance with old generation 2 (__consumer_offsets-49) (reason: removing member consumer-1-2-fb5ad8d9-7446-400d-ab7c-6bf59dcf11a6 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:52:37,167] INFO [GroupCoordinator 0]: Group 5 with generation 3 is now empty (__consumer_offsets-3) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:52:37,168] INFO [GroupCoordinator 2]: Group 1 with generation 3 is now empty (__consumer_offsets-49) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:52:37,192] INFO [GroupCoordinator 2]: Member consumer-3-4-b2e4ff46-658b-46df-92b4-853edec96c54 in group 3 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:52:37,192] INFO [GroupCoordinator 2]: Preparing to rebalance group 3 in state PreparingRebalance with old generation 2 (__consumer_offsets-1) (reason: removing member consumer-3-4-b2e4ff46-658b-46df-92b4-853edec96c54 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:52:37,194] INFO [GroupCoordinator 2]: Group 3 with generation 3 is now empty (__consumer_offsets-1) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:52:51,915] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:52:51,920] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:52:51,909] WARN Close of session 0x100011639500004 (org.apache.zookeeper.server.NIOServerCnxn)
java.io.IOException: An existing connection was forcibly closed by the remote host
	at java.base/sun.nio.ch.SocketDispatcher.read0(Native Method)
	at java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:245)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:324)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:522)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:154)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
[2022-05-15 18:52:51,943] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Cancelled in-flight FETCH request with correlation id 5954 due to node 5 being disconnected (elapsed time since creation: 444ms, elapsed time since send: 444ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:52:51,956] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Cancelled in-flight FETCH request with correlation id 5953 due to node 5 being disconnected (elapsed time since creation: 449ms, elapsed time since send: 449ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:52:51,970] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:52:51,999] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:52:52,029] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Error sending fetch request (sessionId=1887944995, epoch=5952) to node 5: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to 5 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:99)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:52:52,054] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Error sending fetch request (sessionId=485183389, epoch=5951) to node 5: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to 5 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:99)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:52:52,088] WARN [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=4, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=1887944995, epoch=5952), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 5 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:99)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:52:52,107] WARN [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=485183389, epoch=5951), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 5 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:99)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:52:53,633] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:52:53,628] WARN Close of session 0x100011639500000 (org.apache.zookeeper.server.NIOServerCnxn)
java.io.IOException: An existing connection was forcibly closed by the remote host
	at java.base/sun.nio.ch.SocketDispatcher.read0(Native Method)
	at java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:245)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:324)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:522)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:154)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
[2022-05-15 18:52:53,645] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:52:53,660] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Cancelled in-flight FETCH request with correlation id 5951 due to node 4 being disconnected (elapsed time since creation: 442ms, elapsed time since send: 442ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:52:53,679] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Cancelled in-flight FETCH request with correlation id 5951 due to node 4 being disconnected (elapsed time since creation: 547ms, elapsed time since send: 547ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:52:53,704] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:52:53,697] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:52:53,713] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Error sending fetch request (sessionId=1899089789, epoch=5951) to node 4: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to 4 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:99)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:52:53,717] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Error sending fetch request (sessionId=1907215300, epoch=5951) to node 4: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to 4 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:99)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:52:53,742] WARN [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=1899089789, epoch=5951), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 4 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:99)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:52:53,746] WARN [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=1907215300, epoch=5951), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 4 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:99)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:52:55,175] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:52:55,177] WARN [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Connection to node 5 (LAPTOP-S01N1QNU/192.168.68.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:52:55,187] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:52:55,196] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Error sending fetch request (sessionId=485183389, epoch=INITIAL) to node 5: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to LAPTOP-S01N1QNU:9097 (id: 5 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:104)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:52:55,201] WARN [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={Sensor-0=PartitionData(topicId=Wchq4ZOJRIK4ViqZBdmcfw, fetchOffset=20, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=485183389, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to LAPTOP-S01N1QNU:9097 (id: 5 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:104)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:52:56,817] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:52:56,820] WARN [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Connection to node 4 (LAPTOP-S01N1QNU/192.168.68.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:52:56,828] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:52:56,831] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:52:56,830] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Error sending fetch request (sessionId=1899089789, epoch=INITIAL) to node 4: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to LAPTOP-S01N1QNU:9096 (id: 4 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:104)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:52:56,834] WARN [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Connection to node 4 (LAPTOP-S01N1QNU/192.168.68.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:52:56,838] WARN [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={Sensor-2=PartitionData(topicId=Wchq4ZOJRIK4ViqZBdmcfw, fetchOffset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0], lastFetchedEpoch=Optional.empty)}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=1899089789, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to LAPTOP-S01N1QNU:9096 (id: 4 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:104)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:52:56,850] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:52:56,858] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Error sending fetch request (sessionId=1907215300, epoch=INITIAL) to node 4: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to LAPTOP-S01N1QNU:9096 (id: 4 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:104)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:52:56,880] WARN [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={Sensor-2=PartitionData(topicId=Wchq4ZOJRIK4ViqZBdmcfw, fetchOffset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0], lastFetchedEpoch=Optional.empty)}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=1907215300, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to LAPTOP-S01N1QNU:9096 (id: 4 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:104)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:52:58,290] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:52:58,292] WARN [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Connection to node 5 (LAPTOP-S01N1QNU/192.168.68.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:52:58,302] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:52:58,305] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Error sending fetch request (sessionId=485183389, epoch=INITIAL) to node 5: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to LAPTOP-S01N1QNU:9097 (id: 5 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:104)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:52:58,312] WARN [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={Sensor-0=PartitionData(topicId=Wchq4ZOJRIK4ViqZBdmcfw, fetchOffset=20, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=485183389, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to LAPTOP-S01N1QNU:9097 (id: 5 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:104)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:52:59,905] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:52:59,905] WARN [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Connection to node 4 (LAPTOP-S01N1QNU/192.168.68.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:52:59,907] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:52:59,908] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Error sending fetch request (sessionId=1899089789, epoch=INITIAL) to node 4: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to LAPTOP-S01N1QNU:9096 (id: 4 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:104)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:52:59,910] WARN [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={Sensor-2=PartitionData(topicId=Wchq4ZOJRIK4ViqZBdmcfw, fetchOffset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0], lastFetchedEpoch=Optional.empty)}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=1899089789, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to LAPTOP-S01N1QNU:9096 (id: 4 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:104)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:52:59,951] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:52:59,951] WARN [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Connection to node 4 (LAPTOP-S01N1QNU/192.168.68.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:52:59,953] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:52:59,953] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Error sending fetch request (sessionId=1907215300, epoch=INITIAL) to node 4: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to LAPTOP-S01N1QNU:9096 (id: 4 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:104)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:52:59,954] WARN [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={Sensor-2=PartitionData(topicId=Wchq4ZOJRIK4ViqZBdmcfw, fetchOffset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0], lastFetchedEpoch=Optional.empty)}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=1907215300, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to LAPTOP-S01N1QNU:9096 (id: 4 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:104)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:53:01,374] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:53:01,374] WARN [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Connection to node 5 (LAPTOP-S01N1QNU/192.168.68.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:53:01,376] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:53:01,376] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Error sending fetch request (sessionId=485183389, epoch=INITIAL) to node 5: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to LAPTOP-S01N1QNU:9097 (id: 5 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:104)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:53:01,377] WARN [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={Sensor-0=PartitionData(topicId=Wchq4ZOJRIK4ViqZBdmcfw, fetchOffset=20, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=485183389, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to LAPTOP-S01N1QNU:9097 (id: 5 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:104)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:53:02,937] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:53:02,938] WARN [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Connection to node 4 (LAPTOP-S01N1QNU/192.168.68.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:53:02,939] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:53:02,940] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Error sending fetch request (sessionId=1899089789, epoch=INITIAL) to node 4: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to LAPTOP-S01N1QNU:9096 (id: 4 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:104)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:53:02,941] WARN [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={Sensor-2=PartitionData(topicId=Wchq4ZOJRIK4ViqZBdmcfw, fetchOffset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0], lastFetchedEpoch=Optional.empty)}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=1899089789, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to LAPTOP-S01N1QNU:9096 (id: 4 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:104)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:53:02,985] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:53:02,985] WARN [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Connection to node 4 (LAPTOP-S01N1QNU/192.168.68.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:53:02,986] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:53:02,987] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Error sending fetch request (sessionId=1907215300, epoch=INITIAL) to node 4: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to LAPTOP-S01N1QNU:9096 (id: 4 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:104)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:53:02,988] WARN [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={Sensor-2=PartitionData(topicId=Wchq4ZOJRIK4ViqZBdmcfw, fetchOffset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0], lastFetchedEpoch=Optional.empty)}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=1907215300, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to LAPTOP-S01N1QNU:9096 (id: 4 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:104)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:53:04,433] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:53:04,434] WARN [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Connection to node 5 (LAPTOP-S01N1QNU/192.168.68.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:53:04,435] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:53:04,436] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Error sending fetch request (sessionId=485183389, epoch=INITIAL) to node 5: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to LAPTOP-S01N1QNU:9097 (id: 5 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:104)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:53:04,436] WARN [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={Sensor-0=PartitionData(topicId=Wchq4ZOJRIK4ViqZBdmcfw, fetchOffset=20, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=485183389, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to LAPTOP-S01N1QNU:9097 (id: 5 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:104)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:53:05,053] WARN Close of session 0x100011639500002 (org.apache.zookeeper.server.NIOServerCnxn)
java.io.IOException: An existing connection was forcibly closed by the remote host
	at java.base/sun.nio.ch.SocketDispatcher.read0(Native Method)
	at java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:245)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:324)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:522)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:154)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
[2022-05-15 18:53:05,056] WARN Close of session 0x100011639500001 (org.apache.zookeeper.server.NIOServerCnxn)
java.io.IOException: An existing connection was forcibly closed by the remote host
	at java.base/sun.nio.ch.SocketDispatcher.read0(Native Method)
	at java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:245)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:324)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:522)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:154)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
[2022-05-15 18:53:05,112] WARN Close of session 0x100011639500005 (org.apache.zookeeper.server.NIOServerCnxn)
java.io.IOException: An existing connection was forcibly closed by the remote host
	at java.base/sun.nio.ch.SocketDispatcher.read0(Native Method)
	at java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:245)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:324)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:522)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:154)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
[2022-05-15 18:53:05,125] WARN Close of session 0x100011639500003 (org.apache.zookeeper.server.NIOServerCnxn)
java.io.IOException: An existing connection was forcibly closed by the remote host
	at java.base/sun.nio.ch.SocketDispatcher.read0(Native Method)
	at java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:245)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:324)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:522)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:154)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
[2022-05-15 18:53:18,036] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:53:18,044] WARN config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:53:18,044] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:53:18,044] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:53:18,044] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:53:18,044] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:53:18,054] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 18:53:18,054] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 18:53:18,055] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 18:53:18,055] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2022-05-15 18:53:18,055] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2022-05-15 18:53:18,065] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:53:18,065] WARN config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:53:18,065] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:53:18,065] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:53:18,065] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:53:18,065] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:53:18,065] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2022-05-15 18:53:18,076] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@62230c58 (org.apache.zookeeper.server.ServerMetrics)
[2022-05-15 18:53:18,085] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-15 18:53:18,096] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:53:18,096] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:53:18,096] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:53:18,096] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:53:18,096] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:53:18,096] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:53:18,096] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:53:18,096] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:53:18,096] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:53:18,096] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:53:22,664] INFO Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:53:22,665] INFO Server environment:host.name=LAPTOP-S01N1QNU (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:53:22,668] INFO Server environment:java.version=11.0.10 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:53:22,676] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:53:22,676] INFO Server environment:java.home=C:\Program Files\Java\jdk-11.0.10 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:53:22,676] INFO Server environment:java.class.path=C:\Users\joaoc\Documents\kafka\kfk\libs\activation-1.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\aopalliance-repackaged-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\argparse4j-0.7.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\audience-annotations-0.5.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-cli-1.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-lang3-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-basic-auth-extension-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-file-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-json-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-client-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-runtime-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-transforms-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-api-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-locator-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-utils-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-core-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-databind-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-dataformat-csv-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-datatype-jdk8-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-base-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-json-provider-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-jaxb-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-scala_2.12-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.activation-api-1.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.annotation-api-1.3.5.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.inject-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.validation-api-2.0.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javassist-3.27.0-GA.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.servlet-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jaxb-api-2.3.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-client-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-common-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-core-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-hk2-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-server-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-client-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-continuation-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-http-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-io-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-security-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-server-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlet-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlets-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-ajax-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jline-3.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jopt-simple-5.0.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jose4j-0.7.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-clients-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-log4j-appender-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-metadata-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-raft-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-server-common-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-shell-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-examples-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-scala_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-test-utils-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-tools-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\log4j-1.2.17.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\lz4-java-1.8.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\maven-artifact-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-2.2.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-4.1.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-buffer-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-codec-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-handler-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-resolver-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-epoll-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-unix-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\osgi-resource-locator-1.0.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\paranamer-2.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\plexus-utils-3.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\reflections-0.9.12.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\rocksdbjni-6.22.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-collection-compat_2.12-2.4.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-java8-compat_2.12-1.0.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-library-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-logging_2.12-3.9.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-reflect-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-api-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-log4j12-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\snappy-java-1.1.8.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\trogdor-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-jute-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:53:22,685] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-11.0.10\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.10\bin;C:\Program Files\apache-maven-3.6.3\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\sox-14-4-2;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\dotnet\;C:\Users\joaoc\Downloads\apache-zookeeper-3.8.0-bin\bin;C:\Program Files\swipl\bin;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\Scripts\;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\;C:\Users\joaoc\AppData\Local\Microsoft\WindowsApps;C:\Users\joaoc\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\joaoc\AppData\Local\Programs\Julia-1.6.0\bin;C:\Users\joaoc\.dotnet\tools;. (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:53:22,689] INFO Server environment:java.io.tmpdir=C:\Users\joaoc\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:53:22,689] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:53:22,703] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:53:22,706] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:53:22,708] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:53:22,710] INFO Server environment:user.name=joaoc (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:53:22,710] INFO Server environment:user.home=C:\Users\joaoc (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:53:22,711] INFO Server environment:user.dir=C:\Users\joaoc\Documents\kafka\kfk (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:53:22,731] INFO Server environment:os.memory.free=489MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:53:22,737] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:53:22,738] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:53:22,739] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:53:22,740] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:53:22,741] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:53:22,742] INFO zookeeper.flushDelay=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:53:22,743] INFO zookeeper.maxWriteQueuePollTime=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:53:22,743] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:53:22,745] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:53:22,747] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2022-05-15 18:53:22,761] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:53:22,766] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:53:22,776] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-15 18:53:22,776] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-15 18:53:22,776] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 18:53:22,784] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 18:53:22,786] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 18:53:22,792] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 18:53:22,793] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 18:53:22,794] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 18:53:22,796] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:53:22,796] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:53:22,796] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 clientPortListenBacklog -1 datadir C:\Users\joaoc\Documents\kafka\kfk\zookeeper\version-2 snapdir C:\Users\joaoc\Documents\kafka\kfk\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:53:22,835] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-15 18:53:22,836] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-15 18:53:22,836] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-15 18:53:22,845] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-15 18:53:22,888] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2022-05-15 18:53:22,888] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2022-05-15 18:53:22,891] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-15 18:53:22,891] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-15 18:53:22,902] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2022-05-15 18:53:22,904] INFO Snapshotting: 0x0 to C:\Users\joaoc\Documents\kafka\kfk\zookeeper\version-2\snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-15 18:53:22,910] INFO Snapshot loaded in 17 ms, highest zxid is 0x0, digest is 1371985504 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-15 18:53:22,911] INFO Snapshotting: 0x0 to C:\Users\joaoc\Documents\kafka\kfk\zookeeper\version-2\snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-15 18:53:22,913] INFO Snapshot taken in 3 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:53:22,930] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2022-05-15 18:53:22,931] INFO zookeeper.request_throttler.shutdownTimeout = 10000 (org.apache.zookeeper.server.RequestThrottler)
[2022-05-15 18:53:22,947] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2022-05-15 18:53:22,948] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2022-05-15 18:53:23,889] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 18:53:23,951] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 18:53:23,977] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 18:53:23,984] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 18:53:23,986] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 18:53:24,007] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 18:53:24,541] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 18:53:24,592] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 18:53:24,606] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 18:53:24,639] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 18:53:24,651] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 18:53:24,673] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 18:53:24,692] INFO starting (kafka.server.KafkaServer)
[2022-05-15 18:53:24,695] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 18:53:24,733] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:53:24,746] INFO starting (kafka.server.KafkaServer)
[2022-05-15 18:53:24,747] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 18:53:24,759] INFO starting (kafka.server.KafkaServer)
[2022-05-15 18:53:24,760] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 18:53:24,771] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:53:24,783] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:53:24,786] INFO starting (kafka.server.KafkaServer)
[2022-05-15 18:53:24,787] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 18:53:24,794] INFO starting (kafka.server.KafkaServer)
[2022-05-15 18:53:24,795] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 18:53:24,805] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:53:24,807] INFO starting (kafka.server.KafkaServer)
[2022-05-15 18:53:24,808] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 18:53:24,813] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:53:24,822] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:53:29,276] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,276] INFO Client environment:host.name=LAPTOP-S01N1QNU (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,277] INFO Client environment:java.version=11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,277] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,277] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,277] INFO Client environment:java.class.path=C:\Users\joaoc\Documents\kafka\kfk\libs\activation-1.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\aopalliance-repackaged-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\argparse4j-0.7.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\audience-annotations-0.5.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-cli-1.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-lang3-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-basic-auth-extension-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-file-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-json-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-client-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-runtime-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-transforms-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-api-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-locator-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-utils-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-core-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-databind-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-dataformat-csv-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-datatype-jdk8-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-base-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-json-provider-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-jaxb-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-scala_2.12-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.activation-api-1.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.annotation-api-1.3.5.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.inject-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.validation-api-2.0.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javassist-3.27.0-GA.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.servlet-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jaxb-api-2.3.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-client-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-common-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-core-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-hk2-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-server-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-client-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-continuation-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-http-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-io-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-security-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-server-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlet-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlets-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-ajax-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jline-3.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jopt-simple-5.0.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jose4j-0.7.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-clients-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-log4j-appender-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-metadata-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-raft-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-server-common-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-shell-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-examples-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-scala_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-test-utils-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-tools-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\log4j-1.2.17.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\lz4-java-1.8.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\maven-artifact-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-2.2.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-4.1.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-buffer-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-codec-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-handler-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-resolver-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-epoll-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-unix-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\osgi-resource-locator-1.0.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\paranamer-2.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\plexus-utils-3.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\reflections-0.9.12.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\rocksdbjni-6.22.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-collection-compat_2.12-2.4.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-java8-compat_2.12-1.0.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-library-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-logging_2.12-3.9.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-reflect-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-api-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-log4j12-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\snappy-java-1.1.8.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\trogdor-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-jute-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,278] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.10\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.10\bin;C:\Program Files\apache-maven-3.6.3\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\sox-14-4-2;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\dotnet\;C:\Users\joaoc\Downloads\apache-zookeeper-3.8.0-bin\bin;C:\Program Files\swipl\bin;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\Scripts\;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\;C:\Users\joaoc\AppData\Local\Microsoft\WindowsApps;C:\Users\joaoc\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\joaoc\AppData\Local\Programs\Julia-1.6.0\bin;C:\Users\joaoc\.dotnet\tools;. (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,279] INFO Client environment:java.io.tmpdir=C:\Users\joaoc\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,279] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,280] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,280] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,280] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,281] INFO Client environment:user.name=joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,281] INFO Client environment:user.home=C:\Users\joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,281] INFO Client environment:user.dir=C:\Users\joaoc\Documents\kafka\kfk (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,282] INFO Client environment:os.memory.free=1009MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,282] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,282] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,285] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2c5529ab (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,296] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 18:53:29,301] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:53:29,303] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:53:29,310] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:53:29,312] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:53:29,314] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:60642, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:53:29,324] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,324] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,324] INFO Client environment:host.name=LAPTOP-S01N1QNU (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,324] INFO Client environment:java.version=11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,324] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,325] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,324] INFO Client environment:host.name=LAPTOP-S01N1QNU (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,325] INFO Client environment:java.version=11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,325] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,325] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,325] INFO Client environment:java.class.path=C:\Users\joaoc\Documents\kafka\kfk\libs\activation-1.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\aopalliance-repackaged-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\argparse4j-0.7.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\audience-annotations-0.5.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-cli-1.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-lang3-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-basic-auth-extension-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-file-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-json-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-client-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-runtime-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-transforms-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-api-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-locator-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-utils-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-core-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-databind-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-dataformat-csv-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-datatype-jdk8-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-base-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-json-provider-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-jaxb-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-scala_2.12-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.activation-api-1.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.annotation-api-1.3.5.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.inject-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.validation-api-2.0.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javassist-3.27.0-GA.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.servlet-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jaxb-api-2.3.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-client-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-common-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-core-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-hk2-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-server-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-client-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-continuation-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-http-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-io-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-security-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-server-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlet-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlets-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-ajax-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jline-3.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jopt-simple-5.0.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jose4j-0.7.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-clients-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-log4j-appender-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-metadata-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-raft-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-server-common-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-shell-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-examples-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-scala_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-test-utils-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-tools-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\log4j-1.2.17.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\lz4-java-1.8.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\maven-artifact-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-2.2.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-4.1.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-buffer-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-codec-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-handler-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-resolver-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-epoll-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-unix-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\osgi-resource-locator-1.0.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\paranamer-2.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\plexus-utils-3.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\reflections-0.9.12.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\rocksdbjni-6.22.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-collection-compat_2.12-2.4.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-java8-compat_2.12-1.0.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-library-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-logging_2.12-3.9.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-reflect-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-api-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-log4j12-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\snappy-java-1.1.8.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\trogdor-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-jute-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,326] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.10\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.10\bin;C:\Program Files\apache-maven-3.6.3\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\sox-14-4-2;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\dotnet\;C:\Users\joaoc\Downloads\apache-zookeeper-3.8.0-bin\bin;C:\Program Files\swipl\bin;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\Scripts\;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\;C:\Users\joaoc\AppData\Local\Microsoft\WindowsApps;C:\Users\joaoc\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\joaoc\AppData\Local\Programs\Julia-1.6.0\bin;C:\Users\joaoc\.dotnet\tools;. (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,325] INFO Client environment:java.class.path=C:\Users\joaoc\Documents\kafka\kfk\libs\activation-1.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\aopalliance-repackaged-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\argparse4j-0.7.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\audience-annotations-0.5.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-cli-1.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-lang3-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-basic-auth-extension-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-file-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-json-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-client-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-runtime-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-transforms-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-api-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-locator-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-utils-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-core-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-databind-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-dataformat-csv-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-datatype-jdk8-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-base-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-json-provider-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-jaxb-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-scala_2.12-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.activation-api-1.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.annotation-api-1.3.5.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.inject-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.validation-api-2.0.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javassist-3.27.0-GA.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.servlet-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jaxb-api-2.3.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-client-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-common-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-core-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-hk2-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-server-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-client-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-continuation-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-http-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-io-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-security-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-server-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlet-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlets-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-ajax-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jline-3.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jopt-simple-5.0.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jose4j-0.7.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-clients-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-log4j-appender-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-metadata-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-raft-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-server-common-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-shell-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-examples-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-scala_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-test-utils-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-tools-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\log4j-1.2.17.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\lz4-java-1.8.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\maven-artifact-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-2.2.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-4.1.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-buffer-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-codec-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-handler-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-resolver-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-epoll-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-unix-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\osgi-resource-locator-1.0.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\paranamer-2.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\plexus-utils-3.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\reflections-0.9.12.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\rocksdbjni-6.22.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-collection-compat_2.12-2.4.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-java8-compat_2.12-1.0.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-library-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-logging_2.12-3.9.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-reflect-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-api-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-log4j12-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\snappy-java-1.1.8.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\trogdor-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-jute-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,326] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2022-05-15 18:53:29,326] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.10\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.10\bin;C:\Program Files\apache-maven-3.6.3\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\sox-14-4-2;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\dotnet\;C:\Users\joaoc\Downloads\apache-zookeeper-3.8.0-bin\bin;C:\Program Files\swipl\bin;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\Scripts\;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\;C:\Users\joaoc\AppData\Local\Microsoft\WindowsApps;C:\Users\joaoc\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\joaoc\AppData\Local\Programs\Julia-1.6.0\bin;C:\Users\joaoc\.dotnet\tools;. (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,326] INFO Client environment:java.io.tmpdir=C:\Users\joaoc\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,329] INFO Client environment:java.io.tmpdir=C:\Users\joaoc\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,329] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,329] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,331] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,331] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,332] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,332] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,334] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,334] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,336] INFO Client environment:user.name=joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,336] INFO Client environment:user.name=joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,338] INFO Client environment:user.home=C:\Users\joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,338] INFO Client environment:user.home=C:\Users\joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,344] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, session id = 0x100014535cf0000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:53:29,339] INFO Client environment:user.dir=C:\Users\joaoc\Documents\kafka\kfk (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,339] INFO Client environment:user.dir=C:\Users\joaoc\Documents\kafka\kfk (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,347] INFO Client environment:os.memory.free=1010MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,349] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:53:29,347] INFO Client environment:os.memory.free=1010MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,349] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,349] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,351] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,351] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,355] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,355] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,356] INFO Client environment:host.name=LAPTOP-S01N1QNU (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,356] INFO Client environment:host.name=LAPTOP-S01N1QNU (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,356] INFO Client environment:java.version=11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,356] INFO Client environment:java.version=11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,356] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,356] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,356] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,356] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,356] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2c5529ab (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,356] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2c5529ab (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,356] INFO Client environment:java.class.path=C:\Users\joaoc\Documents\kafka\kfk\libs\activation-1.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\aopalliance-repackaged-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\argparse4j-0.7.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\audience-annotations-0.5.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-cli-1.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-lang3-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-basic-auth-extension-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-file-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-json-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-client-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-runtime-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-transforms-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-api-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-locator-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-utils-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-core-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-databind-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-dataformat-csv-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-datatype-jdk8-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-base-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-json-provider-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-jaxb-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-scala_2.12-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.activation-api-1.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.annotation-api-1.3.5.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.inject-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.validation-api-2.0.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javassist-3.27.0-GA.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.servlet-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jaxb-api-2.3.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-client-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-common-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-core-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-hk2-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-server-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-client-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-continuation-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-http-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-io-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-security-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-server-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlet-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlets-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-ajax-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jline-3.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jopt-simple-5.0.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jose4j-0.7.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-clients-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-log4j-appender-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-metadata-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-raft-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-server-common-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-shell-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-examples-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-scala_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-test-utils-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-tools-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\log4j-1.2.17.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\lz4-java-1.8.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\maven-artifact-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-2.2.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-4.1.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-buffer-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-codec-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-handler-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-resolver-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-epoll-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-unix-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\osgi-resource-locator-1.0.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\paranamer-2.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\plexus-utils-3.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\reflections-0.9.12.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\rocksdbjni-6.22.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-collection-compat_2.12-2.4.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-java8-compat_2.12-1.0.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-library-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-logging_2.12-3.9.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-reflect-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-api-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-log4j12-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\snappy-java-1.1.8.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\trogdor-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-jute-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,356] INFO Client environment:java.class.path=C:\Users\joaoc\Documents\kafka\kfk\libs\activation-1.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\aopalliance-repackaged-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\argparse4j-0.7.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\audience-annotations-0.5.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-cli-1.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-lang3-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-basic-auth-extension-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-file-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-json-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-client-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-runtime-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-transforms-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-api-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-locator-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-utils-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-core-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-databind-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-dataformat-csv-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-datatype-jdk8-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-base-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-json-provider-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-jaxb-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-scala_2.12-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.activation-api-1.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.annotation-api-1.3.5.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.inject-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.validation-api-2.0.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javassist-3.27.0-GA.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.servlet-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jaxb-api-2.3.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-client-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-common-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-core-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-hk2-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-server-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-client-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-continuation-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-http-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-io-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-security-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-server-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlet-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlets-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-ajax-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jline-3.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jopt-simple-5.0.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jose4j-0.7.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-clients-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-log4j-appender-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-metadata-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-raft-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-server-common-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-shell-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-examples-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-scala_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-test-utils-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-tools-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\log4j-1.2.17.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\lz4-java-1.8.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\maven-artifact-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-2.2.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-4.1.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-buffer-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-codec-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-handler-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-resolver-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-epoll-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-unix-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\osgi-resource-locator-1.0.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\paranamer-2.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\plexus-utils-3.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\reflections-0.9.12.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\rocksdbjni-6.22.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-collection-compat_2.12-2.4.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-java8-compat_2.12-1.0.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-library-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-logging_2.12-3.9.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-reflect-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-api-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-log4j12-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\snappy-java-1.1.8.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\trogdor-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-jute-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,357] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.10\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.10\bin;C:\Program Files\apache-maven-3.6.3\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\sox-14-4-2;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\dotnet\;C:\Users\joaoc\Downloads\apache-zookeeper-3.8.0-bin\bin;C:\Program Files\swipl\bin;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\Scripts\;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\;C:\Users\joaoc\AppData\Local\Microsoft\WindowsApps;C:\Users\joaoc\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\joaoc\AppData\Local\Programs\Julia-1.6.0\bin;C:\Users\joaoc\.dotnet\tools;. (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,358] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.10\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.10\bin;C:\Program Files\apache-maven-3.6.3\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\sox-14-4-2;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\dotnet\;C:\Users\joaoc\Downloads\apache-zookeeper-3.8.0-bin\bin;C:\Program Files\swipl\bin;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\Scripts\;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\;C:\Users\joaoc\AppData\Local\Microsoft\WindowsApps;C:\Users\joaoc\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\joaoc\AppData\Local\Programs\Julia-1.6.0\bin;C:\Users\joaoc\.dotnet\tools;. (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,360] INFO Client environment:java.io.tmpdir=C:\Users\joaoc\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,361] INFO Client environment:java.io.tmpdir=C:\Users\joaoc\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,362] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,362] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,365] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,365] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,370] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,370] INFO Client environment:host.name=LAPTOP-S01N1QNU (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,372] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 18:53:29,372] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 18:53:29,382] INFO Client environment:java.version=11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,382] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,366] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,383] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,366] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,383] INFO Client environment:java.class.path=C:\Users\joaoc\Documents\kafka\kfk\libs\activation-1.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\aopalliance-repackaged-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\argparse4j-0.7.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\audience-annotations-0.5.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-cli-1.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-lang3-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-basic-auth-extension-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-file-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-json-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-client-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-runtime-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-transforms-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-api-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-locator-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-utils-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-core-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-databind-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-dataformat-csv-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-datatype-jdk8-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-base-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-json-provider-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-jaxb-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-scala_2.12-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.activation-api-1.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.annotation-api-1.3.5.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.inject-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.validation-api-2.0.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javassist-3.27.0-GA.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.servlet-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jaxb-api-2.3.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-client-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-common-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-core-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-hk2-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-server-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-client-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-continuation-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-http-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-io-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-security-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-server-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlet-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlets-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-ajax-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jline-3.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jopt-simple-5.0.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jose4j-0.7.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-clients-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-log4j-appender-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-metadata-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-raft-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-server-common-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-shell-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-examples-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-scala_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-test-utils-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-tools-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\log4j-1.2.17.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\lz4-java-1.8.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\maven-artifact-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-2.2.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-4.1.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-buffer-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-codec-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-handler-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-resolver-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-epoll-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-unix-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\osgi-resource-locator-1.0.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\paranamer-2.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\plexus-utils-3.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\reflections-0.9.12.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\rocksdbjni-6.22.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-collection-compat_2.12-2.4.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-java8-compat_2.12-1.0.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-library-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-logging_2.12-3.9.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-reflect-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-api-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-log4j12-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\snappy-java-1.1.8.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\trogdor-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-jute-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,386] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.10\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.10\bin;C:\Program Files\apache-maven-3.6.3\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\sox-14-4-2;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\dotnet\;C:\Users\joaoc\Downloads\apache-zookeeper-3.8.0-bin\bin;C:\Program Files\swipl\bin;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\Scripts\;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\;C:\Users\joaoc\AppData\Local\Microsoft\WindowsApps;C:\Users\joaoc\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\joaoc\AppData\Local\Programs\Julia-1.6.0\bin;C:\Users\joaoc\.dotnet\tools;. (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,388] INFO Client environment:java.io.tmpdir=C:\Users\joaoc\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,390] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,383] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,383] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,393] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:53:29,393] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:53:29,391] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,391] INFO Client environment:user.name=joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,393] INFO Client environment:user.name=joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,395] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:53:29,396] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:53:29,396] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,396] INFO Client environment:user.home=C:\Users\joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,398] INFO Client environment:user.home=C:\Users\joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,399] INFO Client environment:user.dir=C:\Users\joaoc\Documents\kafka\kfk (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,399] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,402] INFO Client environment:user.dir=C:\Users\joaoc\Documents\kafka\kfk (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,408] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:53:29,405] INFO Client environment:os.memory.free=1010MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,409] INFO Client environment:os.memory.free=1010MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,410] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:53:29,411] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,412] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,415] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:60647, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:53:29,409] INFO Client environment:user.name=joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,413] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,415] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,416] INFO Client environment:user.home=C:\Users\joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,420] INFO Client environment:user.dir=C:\Users\joaoc\Documents\kafka\kfk (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,423] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2c5529ab (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,422] INFO Client environment:os.memory.free=1010MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,424] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2c5529ab (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,427] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, session id = 0x100014535cf0001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:53:29,429] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:53:29,425] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,434] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:53:29,431] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:53:29,442] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 18:53:29,443] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 18:53:29,436] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,449] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:53:29,442] INFO Socket connection established, initiating session, client: /127.0.0.1:60652, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:53:29,450] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:53:29,455] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2c5529ab (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:53:29,456] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:53:29,468] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100014535cf0002, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:53:29,474] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:53:29,456] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:53:29,479] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:53:29,482] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:53:29,486] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 18:53:29,486] INFO Socket connection established, initiating session, client: /127.0.0.1:60655, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:53:29,491] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:53:29,493] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:53:29,496] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:53:29,497] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:60656, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:53:29,498] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100014535cf0003, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:53:29,501] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:53:29,505] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:53:29,508] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, session id = 0x100014535cf0004, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:53:29,511] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:53:29,516] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:53:29,513] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:53:29,524] INFO Socket connection established, initiating session, client: /127.0.0.1:60657, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:53:29,537] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100014535cf0005, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:53:29,537] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:53:29,545] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:53:29,560] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
[2022-05-15 18:53:29,562] INFO Cleared cache (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:53:29,570] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:53:29,588] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
[2022-05-15 18:53:29,589] INFO Cleared cache (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:53:29,613] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:53:29,629] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
[2022-05-15 18:53:29,630] INFO Cleared cache (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:53:29,639] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:53:29,650] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:53:29,654] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
[2022-05-15 18:53:29,658] INFO Cleared cache (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:53:29,666] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
[2022-05-15 18:53:29,672] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:53:29,667] INFO Cleared cache (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:53:29,685] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
[2022-05-15 18:53:29,686] INFO Cleared cache (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:53:29,801] INFO Cluster ID = 4MmEBXr9QB6Y66VgsTj6SQ (kafka.server.KafkaServer)
[2022-05-15 18:53:29,807] WARN No meta.properties file under dir C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-05-15 18:53:29,842] INFO Cluster ID = 4MmEBXr9QB6Y66VgsTj6SQ (kafka.server.KafkaServer)
[2022-05-15 18:53:29,849] WARN No meta.properties file under dir C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-05-15 18:53:29,909] INFO Cluster ID = 4MmEBXr9QB6Y66VgsTj6SQ (kafka.server.KafkaServer)
[2022-05-15 18:53:29,916] WARN No meta.properties file under dir C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-05-15 18:53:29,926] INFO Cluster ID = 4MmEBXr9QB6Y66VgsTj6SQ (kafka.server.KafkaServer)
[2022-05-15 18:53:29,933] WARN No meta.properties file under dir C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-05-15 18:53:29,941] INFO Cluster ID = 4MmEBXr9QB6Y66VgsTj6SQ (kafka.server.KafkaServer)
[2022-05-15 18:53:29,949] WARN No meta.properties file under dir C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-05-15 18:53:29,951] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs6
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:53:29,982] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs6
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:53:29,988] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:53:30,001] INFO Cluster ID = 4MmEBXr9QB6Y66VgsTj6SQ (kafka.server.KafkaServer)
[2022-05-15 18:53:30,008] WARN No meta.properties file under dir C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-05-15 18:53:30,010] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:53:30,062] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:53:30,065] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:53:30,080] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:53:30,061] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:53:30,104] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:53:30,110] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:53:30,077] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:53:30,105] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:53:30,094] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 4
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:53:30,110] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:53:30,104] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:53:30,118] INFO Log directory C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6 not found, creating it. (kafka.log.LogManager)
[2022-05-15 18:53:30,111] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:53:30,111] INFO Log directory C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1 not found, creating it. (kafka.log.LogManager)
[2022-05-15 18:53:30,127] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:53:30,138] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 4
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:53:30,145] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 3
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:53:30,171] INFO Loading logs from log dirs ArrayBuffer(C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1) (kafka.log.LogManager)
[2022-05-15 18:53:30,171] INFO Loading logs from log dirs ArrayBuffer(C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6) (kafka.log.LogManager)
[2022-05-15 18:53:30,179] INFO Attempting recovery for all logs in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1 since no clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 18:53:30,179] INFO Attempting recovery for all logs in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6 since no clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 18:53:30,174] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 3
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.serv[2022-05-15 18:53:30,194] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:53:30,194] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
er.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:53:30,197] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:53:30,198] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:53:30,199] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:53:30,200] INFO Loaded 0 logs in 28ms. (kafka.log.LogManager)
[2022-05-15 18:53:30,199] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:53:30,201] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:53:30,201] INFO Loaded 0 logs in 30ms. (kafka.log.LogManager)
[2022-05-15 18:53:30,201] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 18:53:30,202] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 18:53:30,208] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:53:30,212] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 18:53:30,218] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:53:30,212] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 18:53:30,227] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:53:30,227] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:53:30,227] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:53:30,229] INFO Log directory C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3 not found, creating it. (kafka.log.LogManager)
[2022-05-15 18:53:30,231] INFO Log directory C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2 not found, creating it. (kafka.log.LogManager)
[2022-05-15 18:53:30,254] INFO Log directory C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5 not found, creating it. (kafka.log.LogManager)
[2022-05-15 18:53:30,261] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:53:30,272] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:53:30,272] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:53:30,274] INFO Loading logs from log dirs ArrayBuffer(C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3) (kafka.log.LogManager)
[2022-05-15 18:53:30,275] INFO Loading logs from log dirs ArrayBuffer(C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2) (kafka.log.LogManager)
[2022-05-15 18:53:30,272] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:53:30,284] INFO Attempting recovery for all logs in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3 since no clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 18:53:30,285] INFO Attempting recovery for all logs in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2 since no clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 18:53:30,298] INFO Loading logs from log dirs ArrayBuffer(C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5) (kafka.log.LogManager)
[2022-05-15 18:53:30,301] INFO Log directory C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4 not found, creating it. (kafka.log.LogManager)
[2022-05-15 18:53:30,307] INFO Attempting recovery for all logs in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5 since no clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 18:53:30,311] INFO Loaded 0 logs in 36ms. (kafka.log.LogManager)
[2022-05-15 18:53:30,312] INFO Loaded 0 logs in 37ms. (kafka.log.LogManager)
[2022-05-15 18:53:30,312] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 18:53:30,314] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 18:53:30,335] INFO Loaded 0 logs in 36ms. (kafka.log.LogManager)
[2022-05-15 18:53:30,335] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 18:53:30,337] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 18:53:30,336] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 18:53:30,348] INFO Loading logs from log dirs ArrayBuffer(C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4) (kafka.log.LogManager)
[2022-05-15 18:53:30,356] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 18:53:30,360] INFO Attempting recovery for all logs in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4 since no clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 18:53:30,386] INFO Loaded 0 logs in 36ms. (kafka.log.LogManager)
[2022-05-15 18:53:30,388] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 18:53:30,393] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 18:53:30,792] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:53:30,792] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:53:30,918] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:53:30,918] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:53:30,920] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:53:30,999] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:53:31,294] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 18:53:31,309] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-05-15 18:53:31,325] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 18:53:31,336] INFO Awaiting socket connections on 0.0.0.0:9097. (kafka.network.Acceptor)
[2022-05-15 18:53:31,408] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:53:31,420] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:53:31,442] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:53:31,444] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:53:31,493] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 18:53:31,503] INFO Awaiting socket connections on 0.0.0.0:9096. (kafka.network.Acceptor)
[2022-05-15 18:53:31,504] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 18:53:31,519] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 18:53:31,517] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:53:31,522] INFO [ExpirationReaper-5-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:53:31,518] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2022-05-15 18:53:31,523] INFO [ExpirationReaper-5-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:53:31,532] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2022-05-15 18:53:31,517] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:53:31,523] INFO [ExpirationReaper-5-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:53:31,568] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:53:31,569] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:53:31,522] INFO [ExpirationReaper-5-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:53:31,570] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:53:31,587] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:53:31,590] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:53:31,591] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:53:31,594] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:53:31,596] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:53:31,609] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:53:31,611] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:53:31,613] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 18:53:31,620] INFO Awaiting socket connections on 0.0.0.0:9095. (kafka.network.Acceptor)
[2022-05-15 18:53:31,628] INFO [ExpirationReaper-4-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:53:31,630] INFO [ExpirationReaper-4-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:53:31,632] INFO [ExpirationReaper-4-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:53:31,641] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:53:31,644] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:53:31,654] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:53:31,654] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:53:31,654] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:53:31,661] INFO [ExpirationReaper-4-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:53:31,661] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:53:31,661] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:53:31,661] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:53:31,663] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:53:31,666] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:53:31,673] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:53:31,677] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:53:31,679] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:53:31,701] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:53:31,702] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:53:31,703] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:53:31,706] INFO [ExpirationReaper-3-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:53:31,718] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:53:36,154] INFO Creating /brokers/ids/5 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 18:53:36,154] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 18:53:36,179] INFO Stat of the created znode at /brokers/ids/5 is: 106,106,1652637216170,1652637216170,1,0,0,72058990805057537,214,0,106
 (kafka.zk.KafkaZkClient)
[2022-05-15 18:53:36,179] INFO Stat of the created znode at /brokers/ids/0 is: 105,105,1652637216168,1652637216168,1,0,0,72058990805057536,214,0,105
 (kafka.zk.KafkaZkClient)
[2022-05-15 18:53:36,181] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://LAPTOP-S01N1QNU:9092, czxid (broker epoch): 105 (kafka.zk.KafkaZkClient)
[2022-05-15 18:53:36,180] INFO Registered broker 5 at path /brokers/ids/5 with addresses: PLAINTEXT://LAPTOP-S01N1QNU:9097, czxid (broker epoch): 106 (kafka.zk.KafkaZkClient)
[2022-05-15 18:53:36,218] INFO Creating /brokers/ids/4 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 18:53:36,239] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 18:53:36,239] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 18:53:36,243] INFO Stat of the created znode at /brokers/ids/4 is: 107,107,1652637216234,1652637216234,1,0,0,72058990805057540,214,0,107
 (kafka.zk.KafkaZkClient)
[2022-05-15 18:53:36,245] INFO Registered broker 4 at path /brokers/ids/4 with addresses: PLAINTEXT://LAPTOP-S01N1QNU:9096, czxid (broker epoch): 107 (kafka.zk.KafkaZkClient)
[2022-05-15 18:53:36,261] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:53:36,266] INFO Stat of the created znode at /brokers/ids/1 is: 108,108,1652637216255,1652637216255,1,0,0,72058990805057539,214,0,108
 (kafka.zk.KafkaZkClient)
[2022-05-15 18:53:36,269] INFO Stat of the created znode at /brokers/ids/2 is: 109,109,1652637216258,1652637216258,1,0,0,72058990805057538,214,0,109
 (kafka.zk.KafkaZkClient)
[2022-05-15 18:53:36,276] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:53:36,268] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://LAPTOP-S01N1QNU:9093, czxid (broker epoch): 108 (kafka.zk.KafkaZkClient)
[2022-05-15 18:53:36,276] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:53:36,286] INFO [ExpirationReaper-5-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:53:36,271] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://LAPTOP-S01N1QNU:9094, czxid (broker epoch): 109 (kafka.zk.KafkaZkClient)
[2022-05-15 18:53:36,279] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2022-05-15 18:53:36,302] INFO [ExpirationReaper-5-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:53:36,310] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 18:53:36,302] INFO [ExpirationReaper-5-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:53:36,302] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:36,330] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
[2022-05-15 18:53:36,331] INFO [GroupCoordinator 5]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:36,331] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
[2022-05-15 18:53:36,330] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
[2022-05-15 18:53:36,331] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
[2022-05-15 18:53:36,331] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
[2022-05-15 18:53:36,343] INFO [GroupCoordinator 5]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:36,328] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:36,353] INFO Stat of the created znode at /brokers/ids/3 is: 114,114,1652637216340,1652637216340,1,0,0,72058990805057541,214,0,114
 (kafka.zk.KafkaZkClient)
[2022-05-15 18:53:36,365] INFO Registered broker 3 at path /brokers/ids/3 with addresses: PLAINTEXT://LAPTOP-S01N1QNU:9095, czxid (broker epoch): 114 (kafka.zk.KafkaZkClient)
[2022-05-15 18:53:36,367] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:53:36,328] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
[2022-05-15 18:53:36,371] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:53:36,372] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:53:36,365] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:53:36,380] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:53:36,387] INFO [TransactionCoordinator id=5] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:53:36,391] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:53:36,396] INFO [ExpirationReaper-4-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:53:36,397] INFO [TransactionCoordinator id=5] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:53:36,402] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:53:36,397] INFO [Transaction Marker Channel Manager 5]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:53:36,402] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:53:36,413] INFO [ExpirationReaper-4-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:53:36,426] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:53:36,413] INFO [ExpirationReaper-4-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:53:36,402] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:53:36,438] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:53:36,444] INFO [GroupCoordinator 4]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:36,438] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:53:36,460] INFO [GroupCoordinator 4]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:36,460] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:53:36,466] INFO [ExpirationReaper-5-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:53:36,475] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:53:36,477] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:36,475] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:53:36,489] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:36,497] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:53:36,497] INFO [TransactionCoordinator id=4] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:53:36,507] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:53:36,508] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:36,504] INFO [TransactionCoordinator id=4] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:53:36,519] INFO [ExpirationReaper-3-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:53:36,521] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:36,521] INFO [Transaction Marker Channel Manager 4]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:53:36,527] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:53:36,530] INFO [ExpirationReaper-3-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:53:36,531] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:53:36,539] INFO [ExpirationReaper-3-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:53:36,534] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:53:36,548] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:53:36,555] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:53:36,557] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:53:36,561] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:53:36,563] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:53:36,569] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:53:36,571] INFO [GroupCoordinator 3]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:36,579] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:53:36,570] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:53:36,579] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:53:36,593] INFO [ExpirationReaper-4-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:53:36,596] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:53:36,582] INFO Kafka startTimeMs: 1652637216557 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:53:36,589] INFO [GroupCoordinator 3]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:36,605] INFO [KafkaServer id=5] started (kafka.server.KafkaServer)
[2022-05-15 18:53:36,625] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:53:36,640] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:53:36,647] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:53:36,654] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:53:36,669] INFO [TransactionCoordinator id=3] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:53:36,662] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:53:36,681] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:53:36,681] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:53:36,683] INFO Kafka startTimeMs: 1652637216649 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:53:36,690] INFO [TransactionCoordinator id=3] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:53:36,694] INFO [Transaction Marker Channel Manager 3]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:53:36,704] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:53:36,712] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2022-05-15 18:53:36,718] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:53:36,762] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:53:36,765] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:53:36,774] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:53:36,767] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:53:36,804] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:53:36,822] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:53:36,846] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:53:36,848] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:53:36,866] INFO Kafka startTimeMs: 1652637216781 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:53:36,888] INFO [KafkaServer id=4] started (kafka.server.KafkaServer)
[2022-05-15 18:53:36,909] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:53:36,915] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:53:36,926] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:53:36,938] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:53:36,960] INFO Kafka startTimeMs: 1652637216827 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:53:36,926] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:53:36,925] INFO [ExpirationReaper-3-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:53:36,993] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2022-05-15 18:53:37,034] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:53:37,037] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:53:37,051] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:53:37,051] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:53:37,040] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:53:37,055] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:53:37,068] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:53:37,068] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:53:37,086] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:53:37,093] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:53:37,097] INFO Kafka startTimeMs: 1652637217039 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:53:37,109] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:53:37,110] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:53:37,109] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2022-05-15 18:53:37,150] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:53:37,152] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:53:37,171] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:53:37,175] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:53:37,201] INFO Kafka startTimeMs: 1652637217160 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:53:37,213] INFO [KafkaServer id=3] started (kafka.server.KafkaServer)
[2022-05-15 18:53:37,267] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:53:37,294] INFO Creating topic Sensor with configuration {min.insync.replicas=2} and initial partition assignment Map(2 -> ArrayBuffer(0, 4, 2), 5 -> ArrayBuffer(4, 0, 5), 4 -> ArrayBuffer(1, 3, 0), 1 -> ArrayBuffer(3, 1, 4), 3 -> ArrayBuffer(5, 2, 3), 0 -> ArrayBuffer(2, 5, 1)) (kafka.zk.AdminZkClient)
[2022-05-15 18:53:37,298] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:53:37,359] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:53:37,359] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:53:37,503] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-2) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:53:37,515] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:53:37,515] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-4) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:53:37,521] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:53:37,523] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-5) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:53:37,523] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:53:37,638] INFO [LogLoader partition=Sensor-2, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:37,647] INFO [LogLoader partition=Sensor-4, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:37,654] INFO [LogLoader partition=Sensor-0, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:37,655] INFO [LogLoader partition=Sensor-5, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:37,655] INFO [LogLoader partition=Sensor-1, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:37,656] INFO [LogLoader partition=Sensor-3, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:37,671] INFO Created log for partition Sensor-2 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:53:37,682] INFO Created log for partition Sensor-4 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:53:37,689] INFO Created log for partition Sensor-1 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:53:37,693] INFO Created log for partition Sensor-3 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:53:37,691] INFO Created log for partition Sensor-0 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:53:37,694] INFO [Partition Sensor-1 broker=3] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-15 18:53:37,689] INFO [Partition Sensor-4 broker=1] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-15 18:53:37,675] INFO [Partition Sensor-2 broker=0] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-15 18:53:37,697] INFO [Partition Sensor-3 broker=5] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-15 18:53:37,706] INFO [Partition Sensor-0 broker=2] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 18:53:37,706] INFO [Partition Sensor-1 broker=3] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:37,711] INFO [Partition Sensor-4 broker=1] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:37,691] INFO Created log for partition Sensor-5 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:53:37,711] INFO [Partition Sensor-2 broker=0] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:37,713] INFO [Partition Sensor-3 broker=5] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:37,715] INFO [Partition Sensor-0 broker=2] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:37,723] INFO [Partition Sensor-5 broker=4] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-15 18:53:37,728] INFO [Partition Sensor-5 broker=4] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:37,792] INFO [LogLoader partition=Sensor-4, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:37,792] INFO [LogLoader partition=Sensor-4, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:37,794] INFO Created log for partition Sensor-4 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:53:37,797] INFO [LogLoader partition=Sensor-2, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:37,797] INFO [LogLoader partition=Sensor-1, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:37,799] INFO [LogLoader partition=Sensor-5, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:37,815] INFO [LogLoader partition=Sensor-1, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:37,795] INFO Created log for partition Sensor-4 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:53:37,795] INFO [Partition Sensor-4 broker=0] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-15 18:53:37,800] INFO Created log for partition Sensor-2 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:53:37,802] INFO Created log for partition Sensor-5 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:53:37,801] INFO Created log for partition Sensor-1 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:53:37,820] INFO [Partition Sensor-4 broker=3] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-15 18:53:37,818] INFO Created log for partition Sensor-1 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:53:37,823] INFO [Partition Sensor-2 broker=2] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-15 18:53:37,850] INFO [Partition Sensor-1 broker=4] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-15 18:53:37,850] INFO [Partition Sensor-2 broker=2] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:37,820] INFO [Partition Sensor-4 broker=0] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:37,848] INFO [Partition Sensor-5 broker=5] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-15 18:53:37,848] INFO [Partition Sensor-1 broker=1] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-15 18:53:37,849] INFO [Partition Sensor-4 broker=3] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:37,852] INFO [Partition Sensor-1 broker=4] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:37,870] INFO [LogLoader partition=Sensor-3, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:37,856] INFO [Partition Sensor-5 broker=5] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:37,872] INFO [LogLoader partition=Sensor-3, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:37,871] INFO [LogLoader partition=Sensor-5, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:37,856] INFO [Partition Sensor-1 broker=1] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:37,871] INFO [LogLoader partition=Sensor-2, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:37,872] INFO Created log for partition Sensor-3 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:53:37,893] INFO Created log for partition Sensor-3 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:53:37,894] INFO Created log for partition Sensor-5 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:53:37,907] INFO [LogLoader partition=Sensor-0, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:37,896] INFO [Partition Sensor-3 broker=2] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-15 18:53:37,908] INFO [LogLoader partition=Sensor-0, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:37,896] INFO Created log for partition Sensor-2 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:53:37,899] INFO [Partition Sensor-3 broker=3] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-15 18:53:37,936] INFO Created log for partition Sensor-0 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:53:37,943] INFO [Partition Sensor-0 broker=5] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 18:53:37,933] INFO [Partition Sensor-5 broker=0] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-15 18:53:37,942] INFO Created log for partition Sensor-0 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:53:37,939] INFO [Partition Sensor-3 broker=2] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:37,940] INFO [Partition Sensor-2 broker=4] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-15 18:53:37,940] INFO [Partition Sensor-3 broker=3] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:37,943] INFO [Partition Sensor-0 broker=5] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:37,963] INFO [Partition Sensor-5 broker=0] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:37,964] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-3, Sensor-2) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:53:37,963] INFO [Partition Sensor-0 broker=1] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 18:53:37,966] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-4, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:53:37,965] INFO [Partition Sensor-2 broker=4] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:37,972] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-4, Sensor-5) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:53:37,966] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-0, Sensor-5) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:53:37,990] INFO [Partition Sensor-0 broker=1] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:37,997] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-1, Sensor-2) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:53:38,012] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:53:38,030] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:53:38,034] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:53:38,036] INFO [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:53:38,039] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:53:38,039] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 1 for partitions Map(Sensor-4 -> InitialFetchState(Some(3kHFpB0OSsqsaeYgMpILzw),BrokerEndPoint(id=1, host=LAPTOP-S01N1QNU:9093),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:53:38,037] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 5 for partitions Map(Sensor-3 -> InitialFetchState(Some(3kHFpB0OSsqsaeYgMpILzw),BrokerEndPoint(id=5, host=LAPTOP-S01N1QNU:9097),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:53:38,044] INFO [ReplicaFetcherManager on broker 5] Added fetcher to broker 2 for partitions Map(Sensor-0 -> InitialFetchState(Some(3kHFpB0OSsqsaeYgMpILzw),BrokerEndPoint(id=2, host=LAPTOP-S01N1QNU:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:53:38,057] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:53:38,043] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 5 for partitions Map(Sensor-3 -> InitialFetchState(Some(3kHFpB0OSsqsaeYgMpILzw),BrokerEndPoint(id=5, host=LAPTOP-S01N1QNU:9097),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:53:38,062] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:53:38,039] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Truncating partition Sensor-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:53:38,045] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Truncating partition Sensor-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:53:38,042] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition Sensor-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:53:38,064] INFO [ReplicaFetcherManager on broker 4] Added fetcher to broker 3 for partitions Map(Sensor-1 -> InitialFetchState(Some(3kHFpB0OSsqsaeYgMpILzw),BrokerEndPoint(id=3, host=LAPTOP-S01N1QNU:9095),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:53:38,044] INFO [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Truncating partition Sensor-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:53:38,068] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 3 for partitions Map(Sensor-1 -> InitialFetchState(Some(3kHFpB0OSsqsaeYgMpILzw),BrokerEndPoint(id=3, host=LAPTOP-S01N1QNU:9095),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:53:38,063] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 0 for partitions Map(Sensor-2 -> InitialFetchState(Some(3kHFpB0OSsqsaeYgMpILzw),BrokerEndPoint(id=0, host=LAPTOP-S01N1QNU:9092),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:53:38,059] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 4 for partitions Map(Sensor-5 -> InitialFetchState(Some(3kHFpB0OSsqsaeYgMpILzw),BrokerEndPoint(id=4, host=LAPTOP-S01N1QNU:9096),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:53:38,064] INFO [ReplicaFetcherManager on broker 5] Added fetcher to broker 4 for partitions Map(Sensor-5 -> InitialFetchState(Some(3kHFpB0OSsqsaeYgMpILzw),BrokerEndPoint(id=4, host=LAPTOP-S01N1QNU:9096),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:53:38,066] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Truncating partition Sensor-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:53:38,067] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 1 for partitions Map(Sensor-4 -> InitialFetchState(Some(3kHFpB0OSsqsaeYgMpILzw),BrokerEndPoint(id=1, host=LAPTOP-S01N1QNU:9093),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:53:38,070] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Truncating partition Sensor-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:53:38,081] INFO [UnifiedLog partition=Sensor-3, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:53:38,089] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:53:38,084] INFO [UnifiedLog partition=Sensor-4, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:53:38,085] INFO [UnifiedLog partition=Sensor-3, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:53:38,095] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 2 for partitions Map(Sensor-0 -> InitialFetchState(Some(3kHFpB0OSsqsaeYgMpILzw),BrokerEndPoint(id=2, host=LAPTOP-S01N1QNU:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:53:38,087] INFO [ReplicaFetcherManager on broker 4] Added fetcher to broker 0 for partitions Map(Sensor-2 -> InitialFetchState(Some(3kHFpB0OSsqsaeYgMpILzw),BrokerEndPoint(id=0, host=LAPTOP-S01N1QNU:9092),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:53:38,082] INFO [UnifiedLog partition=Sensor-0, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:53:38,080] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:53:38,082] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:53:38,084] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:53:38,120] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Truncating partition Sensor-5 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:53:38,114] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:53:38,134] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition Sensor-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:53:38,157] INFO [UnifiedLog partition=Sensor-5, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:53:38,154] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Truncating partition Sensor-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:53:38,110] INFO [UnifiedLog partition=Sensor-1, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:53:38,150] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Truncating partition Sensor-5 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:53:38,113] INFO [UnifiedLog partition=Sensor-1, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:53:38,171] INFO [UnifiedLog partition=Sensor-2, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:53:38,177] INFO [UnifiedLog partition=Sensor-5, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:53:38,171] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition Sensor-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:53:38,175] INFO [UnifiedLog partition=Sensor-4, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:53:38,132] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:53:38,250] WARN [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-3. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:53:38,262] WARN [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-4. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:53:38,240] WARN [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-3. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:53:38,252] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Truncating partition Sensor-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:53:38,225] INFO [UnifiedLog partition=Sensor-0, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:53:38,280] WARN [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-0. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:53:38,258] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-4. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:53:38,270] INFO [UnifiedLog partition=Sensor-2, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:53:38,300] WARN [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-5. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:53:38,298] WARN [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-5. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:53:56,003] INFO Creating topic __consumer_offsets with configuration {compression.type=producer, cleanup.policy=compact, segment.bytes=104857600} and initial partition assignment Map(23 -> ArrayBuffer(4), 32 -> ArrayBuffer(0), 41 -> ArrayBuffer(4), 17 -> ArrayBuffer(4), 8 -> ArrayBuffer(0), 35 -> ArrayBuffer(4), 44 -> ArrayBuffer(0), 26 -> ArrayBuffer(0), 11 -> ArrayBuffer(4), 29 -> ArrayBuffer(4), 38 -> ArrayBuffer(0), 47 -> ArrayBuffer(4), 20 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 5 -> ArrayBuffer(4), 14 -> ArrayBuffer(0), 46 -> ArrayBuffer(1), 49 -> ArrayBuffer(3), 40 -> ArrayBuffer(1), 13 -> ArrayBuffer(3), 4 -> ArrayBuffer(1), 22 -> ArrayBuffer(1), 31 -> ArrayBuffer(3), 16 -> ArrayBuffer(1), 7 -> ArrayBuffer(3), 43 -> ArrayBuffer(3), 25 -> ArrayBuffer(3), 34 -> ArrayBuffer(1), 10 -> ArrayBuffer(1), 37 -> ArrayBuffer(3), 1 -> ArrayBuffer(3), 19 -> ArrayBuffer(3), 28 -> ArrayBuffer(1), 45 -> ArrayBuffer(5), 27 -> ArrayBuffer(5), 36 -> ArrayBuffer(2), 18 -> ArrayBuffer(2), 9 -> ArrayBuffer(5), 21 -> ArrayBuffer(5), 48 -> ArrayBuffer(2), 3 -> ArrayBuffer(5), 12 -> ArrayBuffer(2), 30 -> ArrayBuffer(2), 39 -> ArrayBuffer(5), 15 -> ArrayBuffer(5), 42 -> ArrayBuffer(2), 24 -> ArrayBuffer(2), 6 -> ArrayBuffer(2), 33 -> ArrayBuffer(5), 0 -> ArrayBuffer(2)) (kafka.zk.AdminZkClient)
[2022-05-15 18:53:56,171] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(__consumer_offsets-30, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-18, __consumer_offsets-24, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-12) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:53:56,172] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(__consumer_offsets-21, __consumer_offsets-27, __consumer_offsets-9, __consumer_offsets-33, __consumer_offsets-3, __consumer_offsets-15, __consumer_offsets-39, __consumer_offsets-45) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:53:56,172] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(__consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-23, __consumer_offsets-47, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-5, __consumer_offsets-29) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:53:56,173] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-8, __consumer_offsets-38, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44, __consumer_offsets-26, __consumer_offsets-32) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:53:56,174] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(__consumer_offsets-7, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:53:56,174] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-46, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:53:56,191] INFO [LogLoader partition=__consumer_offsets-0, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:56,193] INFO [LogLoader partition=__consumer_offsets-45, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:56,193] INFO [LogLoader partition=__consumer_offsets-7, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:56,193] INFO [LogLoader partition=__consumer_offsets-29, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:56,194] INFO Created log for partition __consumer_offsets-0 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:53:56,193] INFO [LogLoader partition=__consumer_offsets-26, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:56,195] INFO [LogLoader partition=__consumer_offsets-10, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:56,196] INFO Created log for partition __consumer_offsets-45 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\__consumer_offsets-45 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:53:56,196] INFO Created log for partition __consumer_offsets-7 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\__consumer_offsets-7 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:53:56,196] INFO Created log for partition __consumer_offsets-29 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\__consumer_offsets-29 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:53:56,199] INFO [Partition __consumer_offsets-0 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,197] INFO Created log for partition __consumer_offsets-26 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-26 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:53:56,199] INFO Created log for partition __consumer_offsets-10 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\__consumer_offsets-10 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:53:56,208] INFO [Partition __consumer_offsets-10 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2022-05-15 18:53:56,202] INFO [Partition __consumer_offsets-7 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2022-05-15 18:53:56,201] INFO [Partition __consumer_offsets-45 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2022-05-15 18:53:56,202] INFO [Partition __consumer_offsets-29 broker=4] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2022-05-15 18:53:56,205] INFO [Partition __consumer_offsets-26 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2022-05-15 18:53:56,201] INFO [Partition __consumer_offsets-0 broker=2] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,212] INFO [Partition __consumer_offsets-10 broker=1] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,214] INFO [Partition __consumer_offsets-45 broker=5] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,214] INFO [Partition __consumer_offsets-7 broker=3] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,214] INFO [Partition __consumer_offsets-26 broker=0] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,214] INFO [Partition __consumer_offsets-29 broker=4] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,247] INFO [LogLoader partition=__consumer_offsets-4, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:56,247] INFO [LogLoader partition=__consumer_offsets-48, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:56,254] INFO Created log for partition __consumer_offsets-4 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:53:56,254] INFO Created log for partition __consumer_offsets-48 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\__consumer_offsets-48 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:53:56,255] INFO [Partition __consumer_offsets-48 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2022-05-15 18:53:56,255] INFO [Partition __consumer_offsets-4 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2022-05-15 18:53:56,259] INFO [LogLoader partition=__consumer_offsets-23, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:56,258] INFO [Partition __consumer_offsets-4 broker=1] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,258] INFO [Partition __consumer_offsets-48 broker=2] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,260] INFO [LogLoader partition=__consumer_offsets-20, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:56,261] INFO [LogLoader partition=__consumer_offsets-1, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:56,262] INFO [LogLoader partition=__consumer_offsets-39, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:56,262] INFO Created log for partition __consumer_offsets-23 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\__consumer_offsets-23 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:53:56,267] INFO Created log for partition __consumer_offsets-39 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\__consumer_offsets-39 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:53:56,268] INFO [Partition __consumer_offsets-23 broker=4] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2022-05-15 18:53:56,266] INFO Created log for partition __consumer_offsets-20 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-20 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:53:56,266] INFO Created log for partition __consumer_offsets-1 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:53:56,276] INFO [Partition __consumer_offsets-39 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2022-05-15 18:53:56,275] INFO [Partition __consumer_offsets-23 broker=4] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,275] INFO [Partition __consumer_offsets-20 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2022-05-15 18:53:56,280] INFO [Partition __consumer_offsets-39 broker=5] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,277] INFO [Partition __consumer_offsets-1 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2022-05-15 18:53:56,283] INFO [Partition __consumer_offsets-20 broker=0] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,287] INFO [Partition __consumer_offsets-1 broker=3] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,293] INFO [LogLoader partition=__consumer_offsets-46, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:56,300] INFO Created log for partition __consumer_offsets-46 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\__consumer_offsets-46 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:53:56,302] INFO [Partition __consumer_offsets-46 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2022-05-15 18:53:56,302] INFO [LogLoader partition=__consumer_offsets-42, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:56,302] INFO [Partition __consumer_offsets-46 broker=1] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,306] INFO Created log for partition __consumer_offsets-42 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\__consumer_offsets-42 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:53:56,307] INFO [Partition __consumer_offsets-42 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2022-05-15 18:53:56,308] INFO [Partition __consumer_offsets-42 broker=2] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,317] INFO [LogLoader partition=__consumer_offsets-49, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:56,318] INFO [LogLoader partition=__consumer_offsets-33, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:56,317] INFO [LogLoader partition=__consumer_offsets-17, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:56,322] INFO [LogLoader partition=__consumer_offsets-14, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:56,320] INFO Created log for partition __consumer_offsets-49 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\__consumer_offsets-49 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:53:56,321] INFO Created log for partition __consumer_offsets-33 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\__consumer_offsets-33 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:53:56,324] INFO [Partition __consumer_offsets-49 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2022-05-15 18:53:56,322] INFO Created log for partition __consumer_offsets-17 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\__consumer_offsets-17 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:53:56,327] INFO [Partition __consumer_offsets-33 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2022-05-15 18:53:56,328] INFO Created log for partition __consumer_offsets-14 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-14 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:53:56,328] INFO [Partition __consumer_offsets-49 broker=3] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,331] INFO [Partition __consumer_offsets-33 broker=5] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,331] INFO [Partition __consumer_offsets-14 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2022-05-15 18:53:56,329] INFO [Partition __consumer_offsets-17 broker=4] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2022-05-15 18:53:56,337] INFO [Partition __consumer_offsets-14 broker=0] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,339] INFO [Partition __consumer_offsets-17 broker=4] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,356] INFO [LogLoader partition=__consumer_offsets-40, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:56,363] INFO Created log for partition __consumer_offsets-40 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\__consumer_offsets-40 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:53:56,365] INFO [Partition __consumer_offsets-40 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2022-05-15 18:53:56,366] INFO [Partition __consumer_offsets-40 broker=1] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,375] INFO [LogLoader partition=__consumer_offsets-36, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:56,377] INFO [LogLoader partition=__consumer_offsets-27, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:56,378] INFO [LogLoader partition=__consumer_offsets-43, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:56,378] INFO Created log for partition __consumer_offsets-36 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\__consumer_offsets-36 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:53:56,380] INFO [Partition __consumer_offsets-36 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2022-05-15 18:53:56,379] INFO [LogLoader partition=__consumer_offsets-8, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:56,382] INFO [LogLoader partition=__consumer_offsets-11, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:56,380] INFO Created log for partition __consumer_offsets-27 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\__consumer_offsets-27 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:53:56,380] INFO [Partition __consumer_offsets-36 broker=2] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,380] INFO Created log for partition __consumer_offsets-43 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\__consumer_offsets-43 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:53:56,385] INFO Created log for partition __consumer_offsets-11 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\__consumer_offsets-11 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:53:56,384] INFO Created log for partition __consumer_offsets-8 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-8 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:53:56,387] INFO [Partition __consumer_offsets-27 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2022-05-15 18:53:56,392] INFO [Partition __consumer_offsets-8 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2022-05-15 18:53:56,391] INFO [Partition __consumer_offsets-43 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2022-05-15 18:53:56,391] INFO [Partition __consumer_offsets-11 broker=4] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2022-05-15 18:53:56,392] INFO [Partition __consumer_offsets-27 broker=5] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,393] INFO [Partition __consumer_offsets-8 broker=0] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,394] INFO [Partition __consumer_offsets-43 broker=3] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,395] INFO [Partition __consumer_offsets-11 broker=4] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,397] INFO [LogLoader partition=__consumer_offsets-34, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:56,400] INFO Created log for partition __consumer_offsets-34 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\__consumer_offsets-34 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:53:56,401] INFO [Partition __consumer_offsets-34 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2022-05-15 18:53:56,402] INFO [Partition __consumer_offsets-34 broker=1] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,416] INFO [LogLoader partition=__consumer_offsets-30, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:56,418] INFO Created log for partition __consumer_offsets-30 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\__consumer_offsets-30 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:53:56,422] INFO [LogLoader partition=__consumer_offsets-21, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:56,422] INFO [LogLoader partition=__consumer_offsets-2, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:56,419] INFO [Partition __consumer_offsets-30 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2022-05-15 18:53:56,424] INFO [LogLoader partition=__consumer_offsets-37, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:56,425] INFO [LogLoader partition=__consumer_offsets-5, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:56,426] INFO Created log for partition __consumer_offsets-37 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\__consumer_offsets-37 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:53:56,426] INFO [LogLoader partition=__consumer_offsets-28, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:56,425] INFO Created log for partition __consumer_offsets-21 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\__consumer_offsets-21 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:53:56,423] INFO [Partition __consumer_offsets-30 broker=2] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,425] INFO Created log for partition __consumer_offsets-2 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:53:56,426] INFO [Partition __consumer_offsets-37 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2022-05-15 18:53:56,428] INFO Created log for partition __consumer_offsets-28 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\__consumer_offsets-28 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:53:56,427] INFO Created log for partition __consumer_offsets-5 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\__consumer_offsets-5 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:53:56,432] INFO [Partition __consumer_offsets-21 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2022-05-15 18:53:56,432] INFO [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2022-05-15 18:53:56,433] INFO [Partition __consumer_offsets-37 broker=3] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,433] INFO [Partition __consumer_offsets-28 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2022-05-15 18:53:56,434] INFO [Partition __consumer_offsets-5 broker=4] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2022-05-15 18:53:56,438] INFO [Partition __consumer_offsets-21 broker=5] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,440] INFO [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,444] INFO [Partition __consumer_offsets-5 broker=4] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,443] INFO [Partition __consumer_offsets-28 broker=1] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,460] INFO [LogLoader partition=__consumer_offsets-24, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:56,462] INFO Created log for partition __consumer_offsets-24 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\__consumer_offsets-24 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:53:56,462] INFO [Partition __consumer_offsets-24 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2022-05-15 18:53:56,464] INFO [Partition __consumer_offsets-24 broker=2] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,467] INFO [LogLoader partition=__consumer_offsets-31, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:56,471] INFO Created log for partition __consumer_offsets-31 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\__consumer_offsets-31 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:53:56,472] INFO [LogLoader partition=__consumer_offsets-15, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:56,471] INFO [Partition __consumer_offsets-31 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2022-05-15 18:53:56,473] INFO [Partition __consumer_offsets-31 broker=3] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,476] INFO [LogLoader partition=__consumer_offsets-47, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:56,475] INFO Created log for partition __consumer_offsets-15 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\__consumer_offsets-15 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:53:56,477] INFO [LogLoader partition=__consumer_offsets-16, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:56,478] INFO [LogLoader partition=__consumer_offsets-38, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:56,476] INFO [Partition __consumer_offsets-15 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2022-05-15 18:53:56,478] INFO Created log for partition __consumer_offsets-47 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\__consumer_offsets-47 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:53:56,481] INFO Created log for partition __consumer_offsets-16 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\__consumer_offsets-16 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:53:56,479] INFO [Partition __consumer_offsets-15 broker=5] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,481] INFO Created log for partition __consumer_offsets-38 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-38 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:53:56,479] INFO [Partition __consumer_offsets-47 broker=4] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2022-05-15 18:53:56,489] INFO [LogLoader partition=__consumer_offsets-18, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:56,487] INFO [Partition __consumer_offsets-16 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2022-05-15 18:53:56,488] INFO [Partition __consumer_offsets-38 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2022-05-15 18:53:56,488] INFO [Partition __consumer_offsets-47 broker=4] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,491] INFO Created log for partition __consumer_offsets-18 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\__consumer_offsets-18 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:53:56,495] INFO [Partition __consumer_offsets-16 broker=1] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,498] INFO [LogLoader partition=__consumer_offsets-19, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:56,495] INFO [Partition __consumer_offsets-38 broker=0] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,497] INFO [Partition __consumer_offsets-18 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2022-05-15 18:53:56,500] INFO Created log for partition __consumer_offsets-19 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\__consumer_offsets-19 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:53:56,505] INFO [Partition __consumer_offsets-18 broker=2] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,505] INFO [Partition __consumer_offsets-19 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2022-05-15 18:53:56,507] INFO [Partition __consumer_offsets-19 broker=3] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,510] INFO [LogLoader partition=__consumer_offsets-9, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:56,513] INFO Created log for partition __consumer_offsets-9 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\__consumer_offsets-9 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:53:56,518] INFO [LogLoader partition=__consumer_offsets-35, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:56,517] INFO [Partition __consumer_offsets-9 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2022-05-15 18:53:56,520] INFO [Partition __consumer_offsets-9 broker=5] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,521] INFO Created log for partition __consumer_offsets-35 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\__consumer_offsets-35 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:53:56,521] INFO [LogLoader partition=__consumer_offsets-22, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:56,521] INFO [Partition __consumer_offsets-35 broker=4] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2022-05-15 18:53:56,523] INFO Created log for partition __consumer_offsets-22 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\__consumer_offsets-22 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:53:56,523] INFO [Partition __consumer_offsets-22 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2022-05-15 18:53:56,523] INFO [Partition __consumer_offsets-35 broker=4] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,524] INFO [LogLoader partition=__consumer_offsets-44, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:56,524] INFO [Partition __consumer_offsets-22 broker=1] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,527] INFO Created log for partition __consumer_offsets-44 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-44 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:53:56,530] INFO [Partition __consumer_offsets-44 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2022-05-15 18:53:56,534] INFO [LogLoader partition=__consumer_offsets-12, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:56,534] INFO [LogLoader partition=__consumer_offsets-25, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:56,536] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 22 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,534] INFO [Partition __consumer_offsets-44 broker=0] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,536] INFO Created log for partition __consumer_offsets-12 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\__consumer_offsets-12 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:53:56,539] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,537] INFO Created log for partition __consumer_offsets-25 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\__consumer_offsets-25 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:53:56,543] INFO [LogLoader partition=__consumer_offsets-3, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:56,540] INFO [Partition __consumer_offsets-12 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2022-05-15 18:53:56,548] INFO [LogLoader partition=__consumer_offsets-41, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:56,541] INFO [Partition __consumer_offsets-25 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2022-05-15 18:53:56,543] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 28 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,545] INFO Created log for partition __consumer_offsets-3 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:53:56,547] INFO [Partition __consumer_offsets-12 broker=2] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,550] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,550] INFO [Partition __consumer_offsets-25 broker=3] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,551] INFO [Partition __consumer_offsets-3 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2022-05-15 18:53:56,551] INFO Created log for partition __consumer_offsets-41 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\__consumer_offsets-41 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:53:56,555] INFO [Partition __consumer_offsets-3 broker=5] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,553] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 34 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,556] INFO [Partition __consumer_offsets-41 broker=4] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2022-05-15 18:53:56,567] INFO [LogLoader partition=__consumer_offsets-32, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:56,566] INFO [Partition __consumer_offsets-41 broker=4] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,569] INFO Created log for partition __consumer_offsets-32 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-32 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:53:56,572] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 3 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,564] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,572] INFO [Partition __consumer_offsets-32 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2022-05-15 18:53:56,575] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,561] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 15 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,575] INFO [Partition __consumer_offsets-32 broker=0] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,577] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 41 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,577] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 9 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,575] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 40 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,581] INFO [LogLoader partition=__consumer_offsets-13, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:56,580] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,579] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,578] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 26 milliseconds for epoch 0, of which 25 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,583] INFO Created log for partition __consumer_offsets-13 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\__consumer_offsets-13 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:53:56,585] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 44 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,584] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 47 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,579] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,583] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 15 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,586] INFO [LogLoader partition=__consumer_offsets-6, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:53:56,585] INFO [Partition __consumer_offsets-13 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2022-05-15 18:53:56,585] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,587] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,587] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,584] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 10 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,591] INFO [Partition __consumer_offsets-13 broker=3] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,597] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 2 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,589] INFO Created log for partition __consumer_offsets-6 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\__consumer_offsets-6 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 18:53:56,594] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 5 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,587] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 46 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,599] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,600] INFO [Partition __consumer_offsets-6 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2022-05-15 18:53:56,605] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 25 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,589] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-3 in 13 milliseconds for epoch 0, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,596] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-41 in 13 milliseconds for epoch 0, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,604] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 8 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,597] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 11 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,605] INFO [Partition __consumer_offsets-6 broker=2] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:53:56,607] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,595] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 21 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,602] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,607] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 11 milliseconds for epoch 0, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,604] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,612] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 31 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,607] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-9 in 25 milliseconds for epoch 0, of which 25 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,617] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 6 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,607] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-47 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,609] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,615] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 4 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,616] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,612] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,612] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 11 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,614] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,615] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,618] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,620] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-25 in 8 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,619] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 14 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,620] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,617] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-15 in 22 milliseconds for epoch 0, of which 22 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,629] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 12 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,618] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-5 in 6 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,622] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 37 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,627] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,630] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 10 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,632] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,625] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 27 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,629] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-31 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,626] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,629] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,630] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,636] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-6 in 7 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,633] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-21 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,633] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,640] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 17 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,641] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 20 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,634] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,640] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 18 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,639] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,644] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 43 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,641] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-11 in 1 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,645] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-37 in 1 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,641] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,646] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 16 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,643] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-12 in 4 milliseconds for epoch 0, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,648] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 33 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,649] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,645] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,645] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,647] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 1 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,647] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,649] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-27 in 1 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,660] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 49 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,660] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 23 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,655] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,661] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 26 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,663] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 24 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,660] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-43 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,660] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,659] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,671] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 1 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,671] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,664] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-18 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,665] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,666] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,678] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 39 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,661] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,680] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 32 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,676] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,683] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 29 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,678] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,682] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 1 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,687] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,688] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 30 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,684] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,684] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-23 in 1 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,683] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-49 in 1 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,687] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,688] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,689] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,692] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 45 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,689] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,690] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 38 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,690] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,694] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 35 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,692] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,695] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,693] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 3 milliseconds for epoch 0, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,699] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 36 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,697] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 7 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,695] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-29 in 1 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,702] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-45 in 1 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,698] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,699] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,699] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,697] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,705] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,702] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,703] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,706] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,709] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 42 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,710] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 13 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,709] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,712] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,710] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,716] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,718] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 48 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,718] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,720] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 19 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,720] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,720] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,721] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,723] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 0 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,724] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,723] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-48 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,724] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,730] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:53:56,791] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group 4 in Empty state. Created a new member id consumer-4-5-0f926dad-6206-42d9-84d1-b0a554137556 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,792] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group 2 in Empty state. Created a new member id consumer-2-3-3ee1dd09-9162-47ea-a731-f9bee90e5226 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,792] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group 0 in Empty state. Created a new member id consumer-0-1-4f5e5ed5-7d92-4ee6-805e-5da3d588cdf5 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,805] INFO [GroupCoordinator 5]: Dynamic member with unknown member id joins group 5 in Empty state. Created a new member id consumer-5-6-db89c82a-828f-4517-bf9d-16f98bf7aeb3 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,810] INFO [GroupCoordinator 0]: Preparing to rebalance group 4 in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member consumer-4-5-0f926dad-6206-42d9-84d1-b0a554137556 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,813] INFO [GroupCoordinator 2]: Preparing to rebalance group 2 in state PreparingRebalance with old generation 0 (__consumer_offsets-0) (reason: Adding new member consumer-2-3-3ee1dd09-9162-47ea-a731-f9bee90e5226 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,813] INFO [GroupCoordinator 2]: Preparing to rebalance group 0 in state PreparingRebalance with old generation 0 (__consumer_offsets-48) (reason: Adding new member consumer-0-1-4f5e5ed5-7d92-4ee6-805e-5da3d588cdf5 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,818] INFO [GroupCoordinator 3]: Dynamic member with unknown member id joins group 3 in Empty state. Created a new member id consumer-3-4-3ff59e2d-3ab5-4ed7-b34c-2cffec961c58 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,818] INFO [GroupCoordinator 3]: Dynamic member with unknown member id joins group 1 in Empty state. Created a new member id consumer-1-2-4ef43cc3-5aa6-4475-bbf6-c000a3e60e94 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,826] INFO [GroupCoordinator 5]: Preparing to rebalance group 5 in state PreparingRebalance with old generation 0 (__consumer_offsets-3) (reason: Adding new member consumer-5-6-db89c82a-828f-4517-bf9d-16f98bf7aeb3 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,831] INFO [GroupCoordinator 0]: Stabilized group 4 generation 1 (__consumer_offsets-2) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,831] INFO [GroupCoordinator 2]: Stabilized group 2 generation 1 (__consumer_offsets-0) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,841] INFO [GroupCoordinator 2]: Stabilized group 0 generation 1 (__consumer_offsets-48) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,842] INFO [GroupCoordinator 3]: Preparing to rebalance group 1 in state PreparingRebalance with old generation 0 (__consumer_offsets-49) (reason: Adding new member consumer-1-2-4ef43cc3-5aa6-4475-bbf6-c000a3e60e94 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,842] INFO [GroupCoordinator 3]: Preparing to rebalance group 3 in state PreparingRebalance with old generation 0 (__consumer_offsets-1) (reason: Adding new member consumer-3-4-3ff59e2d-3ab5-4ed7-b34c-2cffec961c58 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,845] INFO [GroupCoordinator 5]: Stabilized group 5 generation 1 (__consumer_offsets-3) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,856] INFO [GroupCoordinator 0]: Assignment received from leader consumer-4-5-0f926dad-6206-42d9-84d1-b0a554137556 for group 4 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,860] INFO [GroupCoordinator 2]: Assignment received from leader consumer-0-1-4f5e5ed5-7d92-4ee6-805e-5da3d588cdf5 for group 0 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,860] INFO [GroupCoordinator 2]: Assignment received from leader consumer-2-3-3ee1dd09-9162-47ea-a731-f9bee90e5226 for group 2 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,863] INFO [GroupCoordinator 3]: Stabilized group 1 generation 1 (__consumer_offsets-49) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,863] INFO [GroupCoordinator 5]: Assignment received from leader consumer-5-6-db89c82a-828f-4517-bf9d-16f98bf7aeb3 for group 5 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,875] INFO [GroupCoordinator 3]: Stabilized group 3 generation 1 (__consumer_offsets-1) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,881] INFO [GroupCoordinator 3]: Assignment received from leader consumer-3-4-3ff59e2d-3ab5-4ed7-b34c-2cffec961c58 for group 3 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:53:56,881] INFO [GroupCoordinator 3]: Assignment received from leader consumer-1-2-4ef43cc3-5aa6-4475-bbf6-c000a3e60e94 for group 1 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:54:51,263] INFO [GroupCoordinator 3]: Member consumer-1-2-4ef43cc3-5aa6-4475-bbf6-c000a3e60e94 in group 1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:54:51,264] INFO [GroupCoordinator 3]: Preparing to rebalance group 1 in state PreparingRebalance with old generation 1 (__consumer_offsets-49) (reason: removing member consumer-1-2-4ef43cc3-5aa6-4475-bbf6-c000a3e60e94 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:54:51,266] INFO [GroupCoordinator 3]: Group 1 with generation 2 is now empty (__consumer_offsets-49) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:54:51,311] INFO [GroupCoordinator 0]: Member consumer-4-5-0f926dad-6206-42d9-84d1-b0a554137556 in group 4 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:54:51,311] INFO [GroupCoordinator 2]: Member consumer-0-1-4f5e5ed5-7d92-4ee6-805e-5da3d588cdf5 in group 0 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:54:51,311] INFO [GroupCoordinator 5]: Member consumer-5-6-db89c82a-828f-4517-bf9d-16f98bf7aeb3 in group 5 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:54:51,312] INFO [GroupCoordinator 0]: Preparing to rebalance group 4 in state PreparingRebalance with old generation 1 (__consumer_offsets-2) (reason: removing member consumer-4-5-0f926dad-6206-42d9-84d1-b0a554137556 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:54:51,313] INFO [GroupCoordinator 0]: Group 4 with generation 2 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:54:51,313] INFO [GroupCoordinator 5]: Preparing to rebalance group 5 in state PreparingRebalance with old generation 1 (__consumer_offsets-3) (reason: removing member consumer-5-6-db89c82a-828f-4517-bf9d-16f98bf7aeb3 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:54:51,312] INFO [GroupCoordinator 2]: Preparing to rebalance group 0 in state PreparingRebalance with old generation 1 (__consumer_offsets-48) (reason: removing member consumer-0-1-4f5e5ed5-7d92-4ee6-805e-5da3d588cdf5 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:54:51,318] INFO [GroupCoordinator 5]: Group 5 with generation 2 is now empty (__consumer_offsets-3) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:54:51,318] INFO [GroupCoordinator 2]: Group 0 with generation 2 is now empty (__consumer_offsets-48) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:54:51,324] INFO [GroupCoordinator 3]: Member consumer-3-4-3ff59e2d-3ab5-4ed7-b34c-2cffec961c58 in group 3 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:54:51,324] INFO [GroupCoordinator 2]: Member consumer-2-3-3ee1dd09-9162-47ea-a731-f9bee90e5226 in group 2 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:54:51,327] INFO [GroupCoordinator 2]: Preparing to rebalance group 2 in state PreparingRebalance with old generation 1 (__consumer_offsets-0) (reason: removing member consumer-2-3-3ee1dd09-9162-47ea-a731-f9bee90e5226 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:54:51,327] INFO [GroupCoordinator 3]: Preparing to rebalance group 3 in state PreparingRebalance with old generation 1 (__consumer_offsets-1) (reason: removing member consumer-3-4-3ff59e2d-3ab5-4ed7-b34c-2cffec961c58 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:54:51,328] INFO [GroupCoordinator 2]: Group 2 with generation 2 is now empty (__consumer_offsets-0) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:54:51,330] INFO [GroupCoordinator 3]: Group 3 with generation 2 is now empty (__consumer_offsets-1) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:58:53,405] INFO [GroupCoordinator 5]: Dynamic member with unknown member id joins group ConsumerGroup in Empty state. Created a new member id consumer-ConsumerGroup-3-d84b3092-7c03-471c-bcc3-1d18326e8e32 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:58:53,406] INFO [GroupCoordinator 5]: Dynamic member with unknown member id joins group ConsumerGroup in Empty state. Created a new member id consumer-ConsumerGroup-2-5db26050-60aa-4a37-9913-9e4f4b27b49e and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:58:53,407] INFO [GroupCoordinator 5]: Dynamic member with unknown member id joins group ConsumerGroup in Empty state. Created a new member id consumer-ConsumerGroup-1-14627c95-6fba-4534-8fe9-672352f64a1e and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:58:53,408] INFO [GroupCoordinator 5]: Preparing to rebalance group ConsumerGroup in state PreparingRebalance with old generation 0 (__consumer_offsets-45) (reason: Adding new member consumer-ConsumerGroup-3-d84b3092-7c03-471c-bcc3-1d18326e8e32 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:58:53,413] INFO [GroupCoordinator 5]: Stabilized group ConsumerGroup generation 1 (__consumer_offsets-45) with 3 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:58:53,421] INFO [GroupCoordinator 5]: Assignment received from leader consumer-ConsumerGroup-3-d84b3092-7c03-471c-bcc3-1d18326e8e32 for group ConsumerGroup for generation 1. The group has 3 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 19:26:29,587] INFO [GroupCoordinator 5]: Member consumer-ConsumerGroup-2-5db26050-60aa-4a37-9913-9e4f4b27b49e in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 19:26:29,594] INFO [GroupCoordinator 5]: Preparing to rebalance group ConsumerGroup in state PreparingRebalance with old generation 1 (__consumer_offsets-45) (reason: removing member consumer-ConsumerGroup-2-5db26050-60aa-4a37-9913-9e4f4b27b49e on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 19:26:29,594] INFO [GroupCoordinator 5]: Member consumer-ConsumerGroup-1-14627c95-6fba-4534-8fe9-672352f64a1e in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 19:26:29,650] INFO [GroupCoordinator 5]: Member consumer-ConsumerGroup-3-d84b3092-7c03-471c-bcc3-1d18326e8e32 in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 19:26:29,650] INFO [GroupCoordinator 5]: Group ConsumerGroup with generation 2 is now empty (__consumer_offsets-45) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 19:34:59,112] INFO [GroupCoordinator 3]: Dynamic member with unknown member id joins group Group in Empty state. Created a new member id consumer-Group-1-c9a84eb2-3147-4d95-a9f1-1c237ff8d12c and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 19:34:59,118] INFO [GroupCoordinator 3]: Preparing to rebalance group Group in state PreparingRebalance with old generation 0 (__consumer_offsets-25) (reason: Adding new member consumer-Group-1-c9a84eb2-3147-4d95-a9f1-1c237ff8d12c with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 19:34:59,119] INFO [GroupCoordinator 3]: Stabilized group Group generation 1 (__consumer_offsets-25) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 19:34:59,128] INFO [GroupCoordinator 3]: Assignment received from leader consumer-Group-1-c9a84eb2-3147-4d95-a9f1-1c237ff8d12c for group Group for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 19:35:30,329] INFO [GroupCoordinator 3]: Dynamic member with unknown member id joins group Group in Stable state. Created a new member id consumer-Group-1-c62454be-d609-4c31-a17b-3f28fd8b2c72 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 19:35:30,332] INFO [GroupCoordinator 3]: Preparing to rebalance group Group in state PreparingRebalance with old generation 1 (__consumer_offsets-25) (reason: Adding new member consumer-Group-1-c62454be-d609-4c31-a17b-3f28fd8b2c72 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 19:36:08,959] INFO [GroupCoordinator 3]: Member consumer-Group-1-c9a84eb2-3147-4d95-a9f1-1c237ff8d12c in group Group has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 19:36:08,961] INFO [GroupCoordinator 3]: Stabilized group Group generation 2 (__consumer_offsets-25) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 19:36:08,967] INFO [GroupCoordinator 3]: Assignment received from leader consumer-Group-1-c62454be-d609-4c31-a17b-3f28fd8b2c72 for group Group for generation 2. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 19:37:21,661] INFO [GroupCoordinator 3]: Member consumer-Group-1-c62454be-d609-4c31-a17b-3f28fd8b2c72 in group Group has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 19:37:21,661] INFO [GroupCoordinator 3]: Preparing to rebalance group Group in state PreparingRebalance with old generation 2 (__consumer_offsets-25) (reason: removing member consumer-Group-1-c62454be-d609-4c31-a17b-3f28fd8b2c72 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 19:37:21,661] INFO [GroupCoordinator 3]: Group Group with generation 3 is now empty (__consumer_offsets-25) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 19:44:51,103] INFO [GroupCoordinator 5]: Dynamic member with unknown member id joins group ConsumerGroup_1 in Empty state. Created a new member id consumer-ConsumerGroup_1-5-4d946385-0de2-4198-9d77-cb90952fa6c5 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 19:44:51,105] INFO [GroupCoordinator 5]: Dynamic member with unknown member id joins group ConsumerGroup_1 in Empty state. Created a new member id consumer-ConsumerGroup_1-1-7f8a6944-ad7a-49fb-b726-0144b041eded and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 19:44:51,103] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group ConsumerGroup_2 in Empty state. Created a new member id consumer-ConsumerGroup_2-9-38dff668-1894-431b-bf3a-c7f113cca791 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 19:44:51,113] INFO [GroupCoordinator 5]: Dynamic member with unknown member id joins group ConsumerGroup_1 in Empty state. Created a new member id consumer-ConsumerGroup_1-8-07b94695-b062-4288-861a-52ba2f79856c and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 19:44:51,115] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group ConsumerGroup_2 in Empty state. Created a new member id consumer-ConsumerGroup_2-3-59d1336e-01c7-43a9-8cd0-75bd4c05b2c2 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 19:44:51,117] INFO [GroupCoordinator 5]: Preparing to rebalance group ConsumerGroup_1 in state PreparingRebalance with old generation 0 (__consumer_offsets-21) (reason: Adding new member consumer-ConsumerGroup_1-5-4d946385-0de2-4198-9d77-cb90952fa6c5 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 19:44:51,117] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group ConsumerGroup_2 in Empty state. Created a new member id consumer-ConsumerGroup_2-6-51a8e475-be8a-4617-a336-65a3ddd8e8f9 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 19:44:51,120] INFO [GroupCoordinator 0]: Preparing to rebalance group ConsumerGroup_2 in state PreparingRebalance with old generation 0 (__consumer_offsets-20) (reason: Adding new member consumer-ConsumerGroup_2-9-38dff668-1894-431b-bf3a-c7f113cca791 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 19:44:51,121] INFO [GroupCoordinator 5]: Stabilized group ConsumerGroup_1 generation 1 (__consumer_offsets-21) with 3 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 19:44:51,126] INFO [GroupCoordinator 0]: Stabilized group ConsumerGroup_2 generation 1 (__consumer_offsets-20) with 3 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 19:44:51,122] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group ConsumerGroup_0 in Empty state. Created a new member id consumer-ConsumerGroup_0-2-fed56165-b3af-4828-94c5-2cf0bad85440 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 19:44:51,138] INFO [GroupCoordinator 5]: Assignment received from leader consumer-ConsumerGroup_1-5-4d946385-0de2-4198-9d77-cb90952fa6c5 for group ConsumerGroup_1 for generation 1. The group has 3 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 19:44:51,138] INFO [GroupCoordinator 0]: Assignment received from leader consumer-ConsumerGroup_2-9-38dff668-1894-431b-bf3a-c7f113cca791 for group ConsumerGroup_2 for generation 1. The group has 3 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 19:44:51,144] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group ConsumerGroup_0 in Empty state. Created a new member id consumer-ConsumerGroup_0-4-4a05e33b-104c-4ff7-a1b1-63b5d638d368 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 19:44:51,146] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group ConsumerGroup_0 in Empty state. Created a new member id consumer-ConsumerGroup_0-7-253d3714-80c0-4df0-9611-09bb4c80f377 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 19:44:51,163] INFO [GroupCoordinator 1]: Preparing to rebalance group ConsumerGroup_0 in state PreparingRebalance with old generation 0 (__consumer_offsets-22) (reason: Adding new member consumer-ConsumerGroup_0-2-fed56165-b3af-4828-94c5-2cf0bad85440 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 19:44:51,193] INFO [GroupCoordinator 1]: Stabilized group ConsumerGroup_0 generation 1 (__consumer_offsets-22) with 3 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 19:44:51,210] INFO [GroupCoordinator 1]: Assignment received from leader consumer-ConsumerGroup_0-2-fed56165-b3af-4828-94c5-2cf0bad85440 for group ConsumerGroup_0 for generation 1. The group has 3 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 19:46:44,367] INFO [GroupCoordinator 5]: Member consumer-ConsumerGroup_1-5-4d946385-0de2-4198-9d77-cb90952fa6c5 in group ConsumerGroup_1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 19:46:44,367] INFO [GroupCoordinator 0]: Member consumer-ConsumerGroup_2-6-51a8e475-be8a-4617-a336-65a3ddd8e8f9 in group ConsumerGroup_2 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 19:46:44,368] INFO [GroupCoordinator 0]: Preparing to rebalance group ConsumerGroup_2 in state PreparingRebalance with old generation 1 (__consumer_offsets-20) (reason: removing member consumer-ConsumerGroup_2-6-51a8e475-be8a-4617-a336-65a3ddd8e8f9 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 19:46:44,369] INFO [GroupCoordinator 1]: Member consumer-ConsumerGroup_0-7-253d3714-80c0-4df0-9611-09bb4c80f377 in group ConsumerGroup_0 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 19:46:44,368] INFO [GroupCoordinator 5]: Preparing to rebalance group ConsumerGroup_1 in state PreparingRebalance with old generation 1 (__consumer_offsets-21) (reason: removing member consumer-ConsumerGroup_1-5-4d946385-0de2-4198-9d77-cb90952fa6c5 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 19:46:44,369] INFO [GroupCoordinator 0]: Member consumer-ConsumerGroup_2-9-38dff668-1894-431b-bf3a-c7f113cca791 in group ConsumerGroup_2 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 19:46:44,370] INFO [GroupCoordinator 1]: Preparing to rebalance group ConsumerGroup_0 in state PreparingRebalance with old generation 1 (__consumer_offsets-22) (reason: removing member consumer-ConsumerGroup_0-7-253d3714-80c0-4df0-9611-09bb4c80f377 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 19:46:44,386] INFO [GroupCoordinator 1]: Member consumer-ConsumerGroup_0-4-4a05e33b-104c-4ff7-a1b1-63b5d638d368 in group ConsumerGroup_0 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 19:46:44,383] INFO [GroupCoordinator 5]: Member consumer-ConsumerGroup_1-8-07b94695-b062-4288-861a-52ba2f79856c in group ConsumerGroup_1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 19:46:44,398] INFO [GroupCoordinator 0]: Member consumer-ConsumerGroup_2-3-59d1336e-01c7-43a9-8cd0-75bd4c05b2c2 in group ConsumerGroup_2 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 19:46:44,398] INFO [GroupCoordinator 1]: Member consumer-ConsumerGroup_0-2-fed56165-b3af-4828-94c5-2cf0bad85440 in group ConsumerGroup_0 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 19:46:44,398] INFO [GroupCoordinator 5]: Member consumer-ConsumerGroup_1-1-7f8a6944-ad7a-49fb-b726-0144b041eded in group ConsumerGroup_1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 19:46:44,400] INFO [GroupCoordinator 0]: Group ConsumerGroup_2 with generation 2 is now empty (__consumer_offsets-20) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 19:46:44,400] INFO [GroupCoordinator 5]: Group ConsumerGroup_1 with generation 2 is now empty (__consumer_offsets-21) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 19:46:44,401] INFO [GroupCoordinator 1]: Group ConsumerGroup_0 with generation 2 is now empty (__consumer_offsets-22) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:43:53,823] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:43:53,831] WARN config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:43:53,834] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:43:53,834] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:43:53,834] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:43:53,834] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:43:53,842] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 20:43:53,842] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 20:43:53,842] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 20:43:53,842] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2022-05-15 20:43:53,842] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2022-05-15 20:43:53,853] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:43:53,853] WARN config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:43:53,853] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:43:53,853] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:43:53,853] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:43:53,853] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:43:53,853] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2022-05-15 20:43:53,864] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@2cd2a21f (org.apache.zookeeper.server.ServerMetrics)
[2022-05-15 20:43:53,864] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-15 20:43:53,876] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:43:53,876] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:43:53,876] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:43:53,876] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:43:53,876] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:43:53,876] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:43:53,882] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:43:53,883] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:43:53,883] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:43:53,883] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:44:07,275] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 20:44:07,461] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 20:44:07,782] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 20:44:07,791] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 20:44:07,830] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 20:44:07,968] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 20:44:08,103] INFO starting (kafka.server.KafkaServer)
[2022-05-15 20:44:08,105] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 20:44:08,127] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 20:44:08,177] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 20:44:08,289] INFO starting (kafka.server.KafkaServer)
[2022-05-15 20:44:08,290] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 20:44:08,312] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 20:44:08,377] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 20:44:08,390] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 20:44:08,409] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 20:44:08,490] INFO starting (kafka.server.KafkaServer)
[2022-05-15 20:44:08,491] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 20:44:08,502] INFO starting (kafka.server.KafkaServer)
[2022-05-15 20:44:08,502] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 20:44:08,509] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 20:44:08,516] INFO starting (kafka.server.KafkaServer)
[2022-05-15 20:44:08,517] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 20:44:08,524] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 20:44:08,533] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 20:44:12,674] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:12,674] INFO Client environment:host.name=LAPTOP-S01N1QNU (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:12,674] INFO Client environment:java.version=11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:12,674] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:12,674] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:12,674] INFO Client environment:java.class.path=C:\Users\joaoc\Documents\kafka\kfk\libs\activation-1.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\aopalliance-repackaged-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\argparse4j-0.7.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\audience-annotations-0.5.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-cli-1.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-lang3-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-basic-auth-extension-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-file-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-json-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-client-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-runtime-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-transforms-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-api-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-locator-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-utils-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-core-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-databind-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-dataformat-csv-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-datatype-jdk8-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-base-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-json-provider-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-jaxb-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-scala_2.12-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.activation-api-1.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.annotation-api-1.3.5.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.inject-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.validation-api-2.0.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javassist-3.27.0-GA.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.servlet-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jaxb-api-2.3.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-client-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-common-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-core-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-hk2-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-server-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-client-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-continuation-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-http-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-io-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-security-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-server-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlet-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlets-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-ajax-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jline-3.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jopt-simple-5.0.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jose4j-0.7.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-clients-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-log4j-appender-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-metadata-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-raft-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-server-common-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-shell-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-examples-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-scala_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-test-utils-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-tools-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\log4j-1.2.17.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\lz4-java-1.8.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\maven-artifact-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-2.2.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-4.1.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-buffer-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-codec-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-handler-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-resolver-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-epoll-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-unix-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\osgi-resource-locator-1.0.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\paranamer-2.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\plexus-utils-3.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\reflections-0.9.12.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\rocksdbjni-6.22.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-collection-compat_2.12-2.4.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-java8-compat_2.12-1.0.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-library-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-logging_2.12-3.9.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-reflect-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-api-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-log4j12-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\snappy-java-1.1.8.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\trogdor-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-jute-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:12,676] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.10\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.10\bin;C:\Program Files\apache-maven-3.6.3\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\sox-14-4-2;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\dotnet\;C:\Users\joaoc\Downloads\apache-zookeeper-3.8.0-bin\bin;C:\Program Files\swipl\bin;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\Scripts\;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\;C:\Users\joaoc\AppData\Local\Microsoft\WindowsApps;C:\Users\joaoc\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\joaoc\AppData\Local\Programs\Julia-1.6.0\bin;C:\Users\joaoc\.dotnet\tools;. (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:12,676] INFO Client environment:java.io.tmpdir=C:\Users\joaoc\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:12,677] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:12,678] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:12,678] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:12,678] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:12,679] INFO Client environment:user.name=joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:12,679] INFO Client environment:user.home=C:\Users\joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:12,679] INFO Client environment:user.dir=C:\Users\joaoc\Documents\kafka\kfk (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:12,680] INFO Client environment:os.memory.free=1010MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:12,680] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:12,680] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:12,683] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2c5529ab (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:12,694] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 20:44:12,698] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:44:12,701] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 20:44:12,705] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:44:12,707] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:44:12,709] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:61548, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:44:12,722] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, session id = 0x100014535cf0006, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:44:12,727] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 20:44:12,807] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 20:44:12,928] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 20:44:12,933] INFO Cluster ID = 4MmEBXr9QB6Y66VgsTj6SQ (kafka.server.KafkaServer)
[2022-05-15 20:44:13,001] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 20:44:13,012] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 20:44:13,044] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:44:13,050] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:44:13,052] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:44:13,054] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:44:13,065] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:13,065] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:13,065] INFO Client environment:host.name=LAPTOP-S01N1QNU (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:13,065] INFO Client environment:host.name=LAPTOP-S01N1QNU (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:13,066] INFO Client environment:java.version=11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:13,066] INFO Client environment:java.version=11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:13,066] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:13,066] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:13,067] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:13,067] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:13,067] INFO Client environment:java.class.path=C:\Users\joaoc\Documents\kafka\kfk\libs\activation-1.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\aopalliance-repackaged-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\argparse4j-0.7.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\audience-annotations-0.5.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-cli-1.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-lang3-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-basic-auth-extension-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-file-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-json-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-client-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-runtime-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-transforms-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-api-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-locator-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-utils-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-core-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-databind-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-dataformat-csv-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-datatype-jdk8-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-base-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-json-provider-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-jaxb-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-scala_2.12-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.activation-api-1.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.annotation-api-1.3.5.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.inject-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.validation-api-2.0.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javassist-3.27.0-GA.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.servlet-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jaxb-api-2.3.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-client-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-common-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-core-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-hk2-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-server-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-client-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-continuation-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-http-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-io-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-security-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-server-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlet-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlets-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-ajax-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jline-3.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jopt-simple-5.0.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jose4j-0.7.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-clients-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-log4j-appender-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-metadata-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-raft-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-server-common-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-shell-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-examples-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-scala_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-test-utils-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-tools-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\log4j-1.2.17.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\lz4-java-1.8.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\maven-artifact-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-2.2.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-4.1.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-buffer-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-codec-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-handler-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-resolver-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-epoll-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-unix-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\osgi-resource-locator-1.0.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\paranamer-2.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\plexus-utils-3.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\reflections-0.9.12.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\rocksdbjni-6.22.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-collection-compat_2.12-2.4.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-java8-compat_2.12-1.0.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-library-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-logging_2.12-3.9.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-reflect-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-api-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-log4j12-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\snappy-java-1.1.8.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\trogdor-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-jute-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:13,067] INFO Client environment:java.class.path=C:\Users\joaoc\Documents\kafka\kfk\libs\activation-1.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\aopalliance-repackaged-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\argparse4j-0.7.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\audience-annotations-0.5.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-cli-1.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-lang3-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-basic-auth-extension-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-file-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-json-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-client-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-runtime-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-transforms-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-api-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-locator-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-utils-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-core-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-databind-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-dataformat-csv-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-datatype-jdk8-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-base-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-json-provider-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-jaxb-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-scala_2.12-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.activation-api-1.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.annotation-api-1.3.5.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.inject-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.validation-api-2.0.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javassist-3.27.0-GA.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.servlet-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jaxb-api-2.3.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-client-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-common-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-core-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-hk2-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-server-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-client-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-continuation-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-http-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-io-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-security-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-server-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlet-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlets-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-ajax-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jline-3.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jopt-simple-5.0.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jose4j-0.7.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-clients-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-log4j-appender-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-metadata-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-raft-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-server-common-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-shell-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-examples-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-scala_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-test-utils-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-tools-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\log4j-1.2.17.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\lz4-java-1.8.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\maven-artifact-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-2.2.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-4.1.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-buffer-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-codec-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-handler-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-resolver-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-epoll-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-unix-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\osgi-resource-locator-1.0.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\paranamer-2.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\plexus-utils-3.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\reflections-0.9.12.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\rocksdbjni-6.22.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-collection-compat_2.12-2.4.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-java8-compat_2.12-1.0.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-library-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-logging_2.12-3.9.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-reflect-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-api-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-log4j12-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\snappy-java-1.1.8.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\trogdor-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-jute-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:13,068] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.10\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.10\bin;C:\Program Files\apache-maven-3.6.3\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\sox-14-4-2;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\dotnet\;C:\Users\joaoc\Downloads\apache-zookeeper-3.8.0-bin\bin;C:\Program Files\swipl\bin;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\Scripts\;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\;C:\Users\joaoc\AppData\Local\Microsoft\WindowsApps;C:\Users\joaoc\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\joaoc\AppData\Local\Programs\Julia-1.6.0\bin;C:\Users\joaoc\.dotnet\tools;. (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:13,069] INFO Client environment:java.io.tmpdir=C:\Users\joaoc\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:13,068] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.10\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.10\bin;C:\Program Files\apache-maven-3.6.3\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\sox-14-4-2;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\dotnet\;C:\Users\joaoc\Downloads\apache-zookeeper-3.8.0-bin\bin;C:\Program Files\swipl\bin;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\Scripts\;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\;C:\Users\joaoc\AppData\Local\Microsoft\WindowsApps;C:\Users\joaoc\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\joaoc\AppData\Local\Programs\Julia-1.6.0\bin;C:\Users\joaoc\.dotnet\tools;. (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:13,071] INFO Client environment:java.io.tmpdir=C:\Users\joaoc\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:13,071] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:13,073] ERROR [KafkaServer id=1] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.kafka.common.KafkaException: Failed to acquire lock on file .lock in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager.$anonfun$lockLogDirs$1(LogManager.scala:241)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:293)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:293)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:290)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:236)
	at kafka.log.LogManager.<init>(LogManager.scala:112)
	at kafka.log.LogManager$.apply(LogManager.scala:1315)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:259)
	at kafka.Kafka$.main(Kafka.scala:109)
	at kafka.Kafka.main(Kafka.scala)
[2022-05-15 20:44:13,073] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:13,073] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:13,075] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2022-05-15 20:44:13,075] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:13,075] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:13,077] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:13,077] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:13,078] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:13,079] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 20:44:13,079] INFO Client environment:user.name=joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:13,079] INFO Client environment:user.name=joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:13,080] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 20:44:13,081] INFO Client environment:user.home=C:\Users\joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:13,084] INFO Client environment:user.dir=C:\Users\joaoc\Documents\kafka\kfk (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:13,085] INFO Client environment:os.memory.free=1009MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:13,085] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:13,080] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 20:44:13,081] INFO Client environment:user.home=C:\Users\joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:13,086] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:13,083] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 20:44:13,087] INFO Client environment:user.dir=C:\Users\joaoc\Documents\kafka\kfk (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:13,088] INFO Client environment:os.memory.free=1010MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:13,090] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2c5529ab (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:13,089] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:13,090] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:13,093] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@39a8312f (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:13,101] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 20:44:13,107] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 20:44:13,108] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:44:13,110] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 20:44:13,113] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:44:13,116] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 20:44:13,117] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:44:13,118] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:44:13,120] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:61553, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:44:13,122] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:44:13,123] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:44:13,125] INFO Socket connection established, initiating session, client: /127.0.0.1:61554, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:44:13,128] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, session id = 0x100014535cf0007, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:44:13,133] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 20:44:13,134] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100014535cf0008, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:44:13,138] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 20:44:13,217] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 20:44:13,220] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 20:44:13,221] INFO Session: 0x100014535cf0006 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:13,221] INFO EventThread shut down for session: 0x100014535cf0006 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:44:13,224] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 20:44:13,227] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:44:13,361] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 20:44:13,367] INFO Cluster ID = 4MmEBXr9QB6Y66VgsTj6SQ (kafka.server.KafkaServer)
[2022-05-15 20:44:13,367] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 20:44:13,374] INFO Cluster ID = 4MmEBXr9QB6Y66VgsTj6SQ (kafka.server.KafkaServer)
[2022-05-15 20:44:13,443] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs6
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 20:44:13,447] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 20:44:13,457] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs6
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 20:44:13,462] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 20:44:13,497] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:44:13,497] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:44:13,504] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:44:13,504] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:44:13,506] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:44:13,506] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:44:13,508] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:44:13,508] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:44:13,527] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.kafka.common.KafkaException: Failed to acquire lock on file .lock in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager.$anonfun$lockLogDirs$1(LogManager.scala:241)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:293)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:293)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:290)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:236)
	at kafka.log.LogManager.<init>(LogManager.scala:112)
	at kafka.log.LogManager$.apply(LogManager.scala:1315)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:259)
	at kafka.Kafka$.main(Kafka.scala:109)
	at kafka.Kafka.main(Kafka.scala)
[2022-05-15 20:44:13,530] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2022-05-15 20:44:13,532] ERROR [KafkaServer id=5] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.kafka.common.KafkaException: Failed to acquire lock on file .lock in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager.$anonfun$lockLogDirs$1(LogManager.scala:241)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:293)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:293)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:290)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:236)
	at kafka.log.LogManager.<init>(LogManager.scala:112)
	at kafka.log.LogManager$.apply(LogManager.scala:1315)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:259)
	at kafka.Kafka$.main(Kafka.scala:109)
	at kafka.Kafka.main(Kafka.scala)
[2022-05-15 20:44:13,535] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 20:44:13,539] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 20:44:13,539] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 20:44:13,537] INFO [KafkaServer id=5] shutting down (kafka.server.KafkaServer)
[2022-05-15 20:44:13,541] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 20:44:13,545] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 20:44:13,546] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 20:44:13,546] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 20:44:13,548] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 20:44:13,661] INFO Session: 0x100014535cf0007 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:13,661] INFO Session: 0x100014535cf0008 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:44:13,661] INFO EventThread shut down for session: 0x100014535cf0007 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:44:13,661] INFO EventThread shut down for session: 0x100014535cf0008 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:44:13,663] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 20:44:13,666] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:44:13,663] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 20:44:13,667] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:44:14,065] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:44:14,065] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:44:14,067] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:44:14,520] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:44:14,520] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:44:14,520] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:44:14,520] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:44:14,522] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:44:14,531] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:44:15,080] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:44:15,080] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:44:15,082] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:44:15,534] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:44:15,534] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:44:15,534] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:44:15,534] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:44:15,538] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:44:15,538] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:44:16,082] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:44:16,082] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:44:16,084] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:44:16,542] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:44:16,542] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:44:16,542] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:44:16,542] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:44:16,542] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:44:16,542] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:44:17,102] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:44:17,102] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:44:17,104] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 20:44:17,104] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 20:44:17,104] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 20:44:17,104] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 20:44:17,112] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 20:44:17,112] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2022-05-15 20:44:17,112] ERROR Exiting Kafka. (kafka.Kafka$)
[2022-05-15 20:44:17,112] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2022-05-15 20:44:17,562] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:44:17,562] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:44:17,562] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:44:17,562] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:44:17,566] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 20:44:17,566] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 20:44:17,566] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 20:44:17,566] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 20:44:17,566] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 20:44:17,566] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 20:44:17,572] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 20:44:17,572] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 20:44:17,573] INFO App info kafka.server for 5 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 20:44:17,573] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 20:44:17,573] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2022-05-15 20:44:17,573] INFO [KafkaServer id=5] shut down completed (kafka.server.KafkaServer)
[2022-05-15 20:44:17,573] ERROR Exiting Kafka. (kafka.Kafka$)
[2022-05-15 20:44:17,573] ERROR Exiting Kafka. (kafka.Kafka$)
[2022-05-15 20:44:17,602] INFO [KafkaServer id=5] shutting down (kafka.server.KafkaServer)
[2022-05-15 20:44:17,602] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2022-05-15 20:44:18,532] WARN Close of session 0x100014535cf0000 (org.apache.zookeeper.server.NIOServerCnxn)
java.io.IOException: An existing connection was forcibly closed by the remote host
	at java.base/sun.nio.ch.SocketDispatcher.read0(Native Method)
	at java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:245)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:324)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:522)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:154)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
[2022-05-15 20:44:18,554] WARN Close of session 0x100014535cf0004 (org.apache.zookeeper.server.NIOServerCnxn)
java.io.IOException: An existing connection was forcibly closed by the remote host
	at java.base/sun.nio.ch.SocketDispatcher.read0(Native Method)
	at java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:245)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:324)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:522)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:154)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
[2022-05-15 20:44:18,554] WARN Close of session 0x100014535cf0005 (org.apache.zookeeper.server.NIOServerCnxn)
java.io.IOException: An existing connection was forcibly closed by the remote host
	at java.base/sun.nio.ch.SocketDispatcher.read0(Native Method)
	at java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:245)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:324)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:522)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:154)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
[2022-05-15 20:44:18,544] WARN Close of session 0x100014535cf0002 (org.apache.zookeeper.server.NIOServerCnxn)
java.io.IOException: An existing connection was forcibly closed by the remote host
	at java.base/sun.nio.ch.SocketDispatcher.read0(Native Method)
	at java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:245)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:324)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:522)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:154)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
[2022-05-15 20:44:18,544] WARN Close of session 0x100014535cf0003 (org.apache.zookeeper.server.NIOServerCnxn)
java.io.IOException: An existing connection was forcibly closed by the remote host
	at java.base/sun.nio.ch.SocketDispatcher.read0(Native Method)
	at java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:245)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:324)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:522)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:154)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
[2022-05-15 20:44:18,541] WARN Close of session 0x100014535cf0001 (org.apache.zookeeper.server.NIOServerCnxn)
java.io.IOException: An existing connection was forcibly closed by the remote host
	at java.base/sun.nio.ch.SocketDispatcher.read0(Native Method)
	at java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:245)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:324)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:522)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:154)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
[2022-05-15 20:44:57,266] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:44:57,266] WARN config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:44:57,274] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:44:57,274] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:44:57,274] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:44:57,274] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:44:57,274] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 20:44:57,274] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 20:44:57,274] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 20:44:57,274] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2022-05-15 20:44:57,282] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2022-05-15 20:44:57,293] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:44:57,293] WARN config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:44:57,293] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:44:57,293] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:44:57,293] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:44:57,293] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:44:57,293] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2022-05-15 20:44:57,302] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@62230c58 (org.apache.zookeeper.server.ServerMetrics)
[2022-05-15 20:44:57,306] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-15 20:44:57,313] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:44:57,313] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:44:57,313] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:44:57,313] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:44:57,313] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:44:57,313] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:44:57,313] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:44:57,313] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:44:57,313] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:44:57,322] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:45:01,857] INFO Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:45:01,857] INFO Server environment:host.name=LAPTOP-S01N1QNU (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:45:01,861] INFO Server environment:java.version=11.0.10 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:45:01,862] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:45:01,866] INFO Server environment:java.home=C:\Program Files\Java\jdk-11.0.10 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:45:01,868] INFO Server environment:java.class.path=C:\Users\joaoc\Documents\kafka\kfk\libs\activation-1.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\aopalliance-repackaged-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\argparse4j-0.7.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\audience-annotations-0.5.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-cli-1.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-lang3-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-basic-auth-extension-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-file-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-json-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-client-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-runtime-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-transforms-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-api-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-locator-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-utils-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-core-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-databind-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-dataformat-csv-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-datatype-jdk8-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-base-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-json-provider-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-jaxb-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-scala_2.12-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.activation-api-1.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.annotation-api-1.3.5.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.inject-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.validation-api-2.0.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javassist-3.27.0-GA.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.servlet-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jaxb-api-2.3.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-client-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-common-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-core-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-hk2-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-server-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-client-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-continuation-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-http-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-io-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-security-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-server-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlet-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlets-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-ajax-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jline-3.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jopt-simple-5.0.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jose4j-0.7.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-clients-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-log4j-appender-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-metadata-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-raft-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-server-common-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-shell-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-examples-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-scala_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-test-utils-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-tools-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\log4j-1.2.17.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\lz4-java-1.8.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\maven-artifact-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-2.2.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-4.1.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-buffer-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-codec-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-handler-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-resolver-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-epoll-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-unix-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\osgi-resource-locator-1.0.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\paranamer-2.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\plexus-utils-3.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\reflections-0.9.12.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\rocksdbjni-6.22.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-collection-compat_2.12-2.4.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-java8-compat_2.12-1.0.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-library-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-logging_2.12-3.9.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-reflect-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-api-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-log4j12-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\snappy-java-1.1.8.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\trogdor-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-jute-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:45:01,869] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-11.0.10\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.10\bin;C:\Program Files\apache-maven-3.6.3\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\sox-14-4-2;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\dotnet\;C:\Users\joaoc\Downloads\apache-zookeeper-3.8.0-bin\bin;C:\Program Files\swipl\bin;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\Scripts\;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\;C:\Users\joaoc\AppData\Local\Microsoft\WindowsApps;C:\Users\joaoc\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\joaoc\AppData\Local\Programs\Julia-1.6.0\bin;C:\Users\joaoc\.dotnet\tools;. (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:45:01,869] INFO Server environment:java.io.tmpdir=C:\Users\joaoc\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:45:01,870] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:45:01,870] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:45:01,871] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:45:01,883] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:45:01,887] INFO Server environment:user.name=joaoc (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:45:01,888] INFO Server environment:user.home=C:\Users\joaoc (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:45:01,889] INFO Server environment:user.dir=C:\Users\joaoc\Documents\kafka\kfk (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:45:01,892] INFO Server environment:os.memory.free=489MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:45:01,893] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:45:01,914] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:45:01,916] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:45:01,918] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:45:01,919] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:45:01,919] INFO zookeeper.flushDelay=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:45:01,920] INFO zookeeper.maxWriteQueuePollTime=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:45:01,943] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:45:01,945] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:45:01,949] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2022-05-15 20:45:01,951] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:45:01,952] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:45:01,976] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-15 20:45:01,982] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-15 20:45:01,990] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 20:45:01,991] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 20:45:01,995] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 20:45:01,997] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 20:45:02,005] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 20:45:02,008] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 20:45:02,016] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:45:02,017] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:45:02,023] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 clientPortListenBacklog -1 datadir C:\Users\joaoc\Documents\kafka\kfk\zookeeper\version-2 snapdir C:\Users\joaoc\Documents\kafka\kfk\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:45:02,062] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-15 20:45:02,064] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-15 20:45:02,072] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-15 20:45:02,082] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-15 20:45:02,130] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2022-05-15 20:45:02,130] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2022-05-15 20:45:02,135] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-15 20:45:02,136] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-15 20:45:02,148] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2022-05-15 20:45:02,149] INFO Snapshotting: 0x0 to C:\Users\joaoc\Documents\kafka\kfk\zookeeper\version-2\snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-15 20:45:02,155] INFO Snapshot loaded in 19 ms, highest zxid is 0x0, digest is 1371985504 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-15 20:45:02,156] INFO Snapshotting: 0x0 to C:\Users\joaoc\Documents\kafka\kfk\zookeeper\version-2\snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-15 20:45:02,159] INFO Snapshot taken in 3 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:45:02,176] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2022-05-15 20:45:02,177] INFO zookeeper.request_throttler.shutdownTimeout = 10000 (org.apache.zookeeper.server.RequestThrottler)
[2022-05-15 20:45:02,202] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2022-05-15 20:45:02,204] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2022-05-15 20:45:04,257] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 20:45:04,284] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 20:45:04,316] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 20:45:04,321] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 20:45:04,323] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 20:45:04,346] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 20:45:04,869] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 20:45:04,891] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 20:45:04,894] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 20:45:04,916] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 20:45:04,920] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 20:45:04,956] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 20:45:05,037] INFO starting (kafka.server.KafkaServer)
[2022-05-15 20:45:05,038] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 20:45:05,054] INFO starting (kafka.server.KafkaServer)
[2022-05-15 20:45:05,054] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 20:45:05,056] INFO starting (kafka.server.KafkaServer)
[2022-05-15 20:45:05,057] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 20:45:05,061] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 20:45:05,069] INFO starting (kafka.server.KafkaServer)
[2022-05-15 20:45:05,070] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 20:45:05,074] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 20:45:05,075] INFO starting (kafka.server.KafkaServer)
[2022-05-15 20:45:05,076] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 20:45:05,080] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 20:45:05,093] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 20:45:05,096] INFO starting (kafka.server.KafkaServer)
[2022-05-15 20:45:05,096] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 20:45:05,097] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 20:45:05,113] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 20:45:09,619] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,619] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,619] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,620] INFO Client environment:host.name=LAPTOP-S01N1QNU (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,620] INFO Client environment:host.name=LAPTOP-S01N1QNU (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,620] INFO Client environment:host.name=LAPTOP-S01N1QNU (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,620] INFO Client environment:java.version=11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,620] INFO Client environment:java.version=11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,620] INFO Client environment:java.version=11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,620] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,621] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,621] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,621] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,621] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,621] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,621] INFO Client environment:java.class.path=C:\Users\joaoc\Documents\kafka\kfk\libs\activation-1.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\aopalliance-repackaged-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\argparse4j-0.7.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\audience-annotations-0.5.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-cli-1.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-lang3-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-basic-auth-extension-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-file-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-json-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-client-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-runtime-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-transforms-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-api-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-locator-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-utils-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-core-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-databind-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-dataformat-csv-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-datatype-jdk8-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-base-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-json-provider-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-jaxb-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-scala_2.12-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.activation-api-1.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.annotation-api-1.3.5.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.inject-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.validation-api-2.0.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javassist-3.27.0-GA.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.servlet-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jaxb-api-2.3.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-client-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-common-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-core-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-hk2-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-server-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-client-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-continuation-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-http-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-io-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-security-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-server-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlet-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlets-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-ajax-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jline-3.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jopt-simple-5.0.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jose4j-0.7.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-clients-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-log4j-appender-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-metadata-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-raft-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-server-common-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-shell-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-examples-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-scala_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-test-utils-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-tools-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\log4j-1.2.17.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\lz4-java-1.8.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\maven-artifact-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-2.2.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-4.1.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-buffer-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-codec-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-handler-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-resolver-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-epoll-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-unix-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\osgi-resource-locator-1.0.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\paranamer-2.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\plexus-utils-3.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\reflections-0.9.12.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\rocksdbjni-6.22.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-collection-compat_2.12-2.4.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-java8-compat_2.12-1.0.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-library-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-logging_2.12-3.9.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-reflect-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-api-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-log4j12-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\snappy-java-1.1.8.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\trogdor-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-jute-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,621] INFO Client environment:java.class.path=C:\Users\joaoc\Documents\kafka\kfk\libs\activation-1.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\aopalliance-repackaged-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\argparse4j-0.7.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\audience-annotations-0.5.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-cli-1.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-lang3-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-basic-auth-extension-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-file-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-json-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-client-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-runtime-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-transforms-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-api-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-locator-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-utils-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-core-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-databind-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-dataformat-csv-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-datatype-jdk8-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-base-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-json-provider-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-jaxb-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-scala_2.12-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.activation-api-1.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.annotation-api-1.3.5.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.inject-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.validation-api-2.0.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javassist-3.27.0-GA.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.servlet-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jaxb-api-2.3.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-client-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-common-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-core-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-hk2-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-server-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-client-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-continuation-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-http-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-io-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-security-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-server-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlet-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlets-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-ajax-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jline-3.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jopt-simple-5.0.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jose4j-0.7.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-clients-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-log4j-appender-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-metadata-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-raft-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-server-common-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-shell-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-examples-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-scala_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-test-utils-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-tools-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\log4j-1.2.17.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\lz4-java-1.8.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\maven-artifact-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-2.2.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-4.1.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-buffer-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-codec-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-handler-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-resolver-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-epoll-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-unix-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\osgi-resource-locator-1.0.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\paranamer-2.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\plexus-utils-3.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\reflections-0.9.12.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\rocksdbjni-6.22.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-collection-compat_2.12-2.4.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-java8-compat_2.12-1.0.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-library-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-logging_2.12-3.9.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-reflect-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-api-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-log4j12-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\snappy-java-1.1.8.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\trogdor-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-jute-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,621] INFO Client environment:java.class.path=C:\Users\joaoc\Documents\kafka\kfk\libs\activation-1.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\aopalliance-repackaged-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\argparse4j-0.7.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\audience-annotations-0.5.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-cli-1.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-lang3-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-basic-auth-extension-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-file-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-json-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-client-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-runtime-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-transforms-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-api-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-locator-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-utils-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-core-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-databind-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-dataformat-csv-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-datatype-jdk8-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-base-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-json-provider-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-jaxb-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-scala_2.12-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.activation-api-1.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.annotation-api-1.3.5.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.inject-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.validation-api-2.0.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javassist-3.27.0-GA.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.servlet-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jaxb-api-2.3.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-client-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-common-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-core-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-hk2-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-server-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-client-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-continuation-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-http-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-io-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-security-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-server-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlet-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlets-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-ajax-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jline-3.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jopt-simple-5.0.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jose4j-0.7.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-clients-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-log4j-appender-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-metadata-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-raft-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-server-common-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-shell-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-examples-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-scala_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-test-utils-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-tools-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\log4j-1.2.17.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\lz4-java-1.8.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\maven-artifact-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-2.2.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-4.1.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-buffer-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-codec-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-handler-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-resolver-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-epoll-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-unix-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\osgi-resource-locator-1.0.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\paranamer-2.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\plexus-utils-3.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\reflections-0.9.12.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\rocksdbjni-6.22.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-collection-compat_2.12-2.4.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-java8-compat_2.12-1.0.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-library-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-logging_2.12-3.9.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-reflect-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-api-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-log4j12-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\snappy-java-1.1.8.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\trogdor-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-jute-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,622] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.10\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.10\bin;C:\Program Files\apache-maven-3.6.3\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\sox-14-4-2;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\dotnet\;C:\Users\joaoc\Downloads\apache-zookeeper-3.8.0-bin\bin;C:\Program Files\swipl\bin;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\Scripts\;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\;C:\Users\joaoc\AppData\Local\Microsoft\WindowsApps;C:\Users\joaoc\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\joaoc\AppData\Local\Programs\Julia-1.6.0\bin;C:\Users\joaoc\.dotnet\tools;. (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,622] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.10\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.10\bin;C:\Program Files\apache-maven-3.6.3\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\sox-14-4-2;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\dotnet\;C:\Users\joaoc\Downloads\apache-zookeeper-3.8.0-bin\bin;C:\Program Files\swipl\bin;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\Scripts\;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\;C:\Users\joaoc\AppData\Local\Microsoft\WindowsApps;C:\Users\joaoc\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\joaoc\AppData\Local\Programs\Julia-1.6.0\bin;C:\Users\joaoc\.dotnet\tools;. (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,622] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.10\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.10\bin;C:\Program Files\apache-maven-3.6.3\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\sox-14-4-2;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\dotnet\;C:\Users\joaoc\Downloads\apache-zookeeper-3.8.0-bin\bin;C:\Program Files\swipl\bin;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\Scripts\;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\;C:\Users\joaoc\AppData\Local\Microsoft\WindowsApps;C:\Users\joaoc\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\joaoc\AppData\Local\Programs\Julia-1.6.0\bin;C:\Users\joaoc\.dotnet\tools;. (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,624] INFO Client environment:java.io.tmpdir=C:\Users\joaoc\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,624] INFO Client environment:java.io.tmpdir=C:\Users\joaoc\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,624] INFO Client environment:java.io.tmpdir=C:\Users\joaoc\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,626] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,626] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,626] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,634] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,634] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,634] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,642] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,644] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,644] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,644] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,646] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,646] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,646] INFO Client environment:user.name=joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,651] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,651] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,651] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,648] INFO Client environment:user.name=joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,648] INFO Client environment:user.name=joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,651] INFO Client environment:host.name=LAPTOP-S01N1QNU (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,651] INFO Client environment:host.name=LAPTOP-S01N1QNU (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,651] INFO Client environment:host.name=LAPTOP-S01N1QNU (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,655] INFO Client environment:java.version=11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,655] INFO Client environment:java.version=11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,655] INFO Client environment:java.version=11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,655] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,655] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,655] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,655] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,656] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,656] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,648] INFO Client environment:user.home=C:\Users\joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,656] INFO Client environment:java.class.path=C:\Users\joaoc\Documents\kafka\kfk\libs\activation-1.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\aopalliance-repackaged-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\argparse4j-0.7.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\audience-annotations-0.5.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-cli-1.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-lang3-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-basic-auth-extension-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-file-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-json-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-client-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-runtime-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-transforms-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-api-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-locator-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-utils-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-core-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-databind-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-dataformat-csv-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-datatype-jdk8-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-base-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-json-provider-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-jaxb-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-scala_2.12-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.activation-api-1.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.annotation-api-1.3.5.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.inject-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.validation-api-2.0.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javassist-3.27.0-GA.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.servlet-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jaxb-api-2.3.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-client-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-common-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-core-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-hk2-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-server-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-client-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-continuation-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-http-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-io-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-security-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-server-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlet-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlets-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-ajax-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jline-3.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jopt-simple-5.0.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jose4j-0.7.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-clients-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-log4j-appender-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-metadata-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-raft-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-server-common-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-shell-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-examples-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-scala_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-test-utils-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-tools-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\log4j-1.2.17.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\lz4-java-1.8.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\maven-artifact-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-2.2.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-4.1.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-buffer-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-codec-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-handler-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-resolver-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-epoll-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-unix-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\osgi-resource-locator-1.0.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\paranamer-2.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\plexus-utils-3.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\reflections-0.9.12.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\rocksdbjni-6.22.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-collection-compat_2.12-2.4.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-java8-compat_2.12-1.0.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-library-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-logging_2.12-3.9.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-reflect-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-api-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-log4j12-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\snappy-java-1.1.8.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\trogdor-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-jute-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,656] INFO Client environment:java.class.path=C:\Users\joaoc\Documents\kafka\kfk\libs\activation-1.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\aopalliance-repackaged-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\argparse4j-0.7.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\audience-annotations-0.5.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-cli-1.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-lang3-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-basic-auth-extension-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-file-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-json-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-client-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-runtime-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-transforms-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-api-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-locator-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-utils-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-core-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-databind-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-dataformat-csv-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-datatype-jdk8-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-base-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-json-provider-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-jaxb-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-scala_2.12-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.activation-api-1.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.annotation-api-1.3.5.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.inject-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.validation-api-2.0.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javassist-3.27.0-GA.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.servlet-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jaxb-api-2.3.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-client-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-common-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-core-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-hk2-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-server-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-client-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-continuation-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-http-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-io-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-security-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-server-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlet-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlets-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-ajax-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jline-3.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jopt-simple-5.0.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jose4j-0.7.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-clients-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-log4j-appender-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-metadata-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-raft-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-server-common-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-shell-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-examples-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-scala_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-test-utils-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-tools-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\log4j-1.2.17.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\lz4-java-1.8.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\maven-artifact-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-2.2.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-4.1.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-buffer-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-codec-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-handler-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-resolver-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-epoll-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-unix-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\osgi-resource-locator-1.0.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\paranamer-2.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\plexus-utils-3.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\reflections-0.9.12.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\rocksdbjni-6.22.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-collection-compat_2.12-2.4.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-java8-compat_2.12-1.0.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-library-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-logging_2.12-3.9.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-reflect-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-api-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-log4j12-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\snappy-java-1.1.8.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\trogdor-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-jute-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,656] INFO Client environment:java.class.path=C:\Users\joaoc\Documents\kafka\kfk\libs\activation-1.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\aopalliance-repackaged-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\argparse4j-0.7.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\audience-annotations-0.5.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-cli-1.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-lang3-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-basic-auth-extension-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-file-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-json-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-client-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-runtime-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-transforms-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-api-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-locator-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-utils-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-core-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-databind-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-dataformat-csv-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-datatype-jdk8-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-base-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-json-provider-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-jaxb-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-scala_2.12-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.activation-api-1.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.annotation-api-1.3.5.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.inject-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.validation-api-2.0.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javassist-3.27.0-GA.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.servlet-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jaxb-api-2.3.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-client-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-common-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-core-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-hk2-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-server-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-client-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-continuation-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-http-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-io-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-security-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-server-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlet-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlets-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-ajax-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jline-3.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jopt-simple-5.0.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jose4j-0.7.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-clients-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-log4j-appender-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-metadata-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-raft-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-server-common-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-shell-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-examples-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-scala_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-test-utils-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-tools-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\log4j-1.2.17.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\lz4-java-1.8.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\maven-artifact-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-2.2.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-4.1.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-buffer-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-codec-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-handler-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-resolver-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-epoll-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-unix-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\osgi-resource-locator-1.0.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\paranamer-2.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\plexus-utils-3.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\reflections-0.9.12.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\rocksdbjni-6.22.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-collection-compat_2.12-2.4.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-java8-compat_2.12-1.0.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-library-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-logging_2.12-3.9.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-reflect-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-api-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-log4j12-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\snappy-java-1.1.8.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\trogdor-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-jute-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,655] INFO Client environment:user.home=C:\Users\joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,655] INFO Client environment:user.home=C:\Users\joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,657] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.10\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.10\bin;C:\Program Files\apache-maven-3.6.3\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\sox-14-4-2;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\dotnet\;C:\Users\joaoc\Downloads\apache-zookeeper-3.8.0-bin\bin;C:\Program Files\swipl\bin;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\Scripts\;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\;C:\Users\joaoc\AppData\Local\Microsoft\WindowsApps;C:\Users\joaoc\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\joaoc\AppData\Local\Programs\Julia-1.6.0\bin;C:\Users\joaoc\.dotnet\tools;. (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,657] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.10\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.10\bin;C:\Program Files\apache-maven-3.6.3\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\sox-14-4-2;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\dotnet\;C:\Users\joaoc\Downloads\apache-zookeeper-3.8.0-bin\bin;C:\Program Files\swipl\bin;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\Scripts\;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\;C:\Users\joaoc\AppData\Local\Microsoft\WindowsApps;C:\Users\joaoc\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\joaoc\AppData\Local\Programs\Julia-1.6.0\bin;C:\Users\joaoc\.dotnet\tools;. (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,656] INFO Client environment:user.dir=C:\Users\joaoc\Documents\kafka\kfk (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,658] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.10\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.10\bin;C:\Program Files\apache-maven-3.6.3\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\sox-14-4-2;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\dotnet\;C:\Users\joaoc\Downloads\apache-zookeeper-3.8.0-bin\bin;C:\Program Files\swipl\bin;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\Scripts\;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\;C:\Users\joaoc\AppData\Local\Microsoft\WindowsApps;C:\Users\joaoc\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\joaoc\AppData\Local\Programs\Julia-1.6.0\bin;C:\Users\joaoc\.dotnet\tools;. (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,665] INFO Client environment:user.dir=C:\Users\joaoc\Documents\kafka\kfk (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,665] INFO Client environment:user.dir=C:\Users\joaoc\Documents\kafka\kfk (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,666] INFO Client environment:java.io.tmpdir=C:\Users\joaoc\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,666] INFO Client environment:java.io.tmpdir=C:\Users\joaoc\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,666] INFO Client environment:os.memory.free=1010MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,666] INFO Client environment:java.io.tmpdir=C:\Users\joaoc\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,670] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,669] INFO Client environment:os.memory.free=1010MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,670] INFO Client environment:os.memory.free=1009MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,674] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,678] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,679] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,670] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,670] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,673] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,690] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,690] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,690] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,690] INFO Client environment:user.name=joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,682] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,682] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2c5529ab (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,688] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,688] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,683] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,694] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2c5529ab (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,690] INFO Client environment:user.home=C:\Users\joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,694] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,694] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,697] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2c5529ab (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,695] INFO Client environment:user.dir=C:\Users\joaoc\Documents\kafka\kfk (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,707] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 20:45:09,699] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,698] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,704] INFO Client environment:os.memory.free=1010MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,711] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 20:45:09,710] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,709] INFO Client environment:user.name=joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,710] INFO Client environment:user.name=joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,715] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:45:09,720] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:45:09,721] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 20:45:09,715] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,715] INFO Client environment:user.home=C:\Users\joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,720] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 20:45:09,717] INFO Client environment:user.home=C:\Users\joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,723] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 20:45:09,727] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@5f6722d3 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,724] INFO Client environment:user.dir=C:\Users\joaoc\Documents\kafka\kfk (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,730] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:45:09,724] INFO Client environment:user.dir=C:\Users\joaoc\Documents\kafka\kfk (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,735] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 20:45:09,730] INFO Client environment:os.memory.free=1009MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,739] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:45:09,739] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:45:09,732] INFO Client environment:os.memory.free=1009MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,740] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:45:09,740] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,741] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:45:09,741] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,746] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,745] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,752] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 20:45:09,748] INFO Socket connection established, initiating session, client: /127.0.0.1:61583, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:45:09,750] INFO Socket connection established, initiating session, client: /127.0.0.1:61584, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:45:09,758] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2c5529ab (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,759] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2c5529ab (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:45:09,764] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:45:09,769] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 20:45:09,773] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:45:09,776] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2022-05-15 20:45:09,775] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:45:09,783] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:45:09,785] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 20:45:09,785] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 20:45:09,784] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:45:09,787] INFO Socket connection established, initiating session, client: /127.0.0.1:61589, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:45:09,794] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:45:09,793] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:45:09,797] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x10001ab6ebd0001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:45:09,797] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x10001ab6ebd0000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:45:09,797] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:61590, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:45:09,799] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 20:45:09,799] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 20:45:09,804] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 20:45:09,804] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 20:45:09,806] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x10001ab6ebd0002, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:45:09,813] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, session id = 0x10001ab6ebd0003, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:45:09,812] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 20:45:09,818] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 20:45:09,830] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:45:09,832] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:45:09,838] INFO Socket connection established, initiating session, client: /127.0.0.1:61591, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:45:09,847] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:45:09,849] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:45:09,849] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x10001ab6ebd0004, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:45:09,854] INFO Socket connection established, initiating session, client: /127.0.0.1:61592, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:45:09,858] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 20:45:09,877] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x10001ab6ebd0005, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:45:09,883] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 20:45:09,968] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 20:45:09,970] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 20:45:09,972] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 20:45:09,976] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 20:45:09,985] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 20:45:09,990] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
[2022-05-15 20:45:09,990] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
[2022-05-15 20:45:09,990] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
[2022-05-15 20:45:09,995] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
[2022-05-15 20:45:09,991] INFO Cleared cache (kafka.server.FinalizedFeatureCache)
[2022-05-15 20:45:10,002] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
[2022-05-15 20:45:10,008] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 20:45:09,991] INFO Cleared cache (kafka.server.FinalizedFeatureCache)
[2022-05-15 20:45:09,991] INFO Cleared cache (kafka.server.FinalizedFeatureCache)
[2022-05-15 20:45:09,996] INFO Cleared cache (kafka.server.FinalizedFeatureCache)
[2022-05-15 20:45:10,006] INFO Cleared cache (kafka.server.FinalizedFeatureCache)
[2022-05-15 20:45:10,018] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
[2022-05-15 20:45:10,066] INFO Cleared cache (kafka.server.FinalizedFeatureCache)
[2022-05-15 20:45:10,194] INFO Cluster ID = VjwRgKlsTKq_tAzCGEpbPA (kafka.server.KafkaServer)
[2022-05-15 20:45:10,201] WARN No meta.properties file under dir C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-05-15 20:45:10,282] INFO Cluster ID = VjwRgKlsTKq_tAzCGEpbPA (kafka.server.KafkaServer)
[2022-05-15 20:45:10,283] INFO Cluster ID = VjwRgKlsTKq_tAzCGEpbPA (kafka.server.KafkaServer)
[2022-05-15 20:45:10,290] WARN No meta.properties file under dir C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-05-15 20:45:10,290] WARN No meta.properties file under dir C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-05-15 20:45:10,308] INFO Cluster ID = VjwRgKlsTKq_tAzCGEpbPA (kafka.server.KafkaServer)
[2022-05-15 20:45:10,315] INFO Cluster ID = VjwRgKlsTKq_tAzCGEpbPA (kafka.server.KafkaServer)
[2022-05-15 20:45:10,316] WARN No meta.properties file under dir C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-05-15 20:45:10,322] WARN No meta.properties file under dir C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-05-15 20:45:10,353] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 20:45:10,372] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 20:45:10,402] INFO Cluster ID = VjwRgKlsTKq_tAzCGEpbPA (kafka.server.KafkaServer)
[2022-05-15 20:45:10,410] WARN No meta.properties file under dir C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-05-15 20:45:10,452] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:45:10,440] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs6
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.serv[2022-05-15 20:45:10,440] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
er.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 20:45:10,457] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:45:10,457] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:45:10,461] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:45:10,466] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 4
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 20:45:10,472] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs6
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 20:45:10,471] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 20:45:10,495] INFO Log directory C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1 not found, creating it. (kafka.log.LogManager)
[2022-05-15 20:45:10,474] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 3
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 20:45:10,532] INFO Loading logs from log dirs ArrayBuffer(C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1) (kafka.log.LogManager)
[2022-05-15 20:45:10,550] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:45:10,551] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:45:10,495] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 4
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 20:45:10,551] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:45:10,551] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:45:10,543] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 20:45:10,557] INFO Attempting recovery for all logs in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1 since no clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 20:45:10,551] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:45:10,551] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:45:10,533] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 3
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 20:45:10,551] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:45:10,551] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:45:10,566] INFO Log directory C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6 not found, creating it. (kafka.log.LogManager)
[2022-05-15 20:45:10,567] INFO Log directory C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3 not found, creating it. (kafka.log.LogManager)
[2022-05-15 20:45:10,585] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 20:45:10,595] INFO Loaded 0 logs in 46ms. (kafka.log.LogManager)
[2022-05-15 20:45:10,596] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 20:45:10,603] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 20:45:10,607] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:45:10,614] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:45:10,617] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:45:10,626] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:45:10,632] INFO Loading logs from log dirs ArrayBuffer(C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3) (kafka.log.LogManager)
[2022-05-15 20:45:10,638] INFO Loading logs from log dirs ArrayBuffer(C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6) (kafka.log.LogManager)
[2022-05-15 20:45:10,641] INFO Attempting recovery for all logs in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3 since no clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 20:45:10,642] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:45:10,645] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:45:10,646] INFO Attempting recovery for all logs in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6 since no clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 20:45:10,650] INFO Log directory C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5 not found, creating it. (kafka.log.LogManager)
[2022-05-15 20:45:10,666] INFO Loaded 0 logs in 33ms. (kafka.log.LogManager)
[2022-05-15 20:45:10,669] INFO Loaded 0 logs in 30ms. (kafka.log.LogManager)
[2022-05-15 20:45:10,677] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:45:10,663] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:45:10,677] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:45:10,667] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 20:45:10,670] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 20:45:10,688] INFO Loading logs from log dirs ArrayBuffer(C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5) (kafka.log.LogManager)
[2022-05-15 20:45:10,677] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:45:10,691] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:45:10,685] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 20:45:10,686] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 20:45:10,696] INFO Attempting recovery for all logs in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5 since no clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 20:45:10,691] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:45:10,697] INFO Log directory C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4 not found, creating it. (kafka.log.LogManager)
[2022-05-15 20:45:10,720] INFO Loaded 0 logs in 31ms. (kafka.log.LogManager)
[2022-05-15 20:45:10,715] INFO Log directory C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2 not found, creating it. (kafka.log.LogManager)
[2022-05-15 20:45:10,728] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 20:45:10,738] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 20:45:10,778] INFO Loading logs from log dirs ArrayBuffer(C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4) (kafka.log.LogManager)
[2022-05-15 20:45:10,789] INFO Attempting recovery for all logs in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4 since no clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 20:45:10,792] INFO Loading logs from log dirs ArrayBuffer(C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2) (kafka.log.LogManager)
[2022-05-15 20:45:10,801] INFO Attempting recovery for all logs in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2 since no clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 20:45:10,822] INFO Loaded 0 logs in 43ms. (kafka.log.LogManager)
[2022-05-15 20:45:10,823] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 20:45:10,829] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 20:45:10,830] INFO Loaded 0 logs in 38ms. (kafka.log.LogManager)
[2022-05-15 20:45:10,831] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 20:45:10,838] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 20:45:11,198] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 20:45:11,277] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 20:45:11,280] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 20:45:11,335] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 20:45:11,430] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 20:45:11,453] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 20:45:11,666] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 20:45:11,691] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-05-15 20:45:11,858] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 20:45:11,839] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 20:45:11,868] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 20:45:11,870] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2022-05-15 20:45:11,869] INFO Awaiting socket connections on 0.0.0.0:9097. (kafka.network.Acceptor)
[2022-05-15 20:45:11,902] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 20:45:11,947] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 20:45:11,959] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:45:11,966] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:45:11,968] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:45:11,970] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 20:45:11,970] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:45:11,983] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 20:45:11,989] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 20:45:11,991] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 20:45:11,998] INFO Awaiting socket connections on 0.0.0.0:9096. (kafka.network.Acceptor)
[2022-05-15 20:45:12,008] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 20:45:12,024] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:45:12,030] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:45:12,030] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:45:12,040] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:45:12,042] INFO [ExpirationReaper-5-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:45:12,058] INFO [ExpirationReaper-5-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:45:12,059] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 20:45:12,058] INFO [ExpirationReaper-5-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:45:12,059] INFO [ExpirationReaper-5-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:45:12,068] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 20:45:12,077] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 20:45:12,083] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 20:45:12,093] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 20:45:12,100] INFO Awaiting socket connections on 0.0.0.0:9095. (kafka.network.Acceptor)
[2022-05-15 20:45:12,114] INFO [ExpirationReaper-4-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:45:12,114] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 20:45:12,120] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2022-05-15 20:45:12,148] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 20:45:12,114] INFO [ExpirationReaper-4-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:45:12,152] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 20:45:12,153] INFO [ExpirationReaper-4-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:45:12,153] INFO [ExpirationReaper-4-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:45:12,159] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 20:45:12,172] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 20:45:12,183] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 20:45:12,193] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:45:12,205] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:45:12,240] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:45:12,244] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:45:12,240] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 20:45:12,244] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 20:45:12,240] INFO [ExpirationReaper-3-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:45:12,240] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:45:12,244] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:45:12,244] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:45:16,582] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 20:45:16,604] INFO Stat of the created znode at /brokers/ids/0 is: 115,115,1652643916596,1652643916596,1,0,0,72059429846843394,214,0,115
 (kafka.zk.KafkaZkClient)
[2022-05-15 20:45:16,605] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://LAPTOP-S01N1QNU:9092, czxid (broker epoch): 115 (kafka.zk.KafkaZkClient)
[2022-05-15 20:45:16,632] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 20:45:16,633] INFO Creating /brokers/ids/5 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 20:45:16,650] INFO Stat of the created znode at /brokers/ids/2 is: 116,116,1652643916642,1652643916642,1,0,0,72059429846843393,214,0,116
 (kafka.zk.KafkaZkClient)
[2022-05-15 20:45:16,651] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://LAPTOP-S01N1QNU:9094, czxid (broker epoch): 116 (kafka.zk.KafkaZkClient)
[2022-05-15 20:45:16,652] INFO Stat of the created znode at /brokers/ids/5 is: 117,117,1652643916643,1652643916643,1,0,0,72059429846843392,214,0,117
 (kafka.zk.KafkaZkClient)
[2022-05-15 20:45:16,654] INFO Registered broker 5 at path /brokers/ids/5 with addresses: PLAINTEXT://LAPTOP-S01N1QNU:9097, czxid (broker epoch): 117 (kafka.zk.KafkaZkClient)
[2022-05-15 20:45:16,682] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:45:16,693] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:45:16,693] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:45:16,698] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2022-05-15 20:45:16,712] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:45:16,720] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:45:16,723] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
[2022-05-15 20:45:16,726] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
[2022-05-15 20:45:16,726] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
[2022-05-15 20:45:16,727] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
[2022-05-15 20:45:16,726] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
[2022-05-15 20:45:16,727] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
[2022-05-15 20:45:16,740] INFO Creating /brokers/ids/4 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 20:45:16,765] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 20:45:16,767] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 20:45:16,769] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 20:45:16,770] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 20:45:16,771] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:45:16,766] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 20:45:16,790] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 20:45:16,779] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 20:45:16,797] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 20:45:16,809] INFO [ExpirationReaper-5-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:45:16,773] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 20:45:16,805] INFO Stat of the created znode at /brokers/ids/4 is: 121,121,1652643916790,1652643916790,1,0,0,72059429846843395,214,0,121
 (kafka.zk.KafkaZkClient)
[2022-05-15 20:45:16,793] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 20:45:16,838] INFO Stat of the created znode at /brokers/ids/3 is: 122,122,1652643916825,1652643916825,1,0,0,72059429846843396,214,0,122
 (kafka.zk.KafkaZkClient)
[2022-05-15 20:45:16,840] INFO Stat of the created znode at /brokers/ids/1 is: 123,123,1652643916827,1652643916827,1,0,0,72059429846843397,214,0,123
 (kafka.zk.KafkaZkClient)
[2022-05-15 20:45:16,825] INFO Registered broker 4 at path /brokers/ids/4 with addresses: PLAINTEXT://LAPTOP-S01N1QNU:9096, czxid (broker epoch): 121 (kafka.zk.KafkaZkClient)
[2022-05-15 20:45:16,823] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:45:16,845] INFO [ExpirationReaper-5-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:45:16,849] INFO [ExpirationReaper-5-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:45:16,797] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 20:45:16,845] INFO Registered broker 3 at path /brokers/ids/3 with addresses: PLAINTEXT://LAPTOP-S01N1QNU:9095, czxid (broker epoch): 122 (kafka.zk.KafkaZkClient)
[2022-05-15 20:45:16,845] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://LAPTOP-S01N1QNU:9093, czxid (broker epoch): 123 (kafka.zk.KafkaZkClient)
[2022-05-15 20:45:16,846] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:45:16,859] INFO [GroupCoordinator 5]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:45:16,895] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:45:16,846] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:45:16,892] INFO [GroupCoordinator 5]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:45:16,857] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:45:16,943] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 20:45:16,951] INFO [TransactionCoordinator id=5] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 20:45:16,958] INFO [TransactionCoordinator id=5] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 20:45:16,993] INFO [Transaction Marker Channel Manager 5]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 20:45:16,988] INFO [ExpirationReaper-4-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:45:16,989] INFO [ExpirationReaper-3-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:45:16,995] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 20:45:16,990] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 20:45:16,990] INFO [ExpirationReaper-4-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:45:17,004] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 20:45:17,024] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 20:45:16,989] INFO [ExpirationReaper-3-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:45:16,990] INFO [ExpirationReaper-4-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:45:17,036] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 20:45:17,037] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:45:17,042] INFO [ExpirationReaper-5-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:45:17,028] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 20:45:17,036] INFO [GroupCoordinator 4]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:45:17,027] INFO [ExpirationReaper-3-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:45:17,069] INFO [GroupCoordinator 4]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:45:17,087] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:45:17,038] INFO [GroupCoordinator 3]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:45:17,087] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:45:17,096] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:45:17,078] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 20:45:17,102] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 20:45:17,121] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:45:17,108] INFO [GroupCoordinator 3]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:45:17,116] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:45:17,100] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 20:45:17,133] INFO [TransactionCoordinator id=4] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 20:45:17,148] INFO [TransactionCoordinator id=4] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 20:45:17,159] INFO [Transaction Marker Channel Manager 4]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 20:45:17,178] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 20:45:17,133] INFO Kafka startTimeMs: 1652643917051 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 20:45:17,184] INFO [TransactionCoordinator id=3] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 20:45:17,187] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 20:45:17,137] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 20:45:17,187] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2022-05-15 20:45:17,187] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 20:45:17,192] INFO [TransactionCoordinator id=3] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 20:45:17,262] INFO [Transaction Marker Channel Manager 3]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 20:45:17,261] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 20:45:17,267] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 20:45:17,273] INFO [ExpirationReaper-3-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:45:17,272] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:45:17,278] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 20:45:17,276] INFO [ExpirationReaper-4-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:45:17,293] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 20:45:17,313] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 20:45:17,315] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 20:45:17,330] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 20:45:17,309] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 20:45:17,341] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 20:45:17,302] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 20:45:17,356] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 20:45:17,387] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 20:45:17,387] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 20:45:17,380] INFO Kafka startTimeMs: 1652643917269 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 20:45:17,407] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 20:45:17,416] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 20:45:17,418] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 20:45:17,415] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 20:45:17,418] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 20:45:17,400] INFO [KafkaServer id=5] started (kafka.server.KafkaServer)
[2022-05-15 20:45:17,420] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 20:45:17,409] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 20:45:17,445] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 20:45:17,458] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 20:45:17,458] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 20:45:17,464] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 20:45:17,460] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 20:45:17,459] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 20:45:17,462] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 20:45:17,522] INFO Kafka startTimeMs: 1652643917440 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 20:45:17,516] INFO Kafka startTimeMs: 1652643917427 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 20:45:17,470] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 20:45:17,618] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 20:45:17,528] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 20:45:17,581] INFO Kafka startTimeMs: 1652643917441 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 20:45:17,540] INFO [KafkaServer id=4] started (kafka.server.KafkaServer)
[2022-05-15 20:45:17,549] INFO [KafkaServer id=3] started (kafka.server.KafkaServer)
[2022-05-15 20:45:17,674] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 20:45:17,693] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 20:45:17,677] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 20:45:17,694] INFO Kafka startTimeMs: 1652643917517 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 20:45:17,691] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2022-05-15 20:45:17,741] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 20:45:17,775] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 20:45:17,735] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2022-05-15 20:45:17,793] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 20:45:17,789] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 20:45:17,850] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 20:45:17,852] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 20:45:17,859] INFO Creating topic Sensor with configuration {min.insync.replicas=2} and initial partition assignment Map(2 -> ArrayBuffer(4, 2, 3), 5 -> ArrayBuffer(3, 5, 4), 4 -> ArrayBuffer(2, 0, 5), 1 -> ArrayBuffer(5, 1, 2), 3 -> ArrayBuffer(1, 3, 0), 0 -> ArrayBuffer(0, 4, 1)) (kafka.zk.AdminZkClient)
[2022-05-15 20:45:17,881] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 20:45:18,027] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 20:45:18,036] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 20:45:18,043] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-2) (kafka.server.ReplicaFetcherManager)
[2022-05-15 20:45:18,075] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-5) (kafka.server.ReplicaFetcherManager)
[2022-05-15 20:45:18,077] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-4) (kafka.server.ReplicaFetcherManager)
[2022-05-15 20:45:18,080] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 20:45:18,151] INFO [LogLoader partition=Sensor-0, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:45:18,154] INFO [LogLoader partition=Sensor-3, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:45:18,159] INFO [LogLoader partition=Sensor-2, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:45:18,178] INFO Created log for partition Sensor-0 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 20:45:18,179] INFO [LogLoader partition=Sensor-5, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:45:18,182] INFO [Partition Sensor-0 broker=0] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 20:45:18,183] INFO Created log for partition Sensor-3 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 20:45:18,184] INFO [Partition Sensor-0 broker=0] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:45:18,187] INFO [LogLoader partition=Sensor-4, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:45:18,187] INFO Created log for partition Sensor-2 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 20:45:18,187] INFO [Partition Sensor-3 broker=1] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-15 20:45:18,193] INFO [LogLoader partition=Sensor-1, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:45:18,205] INFO Created log for partition Sensor-5 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 20:45:18,190] INFO [Partition Sensor-3 broker=1] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:45:18,191] INFO [Partition Sensor-2 broker=4] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-15 20:45:18,209] INFO [Partition Sensor-5 broker=3] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-15 20:45:18,217] INFO Created log for partition Sensor-1 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 20:45:18,213] INFO Created log for partition Sensor-4 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 20:45:18,231] INFO [Partition Sensor-2 broker=4] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:45:18,243] INFO [Partition Sensor-1 broker=5] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-15 20:45:18,237] INFO [Partition Sensor-5 broker=3] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:45:18,242] INFO [Partition Sensor-4 broker=2] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-15 20:45:18,254] INFO [LogLoader partition=Sensor-4, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:45:18,245] INFO [Partition Sensor-1 broker=5] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:45:18,251] INFO [Partition Sensor-4 broker=2] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:45:18,256] INFO Created log for partition Sensor-4 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 20:45:18,261] INFO [Partition Sensor-4 broker=0] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-15 20:45:18,278] INFO [Partition Sensor-4 broker=0] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:45:18,298] INFO [LogLoader partition=Sensor-1, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:45:18,301] INFO [LogLoader partition=Sensor-3, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:45:18,301] INFO Created log for partition Sensor-1 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 20:45:18,304] INFO Created log for partition Sensor-3 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 20:45:18,302] INFO [Partition Sensor-1 broker=1] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-15 20:45:18,313] INFO [Partition Sensor-3 broker=0] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-15 20:45:18,313] INFO [Partition Sensor-1 broker=1] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:45:18,323] INFO [LogLoader partition=Sensor-5, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:45:18,318] INFO [Partition Sensor-3 broker=0] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:45:18,329] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-4, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 20:45:18,332] INFO [LogLoader partition=Sensor-2, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:45:18,334] INFO [LogLoader partition=Sensor-4, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:45:18,326] INFO Created log for partition Sensor-5 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 20:45:18,342] INFO [LogLoader partition=Sensor-0, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:45:18,342] INFO [LogLoader partition=Sensor-1, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:45:18,336] INFO Created log for partition Sensor-2 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 20:45:18,335] INFO [Partition Sensor-5 broker=4] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-15 20:45:18,338] INFO Created log for partition Sensor-4 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 20:45:18,345] INFO Created log for partition Sensor-0 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 20:45:18,345] INFO [Partition Sensor-2 broker=3] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-15 20:45:18,345] INFO [Partition Sensor-5 broker=4] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:45:18,346] INFO Created log for partition Sensor-1 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 20:45:18,347] INFO [Partition Sensor-4 broker=5] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-15 20:45:18,348] INFO [Partition Sensor-0 broker=1] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 20:45:18,351] INFO [Partition Sensor-2 broker=3] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:45:18,357] INFO [Partition Sensor-1 broker=2] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-15 20:45:18,372] INFO [LogLoader partition=Sensor-0, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:45:18,366] INFO [Partition Sensor-4 broker=5] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:45:18,366] INFO [Partition Sensor-0 broker=1] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:45:18,377] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 20:45:18,375] INFO Created log for partition Sensor-0 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 20:45:18,388] INFO [LogLoader partition=Sensor-3, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:45:18,369] INFO [Partition Sensor-1 broker=2] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:45:18,384] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 2 for partitions Map(Sensor-4 -> InitialFetchState(Some(DwG3cwJVQsyUp_tfkFJVdQ),BrokerEndPoint(id=2, host=LAPTOP-S01N1QNU:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 20:45:18,394] INFO [LogLoader partition=Sensor-5, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:45:18,380] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 20:45:18,390] INFO Created log for partition Sensor-3 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 20:45:18,383] INFO [Partition Sensor-0 broker=4] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 20:45:18,388] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition Sensor-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 20:45:18,396] INFO Created log for partition Sensor-5 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 20:45:18,397] INFO [Partition Sensor-3 broker=3] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-15 20:45:18,399] INFO [Partition Sensor-0 broker=4] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:45:18,404] INFO [Partition Sensor-5 broker=5] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-15 20:45:18,411] INFO [LogLoader partition=Sensor-2, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:45:18,398] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 1 for partitions Map(Sensor-3 -> InitialFetchState(Some(DwG3cwJVQsyUp_tfkFJVdQ),BrokerEndPoint(id=1, host=LAPTOP-S01N1QNU:9093),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 20:45:18,409] INFO [Partition Sensor-3 broker=3] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:45:18,413] INFO Created log for partition Sensor-2 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 20:45:18,410] INFO [Partition Sensor-5 broker=5] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:45:18,409] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 20:45:18,411] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-0, Sensor-5) (kafka.server.ReplicaFetcherManager)
[2022-05-15 20:45:18,418] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-3, Sensor-2) (kafka.server.ReplicaFetcherManager)
[2022-05-15 20:45:18,423] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-4, Sensor-5) (kafka.server.ReplicaFetcherManager)
[2022-05-15 20:45:18,422] INFO [Partition Sensor-2 broker=2] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-15 20:45:18,405] INFO [UnifiedLog partition=Sensor-4, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 20:45:18,437] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 20:45:18,433] INFO [Partition Sensor-2 broker=2] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:45:18,425] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition Sensor-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 20:45:18,445] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 5 for partitions Map(Sensor-1 -> InitialFetchState(Some(DwG3cwJVQsyUp_tfkFJVdQ),BrokerEndPoint(id=5, host=LAPTOP-S01N1QNU:9097),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 20:45:18,458] INFO [UnifiedLog partition=Sensor-3, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 20:45:18,454] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-1, Sensor-2) (kafka.server.ReplicaFetcherManager)
[2022-05-15 20:45:18,446] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Truncating partition Sensor-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 20:45:18,469] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 0 for partitions Map(Sensor-0 -> InitialFetchState(Some(DwG3cwJVQsyUp_tfkFJVdQ),BrokerEndPoint(id=0, host=LAPTOP-S01N1QNU:9092),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 20:45:18,471] INFO [UnifiedLog partition=Sensor-1, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 20:45:18,473] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 20:45:18,485] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition Sensor-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 20:45:18,487] INFO [UnifiedLog partition=Sensor-0, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 20:45:18,494] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 20:45:18,496] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 20:45:18,505] INFO [ReplicaFetcherManager on broker 5] Added fetcher to broker 3 for partitions Map(Sensor-5 -> InitialFetchState(Some(DwG3cwJVQsyUp_tfkFJVdQ),BrokerEndPoint(id=3, host=LAPTOP-S01N1QNU:9095),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 20:45:18,508] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Truncating partition Sensor-5 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 20:45:18,501] INFO [ReplicaFetcherManager on broker 4] Added fetcher to broker 3 for partitions Map(Sensor-5 -> InitialFetchState(Some(DwG3cwJVQsyUp_tfkFJVdQ),BrokerEndPoint(id=3, host=LAPTOP-S01N1QNU:9095),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 20:45:18,516] INFO [ReplicaFetcherManager on broker 5] Added fetcher to broker 2 for partitions Map(Sensor-4 -> InitialFetchState(Some(DwG3cwJVQsyUp_tfkFJVdQ),BrokerEndPoint(id=2, host=LAPTOP-S01N1QNU:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 20:45:18,513] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 20:45:18,511] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Truncating partition Sensor-5 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 20:45:18,519] INFO [UnifiedLog partition=Sensor-5, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 20:45:18,528] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 4 for partitions Map(Sensor-2 -> InitialFetchState(Some(DwG3cwJVQsyUp_tfkFJVdQ),BrokerEndPoint(id=4, host=LAPTOP-S01N1QNU:9096),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 20:45:18,529] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Truncating partition Sensor-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 20:45:18,542] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 1 for partitions Map(Sensor-3 -> InitialFetchState(Some(DwG3cwJVQsyUp_tfkFJVdQ),BrokerEndPoint(id=1, host=LAPTOP-S01N1QNU:9093),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 20:45:18,559] WARN [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-3. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 20:45:18,556] INFO [UnifiedLog partition=Sensor-2, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 20:45:18,559] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 20:45:18,522] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 20:45:18,535] INFO [UnifiedLog partition=Sensor-5, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 20:45:18,566] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 20:45:18,568] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Truncating partition Sensor-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 20:45:18,569] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Truncating partition Sensor-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 20:45:18,577] WARN [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-4. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 20:45:18,578] INFO [UnifiedLog partition=Sensor-3, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 20:45:18,587] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 5 for partitions Map(Sensor-1 -> InitialFetchState(Some(DwG3cwJVQsyUp_tfkFJVdQ),BrokerEndPoint(id=5, host=LAPTOP-S01N1QNU:9097),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 20:45:18,587] INFO [UnifiedLog partition=Sensor-4, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 20:45:18,589] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Truncating partition Sensor-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 20:45:18,549] INFO [ReplicaFetcherManager on broker 4] Added fetcher to broker 0 for partitions Map(Sensor-0 -> InitialFetchState(Some(DwG3cwJVQsyUp_tfkFJVdQ),BrokerEndPoint(id=0, host=LAPTOP-S01N1QNU:9092),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 20:45:18,627] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 20:45:18,636] INFO [UnifiedLog partition=Sensor-1, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 20:45:18,644] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Truncating partition Sensor-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 20:45:18,647] WARN [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-4. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 20:45:18,620] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 20:45:18,664] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Truncating partition Sensor-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 20:45:18,654] INFO [UnifiedLog partition=Sensor-0, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 20:45:18,675] WARN [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-5. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 20:45:18,614] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 4 for partitions Map(Sensor-2 -> InitialFetchState(Some(DwG3cwJVQsyUp_tfkFJVdQ),BrokerEndPoint(id=4, host=LAPTOP-S01N1QNU:9096),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 20:45:18,673] INFO [UnifiedLog partition=Sensor-2, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 20:45:18,718] WARN [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-1. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 20:45:18,736] WARN [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-2. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 20:45:18,763] WARN [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-2. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 20:49:22,863] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:49:22,864] WARN config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:49:22,872] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:49:22,872] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:49:22,873] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:49:22,873] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:49:22,874] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 20:49:22,875] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 20:49:22,875] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 20:49:22,875] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2022-05-15 20:49:22,878] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2022-05-15 20:49:22,888] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:49:22,888] WARN config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:49:22,889] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:49:22,889] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:49:22,889] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:49:22,889] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:49:22,889] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2022-05-15 20:49:22,900] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@62230c58 (org.apache.zookeeper.server.ServerMetrics)
[2022-05-15 20:49:22,902] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-15 20:49:22,913] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:49:22,914] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:49:22,914] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:49:22,915] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:49:22,915] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:49:22,915] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:49:22,916] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:49:22,916] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:49:22,917] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:49:22,917] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:49:27,426] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 20:49:27,461] INFO Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:49:27,462] INFO Server environment:host.name=LAPTOP-S01N1QNU (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:49:27,463] INFO Server environment:java.version=11.0.10 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:49:27,465] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:49:27,466] INFO Server environment:java.home=C:\Program Files\Java\jdk-11.0.10 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:49:27,466] INFO Server environment:java.class.path=C:\Users\joaoc\Documents\kafka\kfk\libs\activation-1.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\aopalliance-repackaged-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\argparse4j-0.7.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\audience-annotations-0.5.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-cli-1.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-lang3-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-basic-auth-extension-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-file-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-json-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-client-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-runtime-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-transforms-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-api-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-locator-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-utils-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-core-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-databind-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-dataformat-csv-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-datatype-jdk8-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-base-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-json-provider-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-jaxb-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-scala_2.12-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.activation-api-1.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.annotation-api-1.3.5.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.inject-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.validation-api-2.0.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javassist-3.27.0-GA.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.servlet-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jaxb-api-2.3.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-client-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-common-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-core-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-hk2-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-server-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-client-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-continuation-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-http-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-io-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-security-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-server-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlet-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlets-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-ajax-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jline-3.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jopt-simple-5.0.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jose4j-0.7.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-clients-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-log4j-appender-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-metadata-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-raft-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-server-common-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-shell-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-examples-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-scala_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-test-utils-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-tools-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\log4j-1.2.17.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\lz4-java-1.8.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\maven-artifact-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-2.2.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-4.1.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-buffer-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-codec-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-handler-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-resolver-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-epoll-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-unix-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\osgi-resource-locator-1.0.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\paranamer-2.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\plexus-utils-3.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\reflections-0.9.12.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\rocksdbjni-6.22.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-collection-compat_2.12-2.4.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-java8-compat_2.12-1.0.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-library-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-logging_2.12-3.9.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-reflect-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-api-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-log4j12-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\snappy-java-1.1.8.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\trogdor-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-jute-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:49:27,468] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-11.0.10\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.10\bin;C:\Program Files\apache-maven-3.6.3\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\sox-14-4-2;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\dotnet\;C:\Users\joaoc\Downloads\apache-zookeeper-3.8.0-bin\bin;C:\Program Files\swipl\bin;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\Scripts\;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\;C:\Users\joaoc\AppData\Local\Microsoft\WindowsApps;C:\Users\joaoc\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\joaoc\AppData\Local\Programs\Julia-1.6.0\bin;C:\Users\joaoc\.dotnet\tools;. (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:49:27,468] INFO Server environment:java.io.tmpdir=C:\Users\joaoc\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:49:27,469] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:49:27,469] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:49:27,469] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:49:27,470] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:49:27,474] INFO Server environment:user.name=joaoc (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:49:27,475] INFO Server environment:user.home=C:\Users\joaoc (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:49:27,475] INFO Server environment:user.dir=C:\Users\joaoc\Documents\kafka\kfk (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:49:27,475] INFO Server environment:os.memory.free=490MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:49:27,476] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:49:27,479] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:49:27,479] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:49:27,480] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:49:27,480] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:49:27,481] INFO zookeeper.flushDelay=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:49:27,481] INFO zookeeper.maxWriteQueuePollTime=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:49:27,481] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:49:27,482] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:49:27,483] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2022-05-15 20:49:27,485] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:49:27,485] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:49:27,486] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-15 20:49:27,488] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-15 20:49:27,489] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 20:49:27,489] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 20:49:27,490] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 20:49:27,491] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 20:49:27,492] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 20:49:27,494] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 20:49:27,497] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:49:27,498] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:49:27,498] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 clientPortListenBacklog -1 datadir C:\Users\joaoc\Documents\kafka\kfk\zookeeper\version-2 snapdir C:\Users\joaoc\Documents\kafka\kfk\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:49:27,512] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-15 20:49:27,513] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-15 20:49:27,514] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-15 20:49:27,518] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-15 20:49:27,540] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2022-05-15 20:49:27,540] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2022-05-15 20:49:27,543] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-15 20:49:27,543] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-15 20:49:27,550] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2022-05-15 20:49:27,550] INFO Snapshotting: 0x0 to C:\Users\joaoc\Documents\kafka\kfk\zookeeper\version-2\snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-15 20:49:27,555] INFO Snapshot loaded in 11 ms, highest zxid is 0x0, digest is 1371985504 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-15 20:49:27,556] INFO Snapshotting: 0x0 to C:\Users\joaoc\Documents\kafka\kfk\zookeeper\version-2\snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-15 20:49:27,559] INFO Snapshot taken in 3 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:49:27,570] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2022-05-15 20:49:27,570] INFO zookeeper.request_throttler.shutdownTimeout = 10000 (org.apache.zookeeper.server.RequestThrottler)
[2022-05-15 20:49:27,586] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2022-05-15 20:49:27,588] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2022-05-15 20:49:27,778] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 20:49:27,848] INFO starting (kafka.server.KafkaServer)
[2022-05-15 20:49:27,850] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 20:49:27,865] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 20:49:32,404] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:49:32,404] INFO Client environment:host.name=LAPTOP-S01N1QNU (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:49:32,404] INFO Client environment:java.version=11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:49:32,405] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:49:32,405] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:49:32,405] INFO Client environment:java.class.path=C:\Users\joaoc\Documents\kafka\kfk\libs\activation-1.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\aopalliance-repackaged-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\argparse4j-0.7.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\audience-annotations-0.5.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-cli-1.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-lang3-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-basic-auth-extension-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-file-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-json-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-client-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-runtime-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-transforms-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-api-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-locator-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-utils-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-core-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-databind-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-dataformat-csv-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-datatype-jdk8-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-base-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-json-provider-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-jaxb-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-scala_2.12-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.activation-api-1.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.annotation-api-1.3.5.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.inject-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.validation-api-2.0.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javassist-3.27.0-GA.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.servlet-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jaxb-api-2.3.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-client-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-common-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-core-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-hk2-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-server-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-client-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-continuation-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-http-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-io-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-security-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-server-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlet-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlets-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-ajax-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jline-3.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jopt-simple-5.0.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jose4j-0.7.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-clients-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-log4j-appender-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-metadata-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-raft-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-server-common-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-shell-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-examples-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-scala_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-test-utils-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-tools-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\log4j-1.2.17.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\lz4-java-1.8.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\maven-artifact-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-2.2.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-4.1.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-buffer-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-codec-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-handler-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-resolver-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-epoll-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-unix-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\osgi-resource-locator-1.0.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\paranamer-2.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\plexus-utils-3.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\reflections-0.9.12.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\rocksdbjni-6.22.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-collection-compat_2.12-2.4.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-java8-compat_2.12-1.0.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-library-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-logging_2.12-3.9.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-reflect-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-api-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-log4j12-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\snappy-java-1.1.8.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\trogdor-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-jute-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:49:32,406] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.10\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.10\bin;C:\Program Files\apache-maven-3.6.3\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\sox-14-4-2;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\dotnet\;C:\Users\joaoc\Downloads\apache-zookeeper-3.8.0-bin\bin;C:\Program Files\swipl\bin;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\Scripts\;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\;C:\Users\joaoc\AppData\Local\Microsoft\WindowsApps;C:\Users\joaoc\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\joaoc\AppData\Local\Programs\Julia-1.6.0\bin;C:\Users\joaoc\.dotnet\tools;. (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:49:32,406] INFO Client environment:java.io.tmpdir=C:\Users\joaoc\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:49:32,407] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:49:32,407] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:49:32,408] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:49:32,408] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:49:32,409] INFO Client environment:user.name=joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:49:32,409] INFO Client environment:user.home=C:\Users\joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:49:32,409] INFO Client environment:user.dir=C:\Users\joaoc\Documents\kafka\kfk (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:49:32,410] INFO Client environment:os.memory.free=1009MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:49:32,410] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:49:32,410] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:49:32,413] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@5f6722d3 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:49:32,423] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 20:49:32,428] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:49:32,431] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 20:49:32,437] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:49:32,438] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:49:32,441] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:61787, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:49:32,453] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2022-05-15 20:49:32,473] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, session id = 0x10001af7b740000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:49:32,477] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 20:49:32,598] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 20:49:32,609] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
[2022-05-15 20:49:32,609] INFO Cleared cache (kafka.server.FinalizedFeatureCache)
[2022-05-15 20:49:32,739] INFO Cluster ID = ixcfg6f1Rc6J9YVyHF5e-w (kafka.server.KafkaServer)
[2022-05-15 20:49:32,743] WARN No meta.properties file under dir C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-05-15 20:49:32,805] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 20:49:32,817] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 20:49:32,851] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:49:32,862] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:49:32,864] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:49:32,866] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:49:32,880] INFO Log directory C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1 not found, creating it. (kafka.log.LogManager)
[2022-05-15 20:49:32,901] INFO Loading logs from log dirs ArrayBuffer(C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1) (kafka.log.LogManager)
[2022-05-15 20:49:32,905] INFO Attempting recovery for all logs in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1 since no clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 20:49:32,916] INFO Loaded 0 logs in 15ms. (kafka.log.LogManager)
[2022-05-15 20:49:32,917] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 20:49:32,919] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 20:49:33,172] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 20:49:33,314] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 20:49:33,319] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-05-15 20:49:33,344] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 20:49:33,352] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 20:49:33,373] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:49:33,374] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:49:33,375] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:49:33,376] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:49:33,390] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 20:49:37,964] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 20:49:37,987] INFO Stat of the created znode at /brokers/ids/0 is: 25,25,1652644177976,1652644177976,1,0,0,72059447240032256,214,0,25
 (kafka.zk.KafkaZkClient)
[2022-05-15 20:49:37,988] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://LAPTOP-S01N1QNU:9092, czxid (broker epoch): 25 (kafka.zk.KafkaZkClient)
[2022-05-15 20:49:38,042] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:49:38,046] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:49:38,047] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:49:38,054] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2022-05-15 20:49:38,063] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:49:38,068] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:49:38,071] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
[2022-05-15 20:49:38,086] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 20:49:38,090] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 20:49:38,091] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 20:49:38,100] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 20:49:38,119] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:49:38,137] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 20:49:38,151] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 20:49:38,156] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 20:49:38,157] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 20:49:38,164] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 20:49:38,165] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 20:49:38,166] INFO Kafka startTimeMs: 1652644178158 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 20:49:38,169] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2022-05-15 20:49:38,280] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 20:49:38,327] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 20:49:38,336] INFO Creating topic Sensor with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2022-05-15 20:49:38,421] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 20:49:38,481] INFO [LogLoader partition=Sensor-0, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:49:38,497] INFO Created log for partition Sensor-0 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\Sensor-0 with properties {} (kafka.log.LogManager)
[2022-05-15 20:49:38,499] INFO [Partition Sensor-0 broker=0] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 20:49:38,500] INFO [Partition Sensor-0 broker=0] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:51:11,904] WARN Close of session 0x10001af7b740000 (org.apache.zookeeper.server.NIOServerCnxn)
java.io.IOException: An existing connection was forcibly closed by the remote host
	at java.base/sun.nio.ch.SocketDispatcher.read0(Native Method)
	at java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:245)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:324)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:522)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:154)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
[2022-05-15 20:52:06,279] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:52:06,281] WARN config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:52:06,290] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:52:06,290] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:52:06,290] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:52:06,290] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:52:06,293] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 20:52:06,293] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 20:52:06,293] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 20:52:06,293] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2022-05-15 20:52:06,297] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2022-05-15 20:52:06,308] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:52:06,308] WARN config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:52:06,309] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:52:06,310] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:52:06,310] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:52:06,310] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:52:06,310] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2022-05-15 20:52:06,320] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@62230c58 (org.apache.zookeeper.server.ServerMetrics)
[2022-05-15 20:52:06,323] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-15 20:52:06,334] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:52:06,334] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:52:06,335] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:52:06,335] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:52:06,336] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:52:06,336] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:52:06,337] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:52:06,337] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:52:06,337] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:52:06,337] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:52:10,572] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 20:52:10,905] INFO Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:52:10,905] INFO Server environment:host.name=LAPTOP-S01N1QNU (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:52:10,906] INFO Server environment:java.version=11.0.10 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:52:10,907] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:52:10,908] INFO Server environment:java.home=C:\Program Files\Java\jdk-11.0.10 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:52:10,908] INFO Server environment:java.class.path=C:\Users\joaoc\Documents\kafka\kfk\libs\activation-1.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\aopalliance-repackaged-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\argparse4j-0.7.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\audience-annotations-0.5.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-cli-1.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-lang3-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-basic-auth-extension-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-file-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-json-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-client-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-runtime-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-transforms-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-api-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-locator-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-utils-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-core-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-databind-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-dataformat-csv-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-datatype-jdk8-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-base-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-json-provider-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-jaxb-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-scala_2.12-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.activation-api-1.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.annotation-api-1.3.5.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.inject-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.validation-api-2.0.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javassist-3.27.0-GA.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.servlet-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jaxb-api-2.3.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-client-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-common-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-core-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-hk2-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-server-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-client-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-continuation-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-http-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-io-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-security-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-server-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlet-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlets-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-ajax-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jline-3.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jopt-simple-5.0.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jose4j-0.7.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-clients-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-log4j-appender-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-metadata-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-raft-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-server-common-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-shell-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-examples-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-scala_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-test-utils-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-tools-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\log4j-1.2.17.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\lz4-java-1.8.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\maven-artifact-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-2.2.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-4.1.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-buffer-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-codec-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-handler-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-resolver-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-epoll-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-unix-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\osgi-resource-locator-1.0.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\paranamer-2.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\plexus-utils-3.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\reflections-0.9.12.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\rocksdbjni-6.22.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-collection-compat_2.12-2.4.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-java8-compat_2.12-1.0.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-library-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-logging_2.12-3.9.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-reflect-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-api-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-log4j12-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\snappy-java-1.1.8.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\trogdor-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-jute-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:52:10,910] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-11.0.10\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.10\bin;C:\Program Files\apache-maven-3.6.3\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\sox-14-4-2;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\dotnet\;C:\Users\joaoc\Downloads\apache-zookeeper-3.8.0-bin\bin;C:\Program Files\swipl\bin;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\Scripts\;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\;C:\Users\joaoc\AppData\Local\Microsoft\WindowsApps;C:\Users\joaoc\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\joaoc\AppData\Local\Programs\Julia-1.6.0\bin;C:\Users\joaoc\.dotnet\tools;. (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:52:10,910] INFO Server environment:java.io.tmpdir=C:\Users\joaoc\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:52:10,910] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:52:10,911] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:52:10,911] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:52:10,923] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:52:10,928] INFO Server environment:user.name=joaoc (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:52:10,929] INFO Server environment:user.home=C:\Users\joaoc (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:52:10,929] INFO Server environment:user.dir=C:\Users\joaoc\Documents\kafka\kfk (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:52:10,930] INFO Server environment:os.memory.free=489MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:52:10,931] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:52:10,931] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:52:10,932] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:52:10,934] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:52:10,934] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 20:52:10,935] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:52:10,935] INFO zookeeper.flushDelay=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:52:10,935] INFO zookeeper.maxWriteQueuePollTime=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:52:10,936] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:52:10,936] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:52:10,938] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2022-05-15 20:52:10,940] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:52:10,943] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:52:10,945] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-15 20:52:10,945] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-15 20:52:10,947] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 20:52:10,947] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 20:52:10,947] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 20:52:10,960] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 20:52:10,962] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 20:52:10,963] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 20:52:10,966] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:52:10,967] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:52:10,967] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 clientPortListenBacklog -1 datadir C:\Users\joaoc\Documents\kafka\kfk\zookeeper\version-2 snapdir C:\Users\joaoc\Documents\kafka\kfk\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:52:10,982] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-15 20:52:10,983] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-15 20:52:10,985] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-15 20:52:10,989] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-15 20:52:11,009] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2022-05-15 20:52:11,010] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2022-05-15 20:52:11,013] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-15 20:52:11,015] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-15 20:52:11,019] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2022-05-15 20:52:11,026] INFO starting (kafka.server.KafkaServer)
[2022-05-15 20:52:11,028] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 20:52:11,030] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.io.IOException: No snapshot found, but there are log entries. Something is broken!
	at org.apache.zookeeper.server.persistence.FileTxnSnapLog.restore(FileTxnSnapLog.java:281)
	at org.apache.zookeeper.server.ZKDatabase.loadDataBase(ZKDatabase.java:285)
	at org.apache.zookeeper.server.ZooKeeperServer.loadData(ZooKeeperServer.java:494)
	at org.apache.zookeeper.server.ZooKeeperServer.startdata(ZooKeeperServer.java:665)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.startup(NIOServerCnxnFactory.java:758)
	at org.apache.zookeeper.server.ServerCnxnFactory.startup(ServerCnxnFactory.java:130)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:159)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:112)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:67)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:140)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:90)
[2022-05-15 20:52:11,034] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2022-05-15 20:52:11,041] ERROR Exiting JVM with code 1 (org.apache.zookeeper.util.ServiceUtils)
[2022-05-15 20:52:11,043] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 20:52:15,581] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:52:15,581] INFO Client environment:host.name=LAPTOP-S01N1QNU (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:52:15,582] INFO Client environment:java.version=11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:52:15,582] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:52:15,582] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:52:15,582] INFO Client environment:java.class.path=C:\Users\joaoc\Documents\kafka\kfk\libs\activation-1.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\aopalliance-repackaged-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\argparse4j-0.7.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\audience-annotations-0.5.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-cli-1.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-lang3-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-basic-auth-extension-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-file-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-json-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-client-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-runtime-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-transforms-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-api-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-locator-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-utils-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-core-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-databind-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-dataformat-csv-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-datatype-jdk8-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-base-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-json-provider-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-jaxb-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-scala_2.12-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.activation-api-1.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.annotation-api-1.3.5.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.inject-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.validation-api-2.0.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javassist-3.27.0-GA.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.servlet-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jaxb-api-2.3.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-client-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-common-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-core-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-hk2-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-server-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-client-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-continuation-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-http-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-io-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-security-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-server-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlet-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlets-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-ajax-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jline-3.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jopt-simple-5.0.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jose4j-0.7.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-clients-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-log4j-appender-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-metadata-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-raft-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-server-common-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-shell-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-examples-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-scala_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-test-utils-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-tools-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\log4j-1.2.17.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\lz4-java-1.8.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\maven-artifact-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-2.2.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-4.1.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-buffer-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-codec-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-handler-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-resolver-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-epoll-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-unix-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\osgi-resource-locator-1.0.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\paranamer-2.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\plexus-utils-3.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\reflections-0.9.12.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\rocksdbjni-6.22.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-collection-compat_2.12-2.4.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-java8-compat_2.12-1.0.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-library-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-logging_2.12-3.9.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-reflect-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-api-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-log4j12-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\snappy-java-1.1.8.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\trogdor-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-jute-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:52:15,584] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.10\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.10\bin;C:\Program Files\apache-maven-3.6.3\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\sox-14-4-2;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\dotnet\;C:\Users\joaoc\Downloads\apache-zookeeper-3.8.0-bin\bin;C:\Program Files\swipl\bin;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\Scripts\;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\;C:\Users\joaoc\AppData\Local\Microsoft\WindowsApps;C:\Users\joaoc\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\joaoc\AppData\Local\Programs\Julia-1.6.0\bin;C:\Users\joaoc\.dotnet\tools;. (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:52:15,584] INFO Client environment:java.io.tmpdir=C:\Users\joaoc\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:52:15,585] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:52:15,586] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:52:15,586] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:52:15,586] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:52:15,587] INFO Client environment:user.name=joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:52:15,588] INFO Client environment:user.home=C:\Users\joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:52:15,588] INFO Client environment:user.dir=C:\Users\joaoc\Documents\kafka\kfk (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:52:15,589] INFO Client environment:os.memory.free=1009MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:52:15,589] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:52:15,592] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:52:15,594] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2c5529ab (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:52:15,606] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 20:52:15,611] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:52:15,613] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 20:52:15,619] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:52:15,620] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:52:17,661] WARN Session 0x0 for sever localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:779)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-15 20:52:18,774] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:52:18,774] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:52:20,816] WARN Session 0x0 for sever localhost/0:0:0:0:0:0:0:1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:779)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-15 20:52:21,926] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:52:21,926] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:52:23,972] WARN Session 0x0 for sever localhost/0:0:0:0:0:0:0:1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:779)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-15 20:52:25,096] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:52:25,096] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:52:27,142] WARN Session 0x0 for sever localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:779)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-15 20:52:28,251] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:52:28,251] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:52:30,307] WARN Session 0x0 for sever localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:779)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-15 20:52:31,428] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:52:31,428] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:52:33,448] WARN Session 0x0 for sever localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:779)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-15 20:52:33,621] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 20:52:34,556] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:52:34,556] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:52:36,585] WARN An exception was thrown while closing send thread for session 0x0. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:779)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-15 20:53:15,386] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:53:15,388] WARN config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:53:15,397] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:53:15,397] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:53:15,397] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:53:15,397] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:53:15,399] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 20:53:15,399] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 20:53:15,399] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 20:53:15,400] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2022-05-15 20:53:15,404] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2022-05-15 20:53:15,415] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:53:15,415] WARN config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:53:15,416] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:53:15,416] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:53:15,416] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:53:15,417] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 20:53:15,417] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2022-05-15 20:53:15,426] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@62230c58 (org.apache.zookeeper.server.ServerMetrics)
[2022-05-15 20:53:15,428] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-15 20:53:15,438] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:53:15,439] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:53:15,439] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:53:15,440] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:53:15,440] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:53:15,440] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:53:15,440] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:53:15,441] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:53:15,441] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:53:15,441] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:53:20,015] INFO Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:53:20,015] INFO Server environment:host.name=LAPTOP-S01N1QNU (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:53:20,017] INFO Server environment:java.version=11.0.10 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:53:20,018] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:53:20,018] INFO Server environment:java.home=C:\Program Files\Java\jdk-11.0.10 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:53:20,019] INFO Server environment:java.class.path=C:\Users\joaoc\Documents\kafka\kfk\libs\activation-1.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\aopalliance-repackaged-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\argparse4j-0.7.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\audience-annotations-0.5.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-cli-1.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-lang3-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-basic-auth-extension-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-file-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-json-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-client-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-runtime-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-transforms-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-api-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-locator-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-utils-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-core-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-databind-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-dataformat-csv-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-datatype-jdk8-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-base-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-json-provider-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-jaxb-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-scala_2.12-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.activation-api-1.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.annotation-api-1.3.5.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.inject-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.validation-api-2.0.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javassist-3.27.0-GA.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.servlet-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jaxb-api-2.3.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-client-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-common-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-core-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-hk2-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-server-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-client-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-continuation-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-http-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-io-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-security-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-server-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlet-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlets-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-ajax-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jline-3.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jopt-simple-5.0.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jose4j-0.7.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-clients-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-log4j-appender-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-metadata-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-raft-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-server-common-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-shell-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-examples-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-scala_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-test-utils-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-tools-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\log4j-1.2.17.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\lz4-java-1.8.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\maven-artifact-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-2.2.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-4.1.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-buffer-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-codec-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-handler-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-resolver-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-epoll-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-unix-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\osgi-resource-locator-1.0.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\paranamer-2.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\plexus-utils-3.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\reflections-0.9.12.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\rocksdbjni-6.22.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-collection-compat_2.12-2.4.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-java8-compat_2.12-1.0.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-library-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-logging_2.12-3.9.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-reflect-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-api-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-log4j12-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\snappy-java-1.1.8.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\trogdor-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-jute-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:53:20,020] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-11.0.10\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.10\bin;C:\Program Files\apache-maven-3.6.3\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\sox-14-4-2;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\dotnet\;C:\Users\joaoc\Downloads\apache-zookeeper-3.8.0-bin\bin;C:\Program Files\swipl\bin;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\Scripts\;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\;C:\Users\joaoc\AppData\Local\Microsoft\WindowsApps;C:\Users\joaoc\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\joaoc\AppData\Local\Programs\Julia-1.6.0\bin;C:\Users\joaoc\.dotnet\tools;. (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:53:20,021] INFO Server environment:java.io.tmpdir=C:\Users\joaoc\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:53:20,021] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:53:20,022] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:53:20,022] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:53:20,028] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:53:20,028] INFO Server environment:user.name=joaoc (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:53:20,029] INFO Server environment:user.home=C:\Users\joaoc (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:53:20,030] INFO Server environment:user.dir=C:\Users\joaoc\Documents\kafka\kfk (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:53:20,030] INFO Server environment:os.memory.free=489MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:53:20,030] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:53:20,031] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:53:20,034] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:53:20,034] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:53:20,035] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:53:20,037] INFO zookeeper.flushDelay=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:53:20,037] INFO zookeeper.maxWriteQueuePollTime=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:53:20,038] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:53:20,038] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:53:20,040] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2022-05-15 20:53:20,042] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:53:20,042] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:53:20,044] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-15 20:53:20,044] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-15 20:53:20,047] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 20:53:20,049] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 20:53:20,049] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 20:53:20,050] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 20:53:20,051] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 20:53:20,051] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 20:53:20,053] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:53:20,053] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:53:20,054] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 clientPortListenBacklog -1 datadir C:\Users\joaoc\Documents\kafka\kfk\zookeeper\version-2 snapdir C:\Users\joaoc\Documents\kafka\kfk\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:53:20,069] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-15 20:53:20,070] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-15 20:53:20,072] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-15 20:53:20,076] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-15 20:53:20,097] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2022-05-15 20:53:20,097] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2022-05-15 20:53:20,100] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-15 20:53:20,100] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-15 20:53:20,106] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2022-05-15 20:53:20,107] INFO Snapshotting: 0x0 to C:\Users\joaoc\Documents\kafka\kfk\zookeeper\version-2\snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-15 20:53:20,112] INFO Snapshot loaded in 11 ms, highest zxid is 0x0, digest is 1371985504 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-15 20:53:20,112] INFO Snapshotting: 0x0 to C:\Users\joaoc\Documents\kafka\kfk\zookeeper\version-2\snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-15 20:53:20,114] INFO Snapshot taken in 2 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 20:53:20,123] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2022-05-15 20:53:20,124] INFO zookeeper.request_throttler.shutdownTimeout = 10000 (org.apache.zookeeper.server.RequestThrottler)
[2022-05-15 20:53:20,139] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2022-05-15 20:53:20,140] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2022-05-15 20:53:20,515] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 20:53:20,850] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 20:53:20,920] INFO starting (kafka.server.KafkaServer)
[2022-05-15 20:53:20,921] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 20:53:20,935] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 20:53:25,486] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:53:25,486] INFO Client environment:host.name=LAPTOP-S01N1QNU (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:53:25,487] INFO Client environment:java.version=11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:53:25,487] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:53:25,487] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:53:25,487] INFO Client environment:java.class.path=C:\Users\joaoc\Documents\kafka\kfk\libs\activation-1.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\aopalliance-repackaged-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\argparse4j-0.7.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\audience-annotations-0.5.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-cli-1.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-lang3-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-basic-auth-extension-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-file-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-json-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-client-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-runtime-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-transforms-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-api-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-locator-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-utils-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-core-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-databind-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-dataformat-csv-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-datatype-jdk8-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-base-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-json-provider-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-jaxb-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-scala_2.12-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.activation-api-1.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.annotation-api-1.3.5.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.inject-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.validation-api-2.0.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javassist-3.27.0-GA.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.servlet-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jaxb-api-2.3.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-client-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-common-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-core-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-hk2-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-server-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-client-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-continuation-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-http-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-io-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-security-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-server-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlet-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlets-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-ajax-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jline-3.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jopt-simple-5.0.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jose4j-0.7.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-clients-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-log4j-appender-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-metadata-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-raft-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-server-common-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-shell-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-examples-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-scala_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-test-utils-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-tools-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\log4j-1.2.17.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\lz4-java-1.8.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\maven-artifact-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-2.2.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-4.1.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-buffer-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-codec-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-handler-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-resolver-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-epoll-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-unix-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\osgi-resource-locator-1.0.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\paranamer-2.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\plexus-utils-3.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\reflections-0.9.12.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\rocksdbjni-6.22.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-collection-compat_2.12-2.4.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-java8-compat_2.12-1.0.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-library-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-logging_2.12-3.9.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-reflect-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-api-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-log4j12-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\snappy-java-1.1.8.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\trogdor-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-jute-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:53:25,488] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.10\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.10\bin;C:\Program Files\apache-maven-3.6.3\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\sox-14-4-2;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\dotnet\;C:\Users\joaoc\Downloads\apache-zookeeper-3.8.0-bin\bin;C:\Program Files\swipl\bin;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\Scripts\;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\;C:\Users\joaoc\AppData\Local\Microsoft\WindowsApps;C:\Users\joaoc\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\joaoc\AppData\Local\Programs\Julia-1.6.0\bin;C:\Users\joaoc\.dotnet\tools;. (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:53:25,489] INFO Client environment:java.io.tmpdir=C:\Users\joaoc\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:53:25,490] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:53:25,490] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:53:25,490] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:53:25,491] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:53:25,491] INFO Client environment:user.name=joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:53:25,491] INFO Client environment:user.home=C:\Users\joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:53:25,492] INFO Client environment:user.dir=C:\Users\joaoc\Documents\kafka\kfk (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:53:25,492] INFO Client environment:os.memory.free=1010MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:53:25,492] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:53:25,493] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:53:25,495] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2c5529ab (org.apache.zookeeper.ZooKeeper)
[2022-05-15 20:53:25,506] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 20:53:25,510] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:53:25,513] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 20:53:25,519] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:53:25,521] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:53:25,523] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:61872, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:53:25,533] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2022-05-15 20:53:25,547] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, session id = 0x10001b307de0000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 20:53:25,551] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 20:53:25,680] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 20:53:25,820] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
[2022-05-15 20:53:25,821] INFO Cleared cache (kafka.server.FinalizedFeatureCache)
[2022-05-15 20:53:25,956] INFO Cluster ID = mV7o6W7qRSuwNVADHMLh7g (kafka.server.KafkaServer)
[2022-05-15 20:53:25,959] WARN No meta.properties file under dir C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-05-15 20:53:26,023] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 20:53:26,035] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 20:53:26,070] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:53:26,083] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:53:26,085] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:53:26,086] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 20:53:26,101] INFO Log directory C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1 not found, creating it. (kafka.log.LogManager)
[2022-05-15 20:53:26,124] INFO Loading logs from log dirs ArrayBuffer(C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1) (kafka.log.LogManager)
[2022-05-15 20:53:26,128] INFO Attempting recovery for all logs in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1 since no clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 20:53:26,138] INFO Loaded 0 logs in 14ms. (kafka.log.LogManager)
[2022-05-15 20:53:26,140] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 20:53:26,142] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 20:53:26,394] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 20:53:26,531] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 20:53:26,537] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-05-15 20:53:26,560] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 20:53:26,567] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 20:53:26,587] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:53:26,588] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:53:26,589] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:53:26,591] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:53:26,605] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 20:53:31,284] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 20:53:31,305] INFO Stat of the created znode at /brokers/ids/0 is: 25,25,1652644411294,1652644411294,1,0,0,72059462480691200,214,0,25
 (kafka.zk.KafkaZkClient)
[2022-05-15 20:53:31,307] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://LAPTOP-S01N1QNU:9092, czxid (broker epoch): 25 (kafka.zk.KafkaZkClient)
[2022-05-15 20:53:31,359] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:53:31,362] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:53:31,363] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:53:31,371] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2022-05-15 20:53:31,381] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:53:31,385] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:53:31,388] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
[2022-05-15 20:53:31,403] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 20:53:31,408] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 20:53:31,408] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 20:53:31,416] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 20:53:31,436] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 20:53:31,454] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 20:53:31,468] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 20:53:31,474] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 20:53:31,474] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 20:53:31,480] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 20:53:31,481] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 20:53:31,481] INFO Kafka startTimeMs: 1652644411474 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 20:53:31,483] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2022-05-15 20:53:31,556] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 20:53:31,604] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 20:53:32,160] INFO Creating topic Sensor with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2022-05-15 20:53:32,736] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 20:53:33,192] INFO [LogLoader partition=Sensor-0, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:53:33,306] INFO Created log for partition Sensor-0 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\Sensor-0 with properties {} (kafka.log.LogManager)
[2022-05-15 20:53:33,321] INFO [Partition Sensor-0 broker=0] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 20:53:33,329] INFO [Partition Sensor-0 broker=0] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:44,470] INFO Creating topic __consumer_offsets with configuration {compression.type=producer, cleanup.policy=compact, segment.bytes=104857600} and initial partition assignment Map(23 -> ArrayBuffer(0), 32 -> ArrayBuffer(0), 41 -> ArrayBuffer(0), 17 -> ArrayBuffer(0), 8 -> ArrayBuffer(0), 35 -> ArrayBuffer(0), 44 -> ArrayBuffer(0), 26 -> ArrayBuffer(0), 11 -> ArrayBuffer(0), 29 -> ArrayBuffer(0), 38 -> ArrayBuffer(0), 47 -> ArrayBuffer(0), 20 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 5 -> ArrayBuffer(0), 14 -> ArrayBuffer(0), 46 -> ArrayBuffer(0), 49 -> ArrayBuffer(0), 40 -> ArrayBuffer(0), 13 -> ArrayBuffer(0), 4 -> ArrayBuffer(0), 22 -> ArrayBuffer(0), 31 -> ArrayBuffer(0), 16 -> ArrayBuffer(0), 7 -> ArrayBuffer(0), 43 -> ArrayBuffer(0), 25 -> ArrayBuffer(0), 34 -> ArrayBuffer(0), 10 -> ArrayBuffer(0), 37 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 19 -> ArrayBuffer(0), 28 -> ArrayBuffer(0), 45 -> ArrayBuffer(0), 27 -> ArrayBuffer(0), 36 -> ArrayBuffer(0), 18 -> ArrayBuffer(0), 9 -> ArrayBuffer(0), 21 -> ArrayBuffer(0), 48 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 12 -> ArrayBuffer(0), 30 -> ArrayBuffer(0), 39 -> ArrayBuffer(0), 15 -> ArrayBuffer(0), 42 -> ArrayBuffer(0), 24 -> ArrayBuffer(0), 6 -> ArrayBuffer(0), 33 -> ArrayBuffer(0), 0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2022-05-15 20:54:44,598] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2022-05-15 20:54:44,609] INFO [LogLoader partition=__consumer_offsets-0, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:54:44,611] INFO Created log for partition __consumer_offsets-0 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 20:54:44,612] INFO [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2022-05-15 20:54:44,613] INFO [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:44,626] INFO [LogLoader partition=__consumer_offsets-29, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:54:44,627] INFO Created log for partition __consumer_offsets-29 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-29 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 20:54:44,628] INFO [Partition __consumer_offsets-29 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2022-05-15 20:54:44,630] INFO [Partition __consumer_offsets-29 broker=0] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:44,645] INFO [LogLoader partition=__consumer_offsets-48, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:54:44,646] INFO Created log for partition __consumer_offsets-48 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-48 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 20:54:44,647] INFO [Partition __consumer_offsets-48 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2022-05-15 20:54:44,648] INFO [Partition __consumer_offsets-48 broker=0] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:44,661] INFO [LogLoader partition=__consumer_offsets-10, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:54:44,662] INFO Created log for partition __consumer_offsets-10 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-10 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 20:54:44,662] INFO [Partition __consumer_offsets-10 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2022-05-15 20:54:44,663] INFO [Partition __consumer_offsets-10 broker=0] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:44,676] INFO [LogLoader partition=__consumer_offsets-45, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:54:44,678] INFO Created log for partition __consumer_offsets-45 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-45 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 20:54:44,678] INFO [Partition __consumer_offsets-45 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2022-05-15 20:54:44,679] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:44,692] INFO [LogLoader partition=__consumer_offsets-26, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:54:44,694] INFO Created log for partition __consumer_offsets-26 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-26 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 20:54:44,694] INFO [Partition __consumer_offsets-26 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2022-05-15 20:54:44,695] INFO [Partition __consumer_offsets-26 broker=0] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:44,708] INFO [LogLoader partition=__consumer_offsets-7, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:54:44,710] INFO Created log for partition __consumer_offsets-7 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-7 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 20:54:44,710] INFO [Partition __consumer_offsets-7 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2022-05-15 20:54:44,710] INFO [Partition __consumer_offsets-7 broker=0] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:44,723] INFO [LogLoader partition=__consumer_offsets-42, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:54:44,724] INFO Created log for partition __consumer_offsets-42 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-42 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 20:54:44,725] INFO [Partition __consumer_offsets-42 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2022-05-15 20:54:44,725] INFO [Partition __consumer_offsets-42 broker=0] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:44,739] INFO [LogLoader partition=__consumer_offsets-4, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:54:44,741] INFO Created log for partition __consumer_offsets-4 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 20:54:44,741] INFO [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2022-05-15 20:54:44,743] INFO [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:44,754] INFO [LogLoader partition=__consumer_offsets-23, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:54:44,755] INFO Created log for partition __consumer_offsets-23 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-23 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 20:54:44,757] INFO [Partition __consumer_offsets-23 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2022-05-15 20:54:44,758] INFO [Partition __consumer_offsets-23 broker=0] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:44,771] INFO [LogLoader partition=__consumer_offsets-1, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:54:44,773] INFO Created log for partition __consumer_offsets-1 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 20:54:44,773] INFO [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2022-05-15 20:54:44,774] INFO [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:44,786] INFO [LogLoader partition=__consumer_offsets-20, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:54:44,787] INFO Created log for partition __consumer_offsets-20 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-20 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 20:54:44,788] INFO [Partition __consumer_offsets-20 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2022-05-15 20:54:44,788] INFO [Partition __consumer_offsets-20 broker=0] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:44,801] INFO [LogLoader partition=__consumer_offsets-39, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:54:44,802] INFO Created log for partition __consumer_offsets-39 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-39 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 20:54:44,802] INFO [Partition __consumer_offsets-39 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2022-05-15 20:54:44,802] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:44,815] INFO [LogLoader partition=__consumer_offsets-17, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:54:44,816] INFO Created log for partition __consumer_offsets-17 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-17 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 20:54:44,816] INFO [Partition __consumer_offsets-17 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2022-05-15 20:54:44,817] INFO [Partition __consumer_offsets-17 broker=0] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:44,830] INFO [LogLoader partition=__consumer_offsets-36, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:54:44,831] INFO Created log for partition __consumer_offsets-36 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-36 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 20:54:44,831] INFO [Partition __consumer_offsets-36 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2022-05-15 20:54:44,832] INFO [Partition __consumer_offsets-36 broker=0] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:44,844] INFO [LogLoader partition=__consumer_offsets-14, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:54:44,845] INFO Created log for partition __consumer_offsets-14 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-14 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 20:54:44,845] INFO [Partition __consumer_offsets-14 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2022-05-15 20:54:44,846] INFO [Partition __consumer_offsets-14 broker=0] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:44,858] INFO [LogLoader partition=__consumer_offsets-33, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:54:44,859] INFO Created log for partition __consumer_offsets-33 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-33 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 20:54:44,859] INFO [Partition __consumer_offsets-33 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2022-05-15 20:54:44,860] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:44,873] INFO [LogLoader partition=__consumer_offsets-49, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:54:44,874] INFO Created log for partition __consumer_offsets-49 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-49 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 20:54:44,874] INFO [Partition __consumer_offsets-49 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2022-05-15 20:54:44,875] INFO [Partition __consumer_offsets-49 broker=0] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:44,888] INFO [LogLoader partition=__consumer_offsets-11, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:54:44,888] INFO Created log for partition __consumer_offsets-11 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-11 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 20:54:44,889] INFO [Partition __consumer_offsets-11 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2022-05-15 20:54:44,890] INFO [Partition __consumer_offsets-11 broker=0] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:44,904] INFO [LogLoader partition=__consumer_offsets-30, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:54:44,905] INFO Created log for partition __consumer_offsets-30 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-30 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 20:54:44,905] INFO [Partition __consumer_offsets-30 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2022-05-15 20:54:44,905] INFO [Partition __consumer_offsets-30 broker=0] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:44,918] INFO [LogLoader partition=__consumer_offsets-46, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:54:44,919] INFO Created log for partition __consumer_offsets-46 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-46 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 20:54:44,919] INFO [Partition __consumer_offsets-46 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2022-05-15 20:54:44,919] INFO [Partition __consumer_offsets-46 broker=0] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:44,931] INFO [LogLoader partition=__consumer_offsets-27, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:54:44,932] INFO Created log for partition __consumer_offsets-27 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-27 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 20:54:44,933] INFO [Partition __consumer_offsets-27 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2022-05-15 20:54:44,933] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:44,945] INFO [LogLoader partition=__consumer_offsets-8, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:54:44,946] INFO Created log for partition __consumer_offsets-8 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-8 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 20:54:44,946] INFO [Partition __consumer_offsets-8 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2022-05-15 20:54:44,946] INFO [Partition __consumer_offsets-8 broker=0] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:44,959] INFO [LogLoader partition=__consumer_offsets-24, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:54:44,960] INFO Created log for partition __consumer_offsets-24 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-24 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 20:54:44,960] INFO [Partition __consumer_offsets-24 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2022-05-15 20:54:44,961] INFO [Partition __consumer_offsets-24 broker=0] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:44,974] INFO [LogLoader partition=__consumer_offsets-43, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:54:44,975] INFO Created log for partition __consumer_offsets-43 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-43 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 20:54:44,975] INFO [Partition __consumer_offsets-43 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2022-05-15 20:54:44,976] INFO [Partition __consumer_offsets-43 broker=0] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:44,989] INFO [LogLoader partition=__consumer_offsets-5, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:54:44,990] INFO Created log for partition __consumer_offsets-5 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-5 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 20:54:44,990] INFO [Partition __consumer_offsets-5 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2022-05-15 20:54:44,991] INFO [Partition __consumer_offsets-5 broker=0] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:45,003] INFO [LogLoader partition=__consumer_offsets-21, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:54:45,004] INFO Created log for partition __consumer_offsets-21 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-21 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 20:54:45,004] INFO [Partition __consumer_offsets-21 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2022-05-15 20:54:45,005] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:45,018] INFO [LogLoader partition=__consumer_offsets-40, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:54:45,019] INFO Created log for partition __consumer_offsets-40 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-40 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 20:54:45,019] INFO [Partition __consumer_offsets-40 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2022-05-15 20:54:45,019] INFO [Partition __consumer_offsets-40 broker=0] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:45,032] INFO [LogLoader partition=__consumer_offsets-2, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:54:45,034] INFO Created log for partition __consumer_offsets-2 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 20:54:45,034] INFO [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2022-05-15 20:54:45,035] INFO [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:45,047] INFO [LogLoader partition=__consumer_offsets-37, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:54:45,048] INFO Created log for partition __consumer_offsets-37 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-37 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 20:54:45,049] INFO [Partition __consumer_offsets-37 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2022-05-15 20:54:45,049] INFO [Partition __consumer_offsets-37 broker=0] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:45,064] INFO [LogLoader partition=__consumer_offsets-18, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:54:45,065] INFO Created log for partition __consumer_offsets-18 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-18 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 20:54:45,065] INFO [Partition __consumer_offsets-18 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2022-05-15 20:54:45,065] INFO [Partition __consumer_offsets-18 broker=0] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:45,078] INFO [LogLoader partition=__consumer_offsets-34, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:54:45,079] INFO Created log for partition __consumer_offsets-34 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-34 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 20:54:45,079] INFO [Partition __consumer_offsets-34 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2022-05-15 20:54:45,080] INFO [Partition __consumer_offsets-34 broker=0] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:45,092] INFO [LogLoader partition=__consumer_offsets-15, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:54:45,093] INFO Created log for partition __consumer_offsets-15 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-15 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 20:54:45,093] INFO [Partition __consumer_offsets-15 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2022-05-15 20:54:45,094] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:45,106] INFO [LogLoader partition=__consumer_offsets-12, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:54:45,107] INFO Created log for partition __consumer_offsets-12 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-12 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 20:54:45,108] INFO [Partition __consumer_offsets-12 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2022-05-15 20:54:45,108] INFO [Partition __consumer_offsets-12 broker=0] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:45,120] INFO [LogLoader partition=__consumer_offsets-31, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:54:45,121] INFO Created log for partition __consumer_offsets-31 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-31 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 20:54:45,122] INFO [Partition __consumer_offsets-31 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2022-05-15 20:54:45,122] INFO [Partition __consumer_offsets-31 broker=0] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:45,136] INFO [LogLoader partition=__consumer_offsets-9, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:54:45,137] INFO Created log for partition __consumer_offsets-9 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-9 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 20:54:45,137] INFO [Partition __consumer_offsets-9 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2022-05-15 20:54:45,138] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:45,149] INFO [LogLoader partition=__consumer_offsets-47, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:54:45,150] INFO Created log for partition __consumer_offsets-47 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-47 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 20:54:45,150] INFO [Partition __consumer_offsets-47 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2022-05-15 20:54:45,151] INFO [Partition __consumer_offsets-47 broker=0] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:45,165] INFO [LogLoader partition=__consumer_offsets-19, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:54:45,168] INFO Created log for partition __consumer_offsets-19 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-19 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 20:54:45,168] INFO [Partition __consumer_offsets-19 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2022-05-15 20:54:45,168] INFO [Partition __consumer_offsets-19 broker=0] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:45,182] INFO [LogLoader partition=__consumer_offsets-28, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:54:45,182] INFO Created log for partition __consumer_offsets-28 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-28 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 20:54:45,183] INFO [Partition __consumer_offsets-28 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2022-05-15 20:54:45,184] INFO [Partition __consumer_offsets-28 broker=0] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:45,196] INFO [LogLoader partition=__consumer_offsets-38, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:54:45,197] INFO Created log for partition __consumer_offsets-38 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-38 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 20:54:45,198] INFO [Partition __consumer_offsets-38 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2022-05-15 20:54:45,199] INFO [Partition __consumer_offsets-38 broker=0] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:45,211] INFO [LogLoader partition=__consumer_offsets-35, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:54:45,212] INFO Created log for partition __consumer_offsets-35 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-35 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 20:54:45,212] INFO [Partition __consumer_offsets-35 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2022-05-15 20:54:45,212] INFO [Partition __consumer_offsets-35 broker=0] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:45,225] INFO [LogLoader partition=__consumer_offsets-6, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:54:45,226] INFO Created log for partition __consumer_offsets-6 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-6 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 20:54:45,227] INFO [Partition __consumer_offsets-6 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2022-05-15 20:54:45,227] INFO [Partition __consumer_offsets-6 broker=0] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:45,242] INFO [LogLoader partition=__consumer_offsets-44, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:54:45,242] INFO Created log for partition __consumer_offsets-44 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-44 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 20:54:45,243] INFO [Partition __consumer_offsets-44 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2022-05-15 20:54:45,243] INFO [Partition __consumer_offsets-44 broker=0] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:45,256] INFO [LogLoader partition=__consumer_offsets-25, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:54:45,257] INFO Created log for partition __consumer_offsets-25 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-25 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 20:54:45,257] INFO [Partition __consumer_offsets-25 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2022-05-15 20:54:45,258] INFO [Partition __consumer_offsets-25 broker=0] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:45,271] INFO [LogLoader partition=__consumer_offsets-16, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:54:45,272] INFO Created log for partition __consumer_offsets-16 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-16 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 20:54:45,272] INFO [Partition __consumer_offsets-16 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2022-05-15 20:54:45,272] INFO [Partition __consumer_offsets-16 broker=0] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:45,285] INFO [LogLoader partition=__consumer_offsets-22, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:54:45,285] INFO Created log for partition __consumer_offsets-22 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-22 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 20:54:45,286] INFO [Partition __consumer_offsets-22 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2022-05-15 20:54:45,286] INFO [Partition __consumer_offsets-22 broker=0] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:45,301] INFO [LogLoader partition=__consumer_offsets-41, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:54:45,302] INFO Created log for partition __consumer_offsets-41 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-41 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 20:54:45,302] INFO [Partition __consumer_offsets-41 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2022-05-15 20:54:45,303] INFO [Partition __consumer_offsets-41 broker=0] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:45,315] INFO [LogLoader partition=__consumer_offsets-32, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:54:45,316] INFO Created log for partition __consumer_offsets-32 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-32 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 20:54:45,316] INFO [Partition __consumer_offsets-32 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2022-05-15 20:54:45,317] INFO [Partition __consumer_offsets-32 broker=0] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:45,330] INFO [LogLoader partition=__consumer_offsets-3, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:54:45,331] INFO Created log for partition __consumer_offsets-3 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 20:54:45,331] INFO [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2022-05-15 20:54:45,332] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:45,345] INFO [LogLoader partition=__consumer_offsets-13, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 20:54:45,346] INFO Created log for partition __consumer_offsets-13 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-13 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-15 20:54:45,346] INFO [Partition __consumer_offsets-13 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2022-05-15 20:54:45,346] INFO [Partition __consumer_offsets-13 broker=0] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 20:54:45,353] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 22 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,354] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,355] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 25 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,356] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,357] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 28 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,358] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,358] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 31 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,359] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,360] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 34 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,360] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 5 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,360] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,361] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,361] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 37 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,362] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 4 milliseconds for epoch 0, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,363] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,364] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 4 milliseconds for epoch 0, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,364] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 40 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,365] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,365] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 4 milliseconds for epoch 0, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,365] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 43 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,366] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,366] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,367] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 46 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,367] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,367] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,367] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 49 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,368] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,368] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,369] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,369] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 41 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,370] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,370] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,371] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 44 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,374] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,374] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 4 milliseconds for epoch 0, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,375] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 47 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,376] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,376] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,377] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 1 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,378] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 1 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,378] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,380] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 4 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,380] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,380] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,381] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 7 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,381] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,382] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,383] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 10 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,383] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,384] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,385] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 13 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,385] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,386] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,387] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 16 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,387] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,390] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,391] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 19 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,392] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,391] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,392] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 2 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,393] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,393] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,393] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 5 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,394] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,394] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,394] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 8 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,395] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,395] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,395] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 11 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,396] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,396] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,397] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 14 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,397] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,397] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,398] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 17 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,398] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,398] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,399] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 20 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,399] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,399] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,400] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 23 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,400] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,400] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,401] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 26 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,401] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,401] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,402] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 29 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,402] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,402] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,403] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 32 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,403] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,405] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,406] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 35 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,406] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,406] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,407] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 38 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,408] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,408] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,408] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 0 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,409] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 1 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,409] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,409] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,409] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,410] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,410] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 6 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,411] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,411] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,411] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 9 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,412] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 1 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,412] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,412] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 12 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,413] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 1 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,413] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,413] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 15 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,413] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,414] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,414] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 18 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,414] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,415] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,415] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 21 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,415] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,415] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,416] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 24 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,416] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,417] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,417] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 27 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,417] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,418] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,420] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 30 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,421] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 1 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,421] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,422] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 33 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,422] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,423] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,423] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 36 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,424] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 1 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,424] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,425] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 39 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,425] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,425] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,426] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 42 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,426] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,426] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,427] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 45 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,427] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,427] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,428] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 48 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,428] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,428] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,429] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 20:54:45,474] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group ConsumerGroup in Empty state. Created a new member id consumer-ConsumerGroup-1-601d86c7-6541-43fe-b257-c8216764e81f and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,485] INFO [GroupCoordinator 0]: Preparing to rebalance group ConsumerGroup in state PreparingRebalance with old generation 0 (__consumer_offsets-45) (reason: Adding new member consumer-ConsumerGroup-1-601d86c7-6541-43fe-b257-c8216764e81f with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,492] INFO [GroupCoordinator 0]: Stabilized group ConsumerGroup generation 1 (__consumer_offsets-45) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:54:45,511] INFO [GroupCoordinator 0]: Assignment received from leader consumer-ConsumerGroup-1-601d86c7-6541-43fe-b257-c8216764e81f for group ConsumerGroup for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:55:03,848] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group ConsumerGroup in Stable state. Created a new member id consumer-ConsumerGroup-1-135109fe-f231-4c38-9e7c-00177382a2fa and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:55:03,851] INFO [GroupCoordinator 0]: Preparing to rebalance group ConsumerGroup in state PreparingRebalance with old generation 1 (__consumer_offsets-45) (reason: Adding new member consumer-ConsumerGroup-1-135109fe-f231-4c38-9e7c-00177382a2fa with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:55:37,447] INFO [GroupCoordinator 0]: Member consumer-ConsumerGroup-1-601d86c7-6541-43fe-b257-c8216764e81f in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:55:37,450] INFO [GroupCoordinator 0]: Stabilized group ConsumerGroup generation 2 (__consumer_offsets-45) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:55:37,457] INFO [GroupCoordinator 0]: Assignment received from leader consumer-ConsumerGroup-1-135109fe-f231-4c38-9e7c-00177382a2fa for group ConsumerGroup for generation 2. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:57:01,766] INFO [GroupCoordinator 0]: Member consumer-ConsumerGroup-1-135109fe-f231-4c38-9e7c-00177382a2fa in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:57:01,766] INFO [GroupCoordinator 0]: Preparing to rebalance group ConsumerGroup in state PreparingRebalance with old generation 2 (__consumer_offsets-45) (reason: removing member consumer-ConsumerGroup-1-135109fe-f231-4c38-9e7c-00177382a2fa on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 20:57:01,768] INFO [GroupCoordinator 0]: Group ConsumerGroup with generation 3 is now empty (__consumer_offsets-45) (kafka.coordinator.group.GroupCoordinator)
