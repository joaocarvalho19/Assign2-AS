[2022-05-12 16:09:07,545] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-12 16:09:07,549] WARN config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-12 16:09:07,558] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-12 16:09:07,559] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-12 16:09:07,559] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-12 16:09:07,559] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-12 16:09:07,562] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-12 16:09:07,562] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-12 16:09:07,562] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-12 16:09:07,562] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2022-05-12 16:09:07,566] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2022-05-12 16:09:07,577] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-12 16:09:07,577] WARN config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-12 16:09:07,579] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-12 16:09:07,579] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-12 16:09:07,579] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-12 16:09:07,579] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-12 16:09:07,579] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2022-05-12 16:09:07,591] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@2cd2a21f (org.apache.zookeeper.server.ServerMetrics)
[2022-05-12 16:09:07,595] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-12 16:09:07,607] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 16:09:07,608] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 16:09:07,608] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 16:09:07,609] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 16:09:07,609] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 16:09:07,610] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 16:09:07,610] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 16:09:07,610] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 16:09:07,611] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 16:09:07,611] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 16:09:07,614] INFO Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 16:09:07,614] INFO Server environment:host.name=LAPTOP-S01N1QNU.mshome.net (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 16:09:07,615] INFO Server environment:java.version=11.0.10 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 16:09:07,615] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 16:09:07,615] INFO Server environment:java.home=C:\Program Files\Java\jdk-11.0.10 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 16:09:07,616] INFO Server environment:java.class.path=C:\Users\joaoc\Documents\kafka\kfk\libs\activation-1.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\aopalliance-repackaged-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\argparse4j-0.7.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\audience-annotations-0.5.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-cli-1.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-lang3-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-basic-auth-extension-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-file-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-json-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-client-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-runtime-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-transforms-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-api-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-locator-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-utils-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-core-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-databind-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-dataformat-csv-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-datatype-jdk8-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-base-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-json-provider-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-jaxb-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-scala_2.12-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.activation-api-1.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.annotation-api-1.3.5.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.inject-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.validation-api-2.0.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javassist-3.27.0-GA.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.servlet-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jaxb-api-2.3.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-client-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-common-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-core-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-hk2-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-server-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-client-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-continuation-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-http-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-io-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-security-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-server-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlet-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlets-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-ajax-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jline-3.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jopt-simple-5.0.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jose4j-0.7.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-clients-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-log4j-appender-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-metadata-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-raft-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-server-common-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-shell-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-examples-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-scala_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-test-utils-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-tools-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\log4j-1.2.17.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\lz4-java-1.8.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\maven-artifact-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-2.2.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-4.1.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-buffer-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-codec-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-handler-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-resolver-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-epoll-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-unix-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\osgi-resource-locator-1.0.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\paranamer-2.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\plexus-utils-3.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\reflections-0.9.12.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\rocksdbjni-6.22.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-collection-compat_2.12-2.4.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-java8-compat_2.12-1.0.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-library-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-logging_2.12-3.9.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-reflect-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-api-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-log4j12-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\snappy-java-1.1.8.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\trogdor-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-jute-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 16:09:07,617] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-11.0.10\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.10\bin;C:\Program Files\apache-maven-3.6.3\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\sox-14-4-2;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\dotnet\;C:\Users\joaoc\Downloads\apache-zookeeper-3.8.0-bin\bin;C:\Program Files\swipl\bin;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\Scripts\;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\;C:\Users\joaoc\AppData\Local\Microsoft\WindowsApps;C:\Users\joaoc\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\joaoc\AppData\Local\Programs\Julia-1.6.0\bin;C:\Users\joaoc\.dotnet\tools;. (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 16:09:07,617] INFO Server environment:java.io.tmpdir=C:\Users\joaoc\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 16:09:07,618] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 16:09:07,618] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 16:09:07,618] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 16:09:07,619] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 16:09:07,619] INFO Server environment:user.name=joaoc (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 16:09:07,619] INFO Server environment:user.home=C:\Users\joaoc (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 16:09:07,620] INFO Server environment:user.dir=C:\Users\joaoc\Documents\kafka\kfk (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 16:09:07,621] INFO Server environment:os.memory.free=488MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 16:09:07,621] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 16:09:07,621] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 16:09:07,622] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 16:09:07,622] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 16:09:07,623] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 16:09:07,623] INFO zookeeper.flushDelay=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 16:09:07,624] INFO zookeeper.maxWriteQueuePollTime=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 16:09:07,624] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 16:09:07,624] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 16:09:07,626] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2022-05-12 16:09:07,627] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 16:09:07,628] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 16:09:07,632] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-12 16:09:07,633] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-12 16:09:07,634] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-12 16:09:07,634] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-12 16:09:07,635] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-12 16:09:07,635] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-12 16:09:07,636] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-12 16:09:07,636] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-12 16:09:07,638] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 16:09:07,638] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 16:09:07,638] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 clientPortListenBacklog -1 datadir C:\Users\joaoc\Documents\kafka\kfk\zookeeper\version-2 snapdir C:\Users\joaoc\Documents\kafka\kfk\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 16:09:07,654] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-12 16:09:07,656] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-12 16:09:07,657] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-12 16:09:07,667] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-12 16:09:07,685] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2022-05-12 16:09:07,686] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2022-05-12 16:09:07,687] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-12 16:09:07,687] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-12 16:09:07,694] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2022-05-12 16:09:07,694] INFO Snapshotting: 0x0 to C:\Users\joaoc\Documents\kafka\kfk\zookeeper\version-2\snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-12 16:09:07,699] INFO Snapshot loaded in 11 ms, highest zxid is 0x0, digest is 1371985504 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-12 16:09:07,699] INFO Snapshotting: 0x0 to C:\Users\joaoc\Documents\kafka\kfk\zookeeper\version-2\snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-12 16:09:07,702] INFO Snapshot taken in 3 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 16:09:07,713] INFO zookeeper.request_throttler.shutdownTimeout = 10000 (org.apache.zookeeper.server.RequestThrottler)
[2022-05-12 16:09:07,712] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2022-05-12 16:09:07,727] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2022-05-12 16:09:07,728] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2022-05-12 16:09:21,046] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-12 16:09:21,097] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-12 16:09:21,109] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-12 16:09:21,111] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-12 16:09:21,129] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-12 16:09:21,135] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-12 16:09:21,757] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-12 16:09:21,757] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-12 16:09:21,758] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-12 16:09:21,758] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-12 16:09:21,759] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-12 16:09:21,778] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-12 16:09:21,922] INFO starting (kafka.server.KafkaServer)
[2022-05-12 16:09:21,923] INFO starting (kafka.server.KafkaServer)
[2022-05-12 16:09:21,923] INFO starting (kafka.server.KafkaServer)
[2022-05-12 16:09:21,923] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-12 16:09:21,924] INFO starting (kafka.server.KafkaServer)
[2022-05-12 16:09:21,924] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-12 16:09:21,924] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-12 16:09:21,924] INFO starting (kafka.server.KafkaServer)
[2022-05-12 16:09:21,925] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-12 16:09:21,925] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-12 16:09:21,942] INFO starting (kafka.server.KafkaServer)
[2022-05-12 16:09:21,943] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-12 16:09:21,952] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-12 16:09:21,953] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-12 16:09:21,953] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-12 16:09:21,954] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-12 16:09:21,954] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-12 16:09:21,960] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,961] INFO Client environment:host.name=LAPTOP-S01N1QNU.mshome.net (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,961] INFO Client environment:java.version=11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,961] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,961] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,963] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,961] INFO Client environment:java.class.path=C:\Users\joaoc\Documents\kafka\kfk\libs\activation-1.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\aopalliance-repackaged-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\argparse4j-0.7.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\audience-annotations-0.5.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-cli-1.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-lang3-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-basic-auth-extension-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-file-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-json-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-client-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-runtime-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-transforms-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-api-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-locator-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-utils-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-core-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-databind-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-dataformat-csv-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-datatype-jdk8-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-base-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-json-provider-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-jaxb-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-scala_2.12-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.activation-api-1.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.annotation-api-1.3.5.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.inject-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.validation-api-2.0.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javassist-3.27.0-GA.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.servlet-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jaxb-api-2.3.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-client-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-common-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-core-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-hk2-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-server-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-client-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-continuation-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-http-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-io-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-security-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-server-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlet-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlets-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-ajax-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jline-3.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jopt-simple-5.0.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jose4j-0.7.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-clients-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-log4j-appender-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-metadata-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-raft-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-server-common-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-shell-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-examples-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-scala_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-test-utils-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-tools-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\log4j-1.2.17.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\lz4-java-1.8.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\maven-artifact-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-2.2.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-4.1.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-buffer-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-codec-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-handler-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-resolver-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-epoll-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-unix-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\osgi-resource-locator-1.0.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\paranamer-2.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\plexus-utils-3.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\reflections-0.9.12.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\rocksdbjni-6.22.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-collection-compat_2.12-2.4.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-java8-compat_2.12-1.0.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-library-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-logging_2.12-3.9.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-reflect-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-api-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-log4j12-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\snappy-java-1.1.8.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\trogdor-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-jute-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,963] INFO Client environment:host.name=LAPTOP-S01N1QNU.mshome.net (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,963] INFO Client environment:java.version=11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,963] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,963] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,963] INFO Client environment:host.name=LAPTOP-S01N1QNU.mshome.net (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,963] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.10\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.10\bin;C:\Program Files\apache-maven-3.6.3\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\sox-14-4-2;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\dotnet\;C:\Users\joaoc\Downloads\apache-zookeeper-3.8.0-bin\bin;C:\Program Files\swipl\bin;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\Scripts\;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\;C:\Users\joaoc\AppData\Local\Microsoft\WindowsApps;C:\Users\joaoc\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\joaoc\AppData\Local\Programs\Julia-1.6.0\bin;C:\Users\joaoc\.dotnet\tools;. (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,963] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,963] INFO Client environment:java.version=11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,964] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,964] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,964] INFO Client environment:java.io.tmpdir=C:\Users\joaoc\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,964] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,964] INFO Client environment:host.name=LAPTOP-S01N1QNU.mshome.net (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,964] INFO Client environment:java.version=11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,964] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,964] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,965] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,965] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,965] INFO Client environment:host.name=LAPTOP-S01N1QNU.mshome.net (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,964] INFO Client environment:java.class.path=C:\Users\joaoc\Documents\kafka\kfk\libs\activation-1.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\aopalliance-repackaged-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\argparse4j-0.7.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\audience-annotations-0.5.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-cli-1.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-lang3-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-basic-auth-extension-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-file-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-json-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-client-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-runtime-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-transforms-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-api-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-locator-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-utils-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-core-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-databind-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-dataformat-csv-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-datatype-jdk8-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-base-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-json-provider-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-jaxb-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-scala_2.12-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.activation-api-1.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.annotation-api-1.3.5.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.inject-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.validation-api-2.0.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javassist-3.27.0-GA.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.servlet-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jaxb-api-2.3.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-client-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-common-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-core-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-hk2-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-server-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-client-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-continuation-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-http-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-io-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-security-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-server-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlet-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlets-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-ajax-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jline-3.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jopt-simple-5.0.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jose4j-0.7.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-clients-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-log4j-appender-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-metadata-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-raft-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-server-common-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-shell-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-examples-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-scala_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-test-utils-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-tools-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\log4j-1.2.17.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\lz4-java-1.8.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\maven-artifact-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-2.2.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-4.1.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-buffer-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-codec-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-handler-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-resolver-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-epoll-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-unix-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\osgi-resource-locator-1.0.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\paranamer-2.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\plexus-utils-3.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\reflections-0.9.12.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\rocksdbjni-6.22.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-collection-compat_2.12-2.4.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-java8-compat_2.12-1.0.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-library-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-logging_2.12-3.9.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-reflect-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-api-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-log4j12-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\snappy-java-1.1.8.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\trogdor-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-jute-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,965] INFO Client environment:java.version=11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,964] INFO Client environment:java.class.path=C:\Users\joaoc\Documents\kafka\kfk\libs\activation-1.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\aopalliance-repackaged-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\argparse4j-0.7.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\audience-annotations-0.5.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-cli-1.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-lang3-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-basic-auth-extension-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-file-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-json-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-client-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-runtime-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-transforms-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-api-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-locator-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-utils-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-core-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-databind-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-dataformat-csv-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-datatype-jdk8-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-base-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-json-provider-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-jaxb-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-scala_2.12-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.activation-api-1.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.annotation-api-1.3.5.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.inject-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.validation-api-2.0.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javassist-3.27.0-GA.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.servlet-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jaxb-api-2.3.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-client-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-common-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-core-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-hk2-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-server-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-client-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-continuation-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-http-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-io-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-security-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-server-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlet-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlets-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-ajax-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jline-3.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jopt-simple-5.0.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jose4j-0.7.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-clients-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-log4j-appender-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-metadata-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-raft-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-server-common-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-shell-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-examples-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-scala_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-test-utils-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-tools-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\log4j-1.2.17.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\lz4-java-1.8.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\maven-artifact-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-2.2.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-4.1.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-buffer-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-codec-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-handler-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-resolver-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-epoll-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-unix-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\osgi-resource-locator-1.0.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\paranamer-2.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\plexus-utils-3.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\reflections-0.9.12.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\rocksdbjni-6.22.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-collection-compat_2.12-2.4.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-java8-compat_2.12-1.0.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-library-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-logging_2.12-3.9.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-reflect-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-api-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-log4j12-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\snappy-java-1.1.8.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\trogdor-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-jute-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,966] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,965] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,966] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,965] INFO Client environment:java.class.path=C:\Users\joaoc\Documents\kafka\kfk\libs\activation-1.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\aopalliance-repackaged-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\argparse4j-0.7.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\audience-annotations-0.5.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-cli-1.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-lang3-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-basic-auth-extension-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-file-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-json-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-client-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-runtime-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-transforms-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-api-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-locator-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-utils-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-core-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-databind-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-dataformat-csv-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-datatype-jdk8-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-base-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-json-provider-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-jaxb-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-scala_2.12-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.activation-api-1.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.annotation-api-1.3.5.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.inject-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.validation-api-2.0.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javassist-3.27.0-GA.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.servlet-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jaxb-api-2.3.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-client-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-common-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-core-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-hk2-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-server-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-client-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-continuation-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-http-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-io-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-security-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-server-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlet-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlets-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-ajax-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jline-3.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jopt-simple-5.0.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jose4j-0.7.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-clients-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-log4j-appender-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-metadata-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-raft-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-server-common-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-shell-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-examples-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-scala_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-test-utils-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-tools-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\log4j-1.2.17.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\lz4-java-1.8.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\maven-artifact-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-2.2.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-4.1.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-buffer-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-codec-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-handler-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-resolver-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-epoll-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-unix-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\osgi-resource-locator-1.0.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\paranamer-2.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\plexus-utils-3.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\reflections-0.9.12.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\rocksdbjni-6.22.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-collection-compat_2.12-2.4.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-java8-compat_2.12-1.0.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-library-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-logging_2.12-3.9.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-reflect-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-api-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-log4j12-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\snappy-java-1.1.8.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\trogdor-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-jute-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,965] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.10\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.10\bin;C:\Program Files\apache-maven-3.6.3\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\sox-14-4-2;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\dotnet\;C:\Users\joaoc\Downloads\apache-zookeeper-3.8.0-bin\bin;C:\Program Files\swipl\bin;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\Scripts\;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\;C:\Users\joaoc\AppData\Local\Microsoft\WindowsApps;C:\Users\joaoc\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\joaoc\AppData\Local\Programs\Julia-1.6.0\bin;C:\Users\joaoc\.dotnet\tools;. (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,966] INFO Client environment:java.class.path=C:\Users\joaoc\Documents\kafka\kfk\libs\activation-1.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\aopalliance-repackaged-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\argparse4j-0.7.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\audience-annotations-0.5.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-cli-1.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-lang3-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-basic-auth-extension-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-file-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-json-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-client-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-runtime-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-transforms-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-api-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-locator-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-utils-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-core-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-databind-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-dataformat-csv-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-datatype-jdk8-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-base-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-json-provider-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-jaxb-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-scala_2.12-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.activation-api-1.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.annotation-api-1.3.5.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.inject-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.validation-api-2.0.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javassist-3.27.0-GA.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.servlet-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jaxb-api-2.3.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-client-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-common-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-core-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-hk2-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-server-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-client-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-continuation-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-http-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-io-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-security-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-server-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlet-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlets-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-ajax-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jline-3.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jopt-simple-5.0.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jose4j-0.7.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-clients-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-log4j-appender-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-metadata-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-raft-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-server-common-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-shell-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-examples-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-scala_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-test-utils-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-tools-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\log4j-1.2.17.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\lz4-java-1.8.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\maven-artifact-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-2.2.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-4.1.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-buffer-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-codec-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-handler-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-resolver-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-epoll-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-unix-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\osgi-resource-locator-1.0.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\paranamer-2.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\plexus-utils-3.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\reflections-0.9.12.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\rocksdbjni-6.22.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-collection-compat_2.12-2.4.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-java8-compat_2.12-1.0.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-library-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-logging_2.12-3.9.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-reflect-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-api-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-log4j12-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\snappy-java-1.1.8.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\trogdor-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-jute-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,966] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.10\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.10\bin;C:\Program Files\apache-maven-3.6.3\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\sox-14-4-2;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\dotnet\;C:\Users\joaoc\Downloads\apache-zookeeper-3.8.0-bin\bin;C:\Program Files\swipl\bin;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\Scripts\;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\;C:\Users\joaoc\AppData\Local\Microsoft\WindowsApps;C:\Users\joaoc\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\joaoc\AppData\Local\Programs\Julia-1.6.0\bin;C:\Users\joaoc\.dotnet\tools;. (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,970] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-12 16:09:21,966] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,975] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,967] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.10\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.10\bin;C:\Program Files\apache-maven-3.6.3\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\sox-14-4-2;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\dotnet\;C:\Users\joaoc\Downloads\apache-zookeeper-3.8.0-bin\bin;C:\Program Files\swipl\bin;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\Scripts\;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\;C:\Users\joaoc\AppData\Local\Microsoft\WindowsApps;C:\Users\joaoc\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\joaoc\AppData\Local\Programs\Julia-1.6.0\bin;C:\Users\joaoc\.dotnet\tools;. (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,980] INFO Client environment:host.name=LAPTOP-S01N1QNU.mshome.net (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,980] INFO Client environment:java.version=11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,980] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,968] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.10\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.10\bin;C:\Program Files\apache-maven-3.6.3\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\sox-14-4-2;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\dotnet\;C:\Users\joaoc\Downloads\apache-zookeeper-3.8.0-bin\bin;C:\Program Files\swipl\bin;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\Scripts\;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\;C:\Users\joaoc\AppData\Local\Microsoft\WindowsApps;C:\Users\joaoc\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\joaoc\AppData\Local\Programs\Julia-1.6.0\bin;C:\Users\joaoc\.dotnet\tools;. (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,968] INFO Client environment:java.io.tmpdir=C:\Users\joaoc\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,980] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,969] INFO Client environment:java.io.tmpdir=C:\Users\joaoc\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,981] INFO Client environment:java.class.path=C:\Users\joaoc\Documents\kafka\kfk\libs\activation-1.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\aopalliance-repackaged-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\argparse4j-0.7.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\audience-annotations-0.5.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-cli-1.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-lang3-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-basic-auth-extension-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-file-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-json-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-client-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-runtime-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-transforms-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-api-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-locator-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-utils-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-core-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-databind-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-dataformat-csv-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-datatype-jdk8-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-base-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-json-provider-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-jaxb-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-scala_2.12-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.activation-api-1.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.annotation-api-1.3.5.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.inject-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.validation-api-2.0.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javassist-3.27.0-GA.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.servlet-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jaxb-api-2.3.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-client-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-common-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-core-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-hk2-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-server-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-client-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-continuation-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-http-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-io-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-security-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-server-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlet-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlets-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-ajax-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jline-3.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jopt-simple-5.0.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jose4j-0.7.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-clients-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-log4j-appender-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-metadata-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-raft-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-server-common-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-shell-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-examples-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-scala_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-test-utils-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-tools-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\log4j-1.2.17.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\lz4-java-1.8.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\maven-artifact-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-2.2.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-4.1.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-buffer-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-codec-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-handler-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-resolver-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-epoll-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-unix-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\osgi-resource-locator-1.0.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\paranamer-2.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\plexus-utils-3.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\reflections-0.9.12.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\rocksdbjni-6.22.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-collection-compat_2.12-2.4.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-java8-compat_2.12-1.0.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-library-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-logging_2.12-3.9.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-reflect-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-api-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-log4j12-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\snappy-java-1.1.8.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\trogdor-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-jute-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,982] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.10\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.10\bin;C:\Program Files\apache-maven-3.6.3\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\sox-14-4-2;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\dotnet\;C:\Users\joaoc\Downloads\apache-zookeeper-3.8.0-bin\bin;C:\Program Files\swipl\bin;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\Scripts\;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\;C:\Users\joaoc\AppData\Local\Microsoft\WindowsApps;C:\Users\joaoc\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\joaoc\AppData\Local\Programs\Julia-1.6.0\bin;C:\Users\joaoc\.dotnet\tools;. (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,985] INFO Client environment:java.io.tmpdir=C:\Users\joaoc\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,986] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,987] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,987] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,988] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,988] INFO Client environment:user.name=joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,989] INFO Client environment:user.home=C:\Users\joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,981] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,979] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,980] INFO Client environment:java.io.tmpdir=C:\Users\joaoc\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,980] INFO Client environment:java.io.tmpdir=C:\Users\joaoc\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:21,981] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,005] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,006] INFO Client environment:user.name=joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,003] INFO Client environment:user.dir=C:\Users\joaoc\Documents\kafka\kfk (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,007] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,007] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,007] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,008] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,008] INFO Client environment:user.home=C:\Users\joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,009] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,009] INFO Client environment:os.memory.free=1010MB (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,027] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,028] INFO Client environment:user.dir=C:\Users\joaoc\Documents\kafka\kfk (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,026] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,049] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,029] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,026] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,049] INFO Client environment:os.memory.free=1010MB (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,049] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,030] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,048] INFO Client environment:user.name=joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,049] INFO Client environment:user.name=joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,051] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,049] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,052] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,074] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,054] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,074] INFO Client environment:user.name=joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,075] INFO Client environment:user.name=joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,073] INFO Client environment:user.home=C:\Users\joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,073] INFO Client environment:user.home=C:\Users\joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,075] INFO Client environment:user.home=C:\Users\joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,078] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2c5529ab (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,077] INFO Client environment:user.home=C:\Users\joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,079] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2c5529ab (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,092] INFO Client environment:user.dir=C:\Users\joaoc\Documents\kafka\kfk (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,092] INFO Client environment:user.dir=C:\Users\joaoc\Documents\kafka\kfk (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,093] INFO Client environment:user.dir=C:\Users\joaoc\Documents\kafka\kfk (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,107] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-12 16:09:22,107] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-12 16:09:22,093] INFO Client environment:user.dir=C:\Users\joaoc\Documents\kafka\kfk (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,111] INFO Client environment:os.memory.free=1010MB (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,116] INFO Client environment:os.memory.free=1009MB (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,109] INFO Client environment:os.memory.free=1009MB (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,109] INFO Client environment:os.memory.free=1010MB (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,121] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-12 16:09:22,122] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-12 16:09:22,117] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,117] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,145] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-12 16:09:22,140] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,141] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,144] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-12 16:09:22,162] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,162] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,174] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-12 16:09:22,178] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,178] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,182] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-12 16:09:22,184] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2c5529ab (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,184] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2c5529ab (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,188] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-12 16:09:22,198] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2c5529ab (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,198] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2c5529ab (org.apache.zookeeper.ZooKeeper)
[2022-05-12 16:09:22,199] INFO Socket connection established, initiating session, client: /127.0.0.1:50396, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-12 16:09:22,197] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-12 16:09:22,215] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-12 16:09:22,215] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-12 16:09:22,223] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-12 16:09:22,225] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-12 16:09:22,226] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-12 16:09:22,226] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-12 16:09:22,218] INFO Socket connection established, initiating session, client: /127.0.0.1:50402, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-12 16:09:22,231] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-12 16:09:22,230] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-12 16:09:22,234] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2022-05-12 16:09:22,234] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-12 16:09:22,235] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-12 16:09:22,248] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-12 16:09:22,241] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-12 16:09:22,250] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-12 16:09:22,257] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x10066f1e1f10001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-12 16:09:22,257] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x10066f1e1f10000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-12 16:09:22,259] INFO Socket connection established, initiating session, client: /127.0.0.1:50406, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-12 16:09:22,262] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-12 16:09:22,265] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-12 16:09:22,265] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-12 16:09:22,244] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-12 16:09:22,275] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x10066f1e1f10002, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-12 16:09:22,263] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-12 16:09:22,280] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-12 16:09:22,280] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:50407, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-12 16:09:22,280] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-12 16:09:22,283] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-12 16:09:22,281] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-12 16:09:22,282] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-12 16:09:22,294] INFO Socket connection established, initiating session, client: /127.0.0.1:50409, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-12 16:09:22,292] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:50408, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-12 16:09:22,295] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, session id = 0x10066f1e1f10003, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-12 16:09:22,303] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-12 16:09:22,307] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, session id = 0x10066f1e1f10005, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-12 16:09:22,307] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x10066f1e1f10004, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-12 16:09:22,314] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-12 16:09:22,314] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-12 16:09:22,441] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-12 16:09:22,441] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-12 16:09:22,441] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-12 16:09:22,441] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-12 16:09:22,441] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-12 16:09:22,444] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-12 16:09:22,462] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
[2022-05-12 16:09:22,462] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
[2022-05-12 16:09:22,463] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
[2022-05-12 16:09:22,464] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
[2022-05-12 16:09:22,464] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
[2022-05-12 16:09:22,464] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
[2022-05-12 16:09:22,465] INFO Cleared cache (kafka.server.FinalizedFeatureCache)
[2022-05-12 16:09:22,466] INFO Cleared cache (kafka.server.FinalizedFeatureCache)
[2022-05-12 16:09:22,466] INFO Cleared cache (kafka.server.FinalizedFeatureCache)
[2022-05-12 16:09:22,466] INFO Cleared cache (kafka.server.FinalizedFeatureCache)
[2022-05-12 16:09:22,466] INFO Cleared cache (kafka.server.FinalizedFeatureCache)
[2022-05-12 16:09:22,466] INFO Cleared cache (kafka.server.FinalizedFeatureCache)
[2022-05-12 16:09:22,690] INFO Cluster ID = 11fjR8enRGaB8lPCedqidA (kafka.server.KafkaServer)
[2022-05-12 16:09:22,697] WARN No meta.properties file under dir C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-05-12 16:09:22,730] INFO Cluster ID = 11fjR8enRGaB8lPCedqidA (kafka.server.KafkaServer)
[2022-05-12 16:09:22,730] INFO Cluster ID = 11fjR8enRGaB8lPCedqidA (kafka.server.KafkaServer)
[2022-05-12 16:09:22,730] INFO Cluster ID = 11fjR8enRGaB8lPCedqidA (kafka.server.KafkaServer)
[2022-05-12 16:09:22,730] INFO Cluster ID = 11fjR8enRGaB8lPCedqidA (kafka.server.KafkaServer)
[2022-05-12 16:09:22,731] INFO Cluster ID = 11fjR8enRGaB8lPCedqidA (kafka.server.KafkaServer)
[2022-05-12 16:09:22,736] WARN No meta.properties file under dir C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-05-12 16:09:22,736] WARN No meta.properties file under dir C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-05-12 16:09:22,735] WARN No meta.properties file under dir C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-05-12 16:09:22,736] WARN No meta.properties file under dir C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-05-12 16:09:22,737] WARN No meta.properties file under dir C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-05-12 16:09:22,832] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-12 16:09:22,861] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-12 16:09:22,877] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 4
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-12 16:09:22,878] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 3
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-12 16:09:22,879] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-12 16:09:22,884] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs6
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-12 16:09:22,891] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-12 16:09:22,906] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 4
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-12 16:09:22,913] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.serv[2022-05-12 16:09:22,914] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs6
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
er.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-12 16:09:22,911] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 3
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-12 16:09:22,917] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-12 16:09:22,940] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-12 16:09:22,965] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-12 16:09:22,965] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-12 16:09:22,965] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-12 16:09:22,989] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-12 16:09:22,993] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-12 16:09:22,994] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-12 16:09:22,997] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-12 16:09:22,982] INFO Log directory C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2 not found, creating it. (kafka.log.LogManager)
[2022-05-12 16:09:23,017] INFO Log directory C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5 not found, creating it. (kafka.log.LogManager)
[2022-05-12 16:09:23,018] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-12 16:09:23,019] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-12 16:09:23,019] INFO Log directory C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6 not found, creating it. (kafka.log.LogManager)
[2022-05-12 16:09:23,018] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-12 16:09:22,993] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-12 16:09:23,019] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-12 16:09:23,024] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-12 16:09:23,020] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-12 16:09:23,018] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-12 16:09:23,020] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-12 16:09:23,034] INFO Loading logs from log dirs ArrayBuffer(C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2) (kafka.log.LogManager)
[2022-05-12 16:09:23,019] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-12 16:09:23,018] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-12 16:09:23,020] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-12 16:09:23,020] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-12 16:09:23,040] INFO Attempting recovery for all logs in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2 since no clean shutdown file was found (kafka.log.LogManager)
[2022-05-12 16:09:23,027] INFO Log directory C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4 not found, creating it. (kafka.log.LogManager)
[2022-05-12 16:09:23,020] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-12 16:09:23,049] INFO Loading logs from log dirs ArrayBuffer(C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5) (kafka.log.LogManager)
[2022-05-12 16:09:23,023] INFO Log directory C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3 not found, creating it. (kafka.log.LogManager)
[2022-05-12 16:09:23,049] INFO Loading logs from log dirs ArrayBuffer(C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6) (kafka.log.LogManager)
[2022-05-12 16:09:23,069] INFO Loaded 0 logs in 35ms. (kafka.log.LogManager)
[2022-05-12 16:09:23,048] INFO Log directory C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1 not found, creating it. (kafka.log.LogManager)
[2022-05-12 16:09:23,070] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-12 16:09:23,073] INFO Attempting recovery for all logs in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5 since no clean shutdown file was found (kafka.log.LogManager)
[2022-05-12 16:09:23,077] INFO Attempting recovery for all logs in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6 since no clean shutdown file was found (kafka.log.LogManager)
[2022-05-12 16:09:23,070] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-12 16:09:23,070] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-12 16:09:23,092] INFO Loaded 0 logs in 26ms. (kafka.log.LogManager)
[2022-05-12 16:09:23,096] INFO Loading logs from log dirs ArrayBuffer(C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4) (kafka.log.LogManager)
[2022-05-12 16:09:23,096] INFO Loading logs from log dirs ArrayBuffer(C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3) (kafka.log.LogManager)
[2022-05-12 16:09:23,096] INFO Loaded 0 logs in 27ms. (kafka.log.LogManager)
[2022-05-12 16:09:23,099] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-12 16:09:23,104] INFO Loading logs from log dirs ArrayBuffer(C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1) (kafka.log.LogManager)
[2022-05-12 16:09:23,097] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-12 16:09:23,098] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-12 16:09:23,104] INFO Attempting recovery for all logs in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3 since no clean shutdown file was found (kafka.log.LogManager)
[2022-05-12 16:09:23,104] INFO Attempting recovery for all logs in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4 since no clean shutdown file was found (kafka.log.LogManager)
[2022-05-12 16:09:23,118] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-12 16:09:23,120] INFO Attempting recovery for all logs in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1 since no clean shutdown file was found (kafka.log.LogManager)
[2022-05-12 16:09:23,119] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-12 16:09:23,139] INFO Loaded 0 logs in 42ms. (kafka.log.LogManager)
[2022-05-12 16:09:23,140] INFO Loaded 0 logs in 43ms. (kafka.log.LogManager)
[2022-05-12 16:09:23,141] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-12 16:09:23,142] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-12 16:09:23,153] INFO Loaded 0 logs in 41ms. (kafka.log.LogManager)
[2022-05-12 16:09:23,156] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-12 16:09:23,157] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-12 16:09:23,155] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-12 16:09:23,188] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-12 16:09:23,759] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-12 16:09:23,759] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-12 16:09:23,759] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-12 16:09:23,762] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-12 16:09:23,762] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-12 16:09:23,763] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-12 16:09:24,338] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-12 16:09:24,341] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-12 16:09:24,353] INFO Awaiting socket connections on 0.0.0.0:9097. (kafka.network.Acceptor)
[2022-05-12 16:09:24,348] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-05-12 16:09:24,366] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-12 16:09:24,376] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2022-05-12 16:09:24,380] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-12 16:09:24,382] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-12 16:09:24,400] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-12 16:09:24,389] INFO Awaiting socket connections on 0.0.0.0:9096. (kafka.network.Acceptor)
[2022-05-12 16:09:24,391] INFO Awaiting socket connections on 0.0.0.0:9095. (kafka.network.Acceptor)
[2022-05-12 16:09:24,409] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2022-05-12 16:09:24,415] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-12 16:09:24,418] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-12 16:09:24,432] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-12 16:09:24,442] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-12 16:09:24,442] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-12 16:09:24,448] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-12 16:09:24,457] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-12 16:09:24,458] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-12 16:09:24,463] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-12 16:09:24,476] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-12 16:09:24,477] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-12 16:09:24,479] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 16:09:24,479] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-12 16:09:24,479] INFO [ExpirationReaper-5-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 16:09:24,486] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 16:09:24,503] INFO [ExpirationReaper-4-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 16:09:24,506] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 16:09:24,508] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 16:09:24,518] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 16:09:24,518] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 16:09:24,518] INFO [ExpirationReaper-5-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 16:09:24,518] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 16:09:24,550] INFO [ExpirationReaper-3-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 16:09:24,549] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 16:09:24,549] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 16:09:24,550] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 16:09:24,549] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 16:09:24,549] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 16:09:24,550] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-12 16:09:24,550] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-12 16:09:24,503] INFO [ExpirationReaper-4-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 16:09:24,518] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 16:09:24,518] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 16:09:24,518] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 16:09:24,518] INFO [ExpirationReaper-5-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 16:09:24,580] INFO [ExpirationReaper-4-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 16:09:24,518] INFO [ExpirationReaper-5-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 16:09:24,569] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-12 16:09:24,581] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-12 16:09:24,570] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-12 16:09:24,580] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-12 16:09:24,580] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-12 16:09:24,580] INFO [ExpirationReaper-4-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 16:09:24,584] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-12 16:09:24,553] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-12 16:09:24,602] INFO Creating /brokers/ids/5 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-12 16:09:24,581] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-12 16:09:24,610] INFO Creating /brokers/ids/4 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-12 16:09:24,650] INFO Stat of the created znode at /brokers/ids/2 is: 125,125,1652368164619,1652368164619,1,0,0,72170783101747200,236,0,125
 (kafka.zk.KafkaZkClient)
[2022-05-12 16:09:24,655] INFO Stat of the created znode at /brokers/ids/1 is: 128,128,1652368164624,1652368164624,1,0,0,72170783101747202,236,0,128
 (kafka.zk.KafkaZkClient)
[2022-05-12 16:09:24,657] INFO Stat of the created znode at /brokers/ids/0 is: 127,127,1652368164624,1652368164624,1,0,0,72170783101747201,236,0,127
 (kafka.zk.KafkaZkClient)
[2022-05-12 16:09:24,658] INFO Stat of the created znode at /brokers/ids/3 is: 126,126,1652368164623,1652368164623,1,0,0,72170783101747204,236,0,126
 (kafka.zk.KafkaZkClient)
[2022-05-12 16:09:24,660] INFO Stat of the created znode at /brokers/ids/5 is: 129,129,1652368164645,1652368164645,1,0,0,72170783101747203,236,0,129
 (kafka.zk.KafkaZkClient)
[2022-05-12 16:09:24,656] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://LAPTOP-S01N1QNU.mshome.net:9094, czxid (broker epoch): 125 (kafka.zk.KafkaZkClient)
[2022-05-12 16:09:24,664] INFO Stat of the created znode at /brokers/ids/4 is: 130,130,1652368164651,1652368164651,1,0,0,72170783101747205,236,0,130
 (kafka.zk.KafkaZkClient)
[2022-05-12 16:09:24,659] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://LAPTOP-S01N1QNU.mshome.net:9092, czxid (broker epoch): 127 (kafka.zk.KafkaZkClient)
[2022-05-12 16:09:24,658] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://LAPTOP-S01N1QNU.mshome.net:9093, czxid (broker epoch): 128 (kafka.zk.KafkaZkClient)
[2022-05-12 16:09:24,666] INFO Registered broker 4 at path /brokers/ids/4 with addresses: PLAINTEXT://LAPTOP-S01N1QNU.mshome.net:9096, czxid (broker epoch): 130 (kafka.zk.KafkaZkClient)
[2022-05-12 16:09:24,660] INFO Registered broker 3 at path /brokers/ids/3 with addresses: PLAINTEXT://LAPTOP-S01N1QNU.mshome.net:9095, czxid (broker epoch): 126 (kafka.zk.KafkaZkClient)
[2022-05-12 16:09:24,663] INFO Registered broker 5 at path /brokers/ids/5 with addresses: PLAINTEXT://LAPTOP-S01N1QNU.mshome.net:9097, czxid (broker epoch): 129 (kafka.zk.KafkaZkClient)
[2022-05-12 16:09:24,791] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 16:09:24,797] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 16:09:24,825] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 16:09:24,826] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 16:09:24,831] INFO [ExpirationReaper-4-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 16:09:24,840] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 16:09:24,872] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:09:24,844] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 16:09:24,903] INFO [ExpirationReaper-4-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 16:09:24,895] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2022-05-12 16:09:24,908] INFO [GroupCoordinator 4]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:09:24,903] INFO [ExpirationReaper-4-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 16:09:24,898] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:09:24,845] INFO [ExpirationReaper-3-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 16:09:24,910] INFO [ExpirationReaper-3-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 16:09:24,913] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:09:24,927] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 16:09:24,924] INFO [ExpirationReaper-5-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 16:09:24,943] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:09:24,926] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 16:09:24,949] INFO [GroupCoordinator 4]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:09:24,909] INFO [ExpirationReaper-3-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 16:09:24,927] INFO [ExpirationReaper-5-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 16:09:24,942] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:09:24,965] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
[2022-05-12 16:09:24,965] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
[2022-05-12 16:09:24,966] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
[2022-05-12 16:09:24,926] INFO [ExpirationReaper-5-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 16:09:24,925] INFO [GroupCoordinator 3]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:09:25,006] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-12 16:09:25,000] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-12 16:09:25,008] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-12 16:09:24,950] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:09:24,933] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 16:09:24,964] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
[2022-05-12 16:09:24,965] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
[2022-05-12 16:09:25,002] INFO [TransactionCoordinator id=4] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-12 16:09:25,007] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-12 16:09:25,012] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
[2022-05-12 16:09:25,018] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-12 16:09:25,018] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-12 16:09:24,943] INFO [GroupCoordinator 5]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:09:25,055] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-12 16:09:25,043] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-12 16:09:25,057] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-12 16:09:25,025] INFO [GroupCoordinator 3]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:09:25,063] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-12 16:09:25,048] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-12 16:09:25,039] INFO [TransactionCoordinator id=4] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-12 16:09:25,072] INFO [GroupCoordinator 5]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:09:25,080] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-12 16:09:25,081] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-12 16:09:25,132] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 16:09:25,133] INFO [TransactionCoordinator id=5] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-12 16:09:25,117] INFO [TransactionCoordinator id=3] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-12 16:09:25,091] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-12 16:09:25,142] INFO [Transaction Marker Channel Manager 4]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-12 16:09:25,144] INFO [TransactionCoordinator id=5] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-12 16:09:25,143] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 16:09:25,144] INFO [TransactionCoordinator id=3] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-12 16:09:25,135] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-12 16:09:25,176] INFO [Transaction Marker Channel Manager 3]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-12 16:09:25,182] INFO [Transaction Marker Channel Manager 5]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-12 16:09:25,194] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-12 16:09:25,201] INFO [ExpirationReaper-4-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 16:09:25,210] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 16:09:25,216] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-12 16:09:25,228] INFO [ExpirationReaper-5-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 16:09:25,228] INFO [ExpirationReaper-3-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 16:09:25,222] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-12 16:09:25,250] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-12 16:09:25,254] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-12 16:09:25,263] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-12 16:09:25,267] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-12 16:09:25,269] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-12 16:09:25,273] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-12 16:09:25,281] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-12 16:09:25,288] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-12 16:09:25,289] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-12 16:09:25,291] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-12 16:09:25,292] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-12 16:09:25,286] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-12 16:09:25,304] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-12 16:09:25,301] INFO Kafka startTimeMs: 1652368165270 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-12 16:09:25,329] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-12 16:09:25,332] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-12 16:09:25,326] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2022-05-12 16:09:25,314] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-12 16:09:25,301] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-12 16:09:25,330] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-12 16:09:25,339] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-12 16:09:25,357] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-12 16:09:25,362] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-12 16:09:25,371] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-12 16:09:25,379] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-12 16:09:25,378] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-12 16:09:25,380] INFO Kafka startTimeMs: 1652368165336 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-12 16:09:25,381] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-12 16:09:25,381] INFO Kafka startTimeMs: 1652368165336 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-12 16:09:25,408] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-12 16:09:25,360] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-12 16:09:25,417] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-12 16:09:25,429] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-12 16:09:25,404] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2022-05-12 16:09:25,389] INFO [KafkaServer id=4] started (kafka.server.KafkaServer)
[2022-05-12 16:09:25,410] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-12 16:09:25,433] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-12 16:09:25,474] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-12 16:09:25,477] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-12 16:09:25,477] INFO Kafka startTimeMs: 1652368165400 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-12 16:09:25,443] INFO Kafka startTimeMs: 1652368165338 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-12 16:09:25,492] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2022-05-12 16:09:25,495] INFO [KafkaServer id=3] started (kafka.server.KafkaServer)
[2022-05-12 16:09:25,488] INFO Kafka startTimeMs: 1652368165460 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-12 16:09:25,583] INFO [KafkaServer id=5] started (kafka.server.KafkaServer)
[2022-05-12 16:09:25,560] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU.mshome.net:9094 (id: 2 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-12 16:09:25,622] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU.mshome.net:9094 (id: 2 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-12 16:09:25,658] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU.mshome.net:9094 (id: 2 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-12 16:09:25,660] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU.mshome.net:9094 (id: 2 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-12 16:09:25,671] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU.mshome.net:9094 (id: 2 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-12 16:09:25,683] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU.mshome.net:9094 (id: 2 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-12 16:09:25,684] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU.mshome.net:9094 (id: 2 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-12 16:09:25,696] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU.mshome.net:9094 (id: 2 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-12 16:09:25,705] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU.mshome.net:9094 (id: 2 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-12 16:09:25,743] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU.mshome.net:9094 (id: 2 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-12 16:09:25,806] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU.mshome.net:9094 (id: 2 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-12 16:09:25,806] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU.mshome.net:9094 (id: 2 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-12 16:09:25,880] INFO Creating topic Sensor with configuration {min.insync.replicas=2} and initial partition assignment Map(2 -> ArrayBuffer(5, 0, 4), 5 -> ArrayBuffer(2, 1, 3), 4 -> ArrayBuffer(1, 4, 2), 1 -> ArrayBuffer(0, 3, 5), 3 -> ArrayBuffer(4, 5, 1), 0 -> ArrayBuffer(3, 2, 0)) (kafka.zk.AdminZkClient)
[2022-05-12 16:09:26,018] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-5) (kafka.server.ReplicaFetcherManager)
[2022-05-12 16:09:26,023] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-4) (kafka.server.ReplicaFetcherManager)
[2022-05-12 16:09:26,023] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-12 16:09:26,024] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-12 16:09:26,028] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-12 16:09:26,036] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-2) (kafka.server.ReplicaFetcherManager)
[2022-05-12 16:09:26,134] INFO [LogLoader partition=Sensor-3, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:09:26,135] INFO [LogLoader partition=Sensor-5, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:09:26,136] INFO [LogLoader partition=Sensor-4, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:09:26,136] INFO [LogLoader partition=Sensor-1, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:09:26,139] INFO [LogLoader partition=Sensor-0, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:09:26,145] INFO [LogLoader partition=Sensor-2, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:09:26,167] INFO Created log for partition Sensor-5 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-12 16:09:26,167] INFO Created log for partition Sensor-1 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-12 16:09:26,169] INFO Created log for partition Sensor-4 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-12 16:09:26,167] INFO Created log for partition Sensor-3 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-12 16:09:26,170] INFO Created log for partition Sensor-0 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-12 16:09:26,174] INFO [Partition Sensor-1 broker=0] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-12 16:09:26,173] INFO [Partition Sensor-5 broker=2] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-12 16:09:26,174] INFO [Partition Sensor-4 broker=1] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-12 16:09:26,179] INFO Created log for partition Sensor-2 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-12 16:09:26,175] INFO [Partition Sensor-0 broker=3] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-12 16:09:26,177] INFO [Partition Sensor-3 broker=4] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-12 16:09:26,176] INFO [Partition Sensor-1 broker=0] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:09:26,177] INFO [Partition Sensor-5 broker=2] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:09:26,178] INFO [Partition Sensor-4 broker=1] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:09:26,192] INFO [Partition Sensor-0 broker=3] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:09:26,182] INFO [Partition Sensor-2 broker=5] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-12 16:09:26,192] INFO [Partition Sensor-3 broker=4] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:09:26,221] INFO [Partition Sensor-2 broker=5] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:09:26,249] INFO [LogLoader partition=Sensor-4, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:09:26,249] INFO [LogLoader partition=Sensor-5, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:09:26,249] INFO [LogLoader partition=Sensor-2, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:09:26,253] INFO Created log for partition Sensor-2 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-12 16:09:26,253] INFO Created log for partition Sensor-5 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-12 16:09:26,252] INFO Created log for partition Sensor-4 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-12 16:09:26,261] INFO [Partition Sensor-2 broker=0] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-12 16:09:26,280] INFO [Partition Sensor-2 broker=0] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:09:26,278] INFO [Partition Sensor-5 broker=1] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-12 16:09:26,283] INFO [LogLoader partition=Sensor-1, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:09:26,284] INFO [LogLoader partition=Sensor-4, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:09:26,287] INFO [LogLoader partition=Sensor-1, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:09:26,279] INFO [Partition Sensor-4 broker=2] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-12 16:09:26,298] INFO [LogLoader partition=Sensor-0, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:09:26,283] INFO [Partition Sensor-5 broker=1] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:09:26,289] INFO Created log for partition Sensor-1 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-12 16:09:26,286] INFO Created log for partition Sensor-1 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-12 16:09:26,286] INFO Created log for partition Sensor-4 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-12 16:09:26,301] INFO [Partition Sensor-4 broker=2] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:09:26,302] INFO Created log for partition Sensor-0 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-12 16:09:26,305] INFO [Partition Sensor-1 broker=5] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-12 16:09:26,311] INFO [Partition Sensor-4 broker=4] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-12 16:09:26,311] INFO [Partition Sensor-1 broker=3] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-12 16:09:26,319] INFO [Partition Sensor-1 broker=3] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:09:26,324] INFO [LogLoader partition=Sensor-3, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:09:26,316] INFO [Partition Sensor-0 broker=0] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-12 16:09:26,317] INFO [Partition Sensor-1 broker=5] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:09:26,317] INFO [Partition Sensor-4 broker=4] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:09:26,327] INFO Created log for partition Sensor-3 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-12 16:09:26,330] INFO [Partition Sensor-0 broker=0] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:09:26,339] INFO [LogLoader partition=Sensor-0, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:09:26,342] INFO Created log for partition Sensor-0 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-12 16:09:26,332] INFO [Partition Sensor-3 broker=1] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-12 16:09:26,346] INFO [LogLoader partition=Sensor-5, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:09:26,341] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-0, Sensor-2) (kafka.server.ReplicaFetcherManager)
[2022-05-12 16:09:26,344] INFO [Partition Sensor-0 broker=2] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-12 16:09:26,345] INFO [Partition Sensor-3 broker=1] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:09:26,353] INFO [LogLoader partition=Sensor-3, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:09:26,353] INFO [LogLoader partition=Sensor-2, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:09:26,349] INFO Created log for partition Sensor-5 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-12 16:09:26,354] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-5, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-12 16:09:26,351] INFO [Partition Sensor-0 broker=2] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:09:26,356] INFO Created log for partition Sensor-3 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-12 16:09:26,356] INFO Created log for partition Sensor-2 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-12 16:09:26,354] INFO [Partition Sensor-5 broker=3] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-12 16:09:26,367] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-0, Sensor-4) (kafka.server.ReplicaFetcherManager)
[2022-05-12 16:09:26,366] INFO [Partition Sensor-3 broker=5] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-12 16:09:26,371] INFO [Partition Sensor-2 broker=4] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-12 16:09:26,372] INFO [Partition Sensor-5 broker=3] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:09:26,391] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-12 16:09:26,400] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-12 16:09:26,390] INFO [Partition Sensor-3 broker=5] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:09:26,391] INFO [Partition Sensor-2 broker=4] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:09:26,392] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-5, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-12 16:09:26,397] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 3 for partitions Map(Sensor-0 -> InitialFetchState(Some(0MnGw21FSROwsA7IuGeqYQ),BrokerEndPoint(id=3, host=LAPTOP-S01N1QNU.mshome.net:9095),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-12 16:09:26,399] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Truncating partition Sensor-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-12 16:09:26,407] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-3, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-12 16:09:26,409] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-4, Sensor-2) (kafka.server.ReplicaFetcherManager)
[2022-05-12 16:09:26,404] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 2 for partitions Map(Sensor-5 -> InitialFetchState(Some(0MnGw21FSROwsA7IuGeqYQ),BrokerEndPoint(id=2, host=LAPTOP-S01N1QNU.mshome.net:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-12 16:09:26,421] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-12 16:09:26,414] INFO [UnifiedLog partition=Sensor-0, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-12 16:09:26,405] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition Sensor-5 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-12 16:09:26,425] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 3 for partitions Map(Sensor-0 -> InitialFetchState(Some(0MnGw21FSROwsA7IuGeqYQ),BrokerEndPoint(id=3, host=LAPTOP-S01N1QNU.mshome.net:9095),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-12 16:09:26,418] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 5 for partitions Map(Sensor-2 -> InitialFetchState(Some(0MnGw21FSROwsA7IuGeqYQ),BrokerEndPoint(id=5, host=LAPTOP-S01N1QNU.mshome.net:9097),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-12 16:09:26,423] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 4 for partitions Map(Sensor-3 -> InitialFetchState(Some(0MnGw21FSROwsA7IuGeqYQ),BrokerEndPoint(id=4, host=LAPTOP-S01N1QNU.mshome.net:9096),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-12 16:09:26,428] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Truncating partition Sensor-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-12 16:09:26,455] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-12 16:09:26,455] INFO [ReplicaFetcher replicaId=5, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-12 16:09:26,437] INFO [ReplicaFetcher replicaId=1, leaderId=4, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-12 16:09:26,442] INFO [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-12 16:09:26,442] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 1 for partitions Map(Sensor-4 -> InitialFetchState(Some(0MnGw21FSROwsA7IuGeqYQ),BrokerEndPoint(id=1, host=LAPTOP-S01N1QNU.mshome.net:9093),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-12 16:09:26,465] INFO [ReplicaFetcherManager on broker 5] Added fetcher to broker 0 for partitions Map(Sensor-1 -> InitialFetchState(Some(0MnGw21FSROwsA7IuGeqYQ),BrokerEndPoint(id=0, host=LAPTOP-S01N1QNU.mshome.net:9092),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-12 16:09:26,466] INFO [ReplicaFetcher replicaId=5, leaderId=0, fetcherId=0] Truncating partition Sensor-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-12 16:09:26,463] INFO [ReplicaFetcher replicaId=1, leaderId=4, fetcherId=0] Truncating partition Sensor-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-12 16:09:26,466] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-12 16:09:26,465] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 0 for partitions Map(Sensor-1 -> InitialFetchState(Some(0MnGw21FSROwsA7IuGeqYQ),BrokerEndPoint(id=0, host=LAPTOP-S01N1QNU.mshome.net:9092),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-12 16:09:26,464] INFO [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Truncating partition Sensor-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-12 16:09:26,447] INFO [UnifiedLog partition=Sensor-0, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-12 16:09:26,472] INFO [UnifiedLog partition=Sensor-3, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-12 16:09:26,475] INFO [UnifiedLog partition=Sensor-1, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-12 16:09:26,472] INFO [ReplicaFetcherManager on broker 4] Added fetcher to broker 5 for partitions Map(Sensor-2 -> InitialFetchState(Some(0MnGw21FSROwsA7IuGeqYQ),BrokerEndPoint(id=5, host=LAPTOP-S01N1QNU.mshome.net:9097),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-12 16:09:26,469] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Truncating partition Sensor-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-12 16:09:26,494] INFO [UnifiedLog partition=Sensor-2, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-12 16:09:26,466] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-12 16:09:26,476] INFO [ReplicaFetcherManager on broker 5] Added fetcher to broker 4 for partitions Map(Sensor-3 -> InitialFetchState(Some(0MnGw21FSROwsA7IuGeqYQ),BrokerEndPoint(id=4, host=LAPTOP-S01N1QNU.mshome.net:9096),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-12 16:09:26,436] INFO [UnifiedLog partition=Sensor-5, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-12 16:09:26,503] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-12 16:09:26,481] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Truncating partition Sensor-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-12 16:09:26,507] INFO [UnifiedLog partition=Sensor-1, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-12 16:09:26,517] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition Sensor-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-12 16:09:26,521] INFO [ReplicaFetcher replicaId=4, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-12 16:09:26,504] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-12 16:09:26,551] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Truncating partition Sensor-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-12 16:09:26,542] INFO [UnifiedLog partition=Sensor-4, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-12 16:09:26,563] INFO [UnifiedLog partition=Sensor-3, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-12 16:09:26,507] INFO [ReplicaFetcherManager on broker 4] Added fetcher to broker 1 for partitions Map(Sensor-4 -> InitialFetchState(Some(0MnGw21FSROwsA7IuGeqYQ),BrokerEndPoint(id=1, host=LAPTOP-S01N1QNU.mshome.net:9093),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-12 16:09:26,482] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 2 for partitions Map(Sensor-5 -> InitialFetchState(Some(0MnGw21FSROwsA7IuGeqYQ),BrokerEndPoint(id=2, host=LAPTOP-S01N1QNU.mshome.net:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-12 16:09:26,588] WARN [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-0. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-12 16:09:26,553] INFO [ReplicaFetcher replicaId=4, leaderId=1, fetcherId=0] Truncating partition Sensor-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-12 16:09:26,606] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-5. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-12 16:09:26,584] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-0. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-12 16:09:26,526] INFO [UnifiedLog partition=Sensor-2, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-12 16:09:26,632] WARN [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-3. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-12 16:09:26,519] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Truncating partition Sensor-5 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-12 16:09:26,601] WARN [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-2. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-12 16:09:26,624] WARN [ReplicaFetcher replicaId=1, leaderId=4, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-3. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-12 16:09:26,609] INFO [UnifiedLog partition=Sensor-4, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-12 16:09:26,649] INFO [UnifiedLog partition=Sensor-5, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-12 16:10:02,803] INFO Creating topic __consumer_offsets with configuration {compression.type=producer, cleanup.policy=compact, segment.bytes=104857600} and initial partition assignment Map(23 -> ArrayBuffer(3), 32 -> ArrayBuffer(4), 41 -> ArrayBuffer(3), 17 -> ArrayBuffer(3), 8 -> ArrayBuffer(4), 35 -> ArrayBuffer(3), 44 -> ArrayBuffer(4), 26 -> ArrayBuffer(4), 11 -> ArrayBuffer(3), 29 -> ArrayBuffer(3), 38 -> ArrayBuffer(4), 47 -> ArrayBuffer(3), 20 -> ArrayBuffer(4), 2 -> ArrayBuffer(4), 5 -> ArrayBuffer(3), 14 -> ArrayBuffer(4), 46 -> ArrayBuffer(2), 49 -> ArrayBuffer(5), 40 -> ArrayBuffer(2), 13 -> ArrayBuffer(5), 4 -> ArrayBuffer(2), 22 -> ArrayBuffer(2), 31 -> ArrayBuffer(5), 16 -> ArrayBuffer(2), 7 -> ArrayBuffer(5), 43 -> ArrayBuffer(5), 25 -> ArrayBuffer(5), 34 -> ArrayBuffer(2), 10 -> ArrayBuffer(2), 37 -> ArrayBuffer(5), 1 -> ArrayBuffer(5), 19 -> ArrayBuffer(5), 28 -> ArrayBuffer(2), 45 -> ArrayBuffer(1), 27 -> ArrayBuffer(1), 36 -> ArrayBuffer(0), 18 -> ArrayBuffer(0), 9 -> ArrayBuffer(1), 21 -> ArrayBuffer(1), 48 -> ArrayBuffer(0), 3 -> ArrayBuffer(1), 12 -> ArrayBuffer(0), 30 -> ArrayBuffer(0), 39 -> ArrayBuffer(1), 15 -> ArrayBuffer(1), 42 -> ArrayBuffer(0), 24 -> ArrayBuffer(0), 6 -> ArrayBuffer(0), 33 -> ArrayBuffer(1), 0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2022-05-12 16:10:03,068] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-46, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2022-05-12 16:10:03,071] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-30, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-18, __consumer_offsets-24, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-12) (kafka.server.ReplicaFetcherManager)
[2022-05-12 16:10:03,068] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(__consumer_offsets-21, __consumer_offsets-27, __consumer_offsets-9, __consumer_offsets-33, __consumer_offsets-3, __consumer_offsets-15, __consumer_offsets-39, __consumer_offsets-45) (kafka.server.ReplicaFetcherManager)
[2022-05-12 16:10:03,085] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(__consumer_offsets-8, __consumer_offsets-38, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44, __consumer_offsets-26, __consumer_offsets-32) (kafka.server.ReplicaFetcherManager)
[2022-05-12 16:10:03,092] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(__consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-23, __consumer_offsets-47, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-5, __consumer_offsets-29) (kafka.server.ReplicaFetcherManager)
[2022-05-12 16:10:03,149] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(__consumer_offsets-7, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1) (kafka.server.ReplicaFetcherManager)
[2022-05-12 16:10:03,202] INFO [LogLoader partition=__consumer_offsets-45, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:10:03,215] INFO [LogLoader partition=__consumer_offsets-10, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:10:03,211] INFO Created log for partition __consumer_offsets-45 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\__consumer_offsets-45 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 16:10:03,243] INFO Created log for partition __consumer_offsets-10 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\__consumer_offsets-10 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 16:10:03,259] INFO [Partition __consumer_offsets-10 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2022-05-12 16:10:03,258] INFO [Partition __consumer_offsets-45 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2022-05-12 16:10:03,259] INFO [LogLoader partition=__consumer_offsets-0, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:10:03,265] INFO [LogLoader partition=__consumer_offsets-29, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:10:03,264] INFO [Partition __consumer_offsets-45 broker=1] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:10:03,264] INFO [Partition __consumer_offsets-10 broker=2] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:10:03,295] INFO [LogLoader partition=__consumer_offsets-7, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:10:03,292] INFO [LogLoader partition=__consumer_offsets-26, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:10:03,273] INFO Created log for partition __consumer_offsets-0 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 16:10:03,298] INFO Created log for partition __consumer_offsets-29 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\__consumer_offsets-29 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 16:10:03,326] INFO Created log for partition __consumer_offsets-7 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\__consumer_offsets-7 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 16:10:03,316] INFO Created log for partition __consumer_offsets-26 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\__consumer_offsets-26 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 16:10:03,364] INFO [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2022-05-12 16:10:03,367] INFO [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:10:03,371] INFO [Partition __consumer_offsets-29 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2022-05-12 16:10:03,397] INFO [Partition __consumer_offsets-7 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2022-05-12 16:10:03,401] INFO [Partition __consumer_offsets-29 broker=3] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:10:03,398] INFO [Partition __consumer_offsets-26 broker=4] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2022-05-12 16:10:03,401] INFO [Partition __consumer_offsets-7 broker=5] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:10:03,431] INFO [Partition __consumer_offsets-26 broker=4] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:10:03,472] INFO [LogLoader partition=__consumer_offsets-4, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:10:03,488] INFO Created log for partition __consumer_offsets-4 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 16:10:03,491] INFO [Partition __consumer_offsets-4 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2022-05-12 16:10:03,498] INFO [Partition __consumer_offsets-4 broker=2] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:10:03,538] INFO [LogLoader partition=__consumer_offsets-39, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:10:03,547] INFO Created log for partition __consumer_offsets-39 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\__consumer_offsets-39 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 16:10:03,558] INFO [LogLoader partition=__consumer_offsets-48, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:10:03,563] INFO [Partition __consumer_offsets-39 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2022-05-12 16:10:03,574] INFO [Partition __consumer_offsets-39 broker=1] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:10:03,599] INFO Created log for partition __consumer_offsets-48 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-48 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 16:10:03,611] INFO [Partition __consumer_offsets-48 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2022-05-12 16:10:03,616] INFO [LogLoader partition=__consumer_offsets-23, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:10:03,654] INFO Created log for partition __consumer_offsets-23 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\__consumer_offsets-23 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 16:10:03,653] INFO [Partition __consumer_offsets-48 broker=0] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:10:03,656] INFO [Partition __consumer_offsets-23 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2022-05-12 16:10:03,678] INFO [Partition __consumer_offsets-23 broker=3] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:10:03,703] INFO [LogLoader partition=__consumer_offsets-20, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:10:03,714] INFO [LogLoader partition=__consumer_offsets-46, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:10:03,772] INFO Created log for partition __consumer_offsets-46 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\__consumer_offsets-46 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 16:10:03,703] INFO [LogLoader partition=__consumer_offsets-1, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:10:03,718] INFO Created log for partition __consumer_offsets-20 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\__consumer_offsets-20 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 16:10:03,791] INFO [Partition __consumer_offsets-46 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2022-05-12 16:10:03,797] INFO Created log for partition __consumer_offsets-1 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 16:10:03,799] INFO [Partition __consumer_offsets-46 broker=2] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:10:03,786] INFO [Partition __consumer_offsets-20 broker=4] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2022-05-12 16:10:03,806] INFO [Partition __consumer_offsets-1 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2022-05-12 16:10:03,824] INFO [Partition __consumer_offsets-1 broker=5] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:10:03,811] INFO [LogLoader partition=__consumer_offsets-33, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:10:03,884] INFO Created log for partition __consumer_offsets-33 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\__consumer_offsets-33 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 16:10:03,821] INFO [Partition __consumer_offsets-20 broker=4] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:10:03,917] INFO [LogLoader partition=__consumer_offsets-17, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:10:03,890] INFO [Partition __consumer_offsets-33 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2022-05-12 16:10:03,951] INFO [Partition __consumer_offsets-33 broker=1] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:10:03,948] INFO Created log for partition __consumer_offsets-17 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\__consumer_offsets-17 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 16:10:03,965] INFO [Partition __consumer_offsets-17 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2022-05-12 16:10:03,997] INFO [Partition __consumer_offsets-17 broker=3] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:10:03,987] INFO [LogLoader partition=__consumer_offsets-42, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:10:04,044] INFO [LogLoader partition=__consumer_offsets-40, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:10:04,071] INFO Created log for partition __consumer_offsets-42 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-42 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 16:10:04,075] INFO [Partition __consumer_offsets-42 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2022-05-12 16:10:04,086] INFO [Partition __consumer_offsets-42 broker=0] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:10:04,100] INFO Created log for partition __consumer_offsets-40 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\__consumer_offsets-40 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 16:10:04,104] INFO [Partition __consumer_offsets-40 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2022-05-12 16:10:04,133] INFO [LogLoader partition=__consumer_offsets-27, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:10:04,119] INFO [Partition __consumer_offsets-40 broker=2] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:10:04,166] INFO Created log for partition __consumer_offsets-27 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\__consumer_offsets-27 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 16:10:04,176] INFO [Partition __consumer_offsets-27 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2022-05-12 16:10:04,189] INFO [Partition __consumer_offsets-27 broker=1] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:10:04,204] INFO [LogLoader partition=__consumer_offsets-11, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:10:04,233] INFO [LogLoader partition=__consumer_offsets-36, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:10:04,272] INFO Created log for partition __consumer_offsets-11 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\__consumer_offsets-11 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 16:10:04,279] INFO Created log for partition __consumer_offsets-36 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-36 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 16:10:04,270] INFO [LogLoader partition=__consumer_offsets-49, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:10:04,278] INFO [Partition __consumer_offsets-11 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2022-05-12 16:10:04,287] INFO [Partition __consumer_offsets-36 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2022-05-12 16:10:04,307] INFO [Partition __consumer_offsets-11 broker=3] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:10:04,308] INFO [Partition __consumer_offsets-36 broker=0] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:10:04,367] INFO [LogLoader partition=__consumer_offsets-21, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:10:04,349] INFO [LogLoader partition=__consumer_offsets-34, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:10:04,349] INFO Created log for partition __consumer_offsets-49 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\__consumer_offsets-49 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 16:10:04,380] INFO [Partition __consumer_offsets-49 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2022-05-12 16:10:04,410] INFO Created log for partition __consumer_offsets-21 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\__consumer_offsets-21 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 16:10:04,398] INFO [Partition __consumer_offsets-49 broker=5] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:10:04,377] INFO [LogLoader partition=__consumer_offsets-14, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:10:04,396] INFO Created log for partition __consumer_offsets-34 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\__consumer_offsets-34 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 16:10:04,442] INFO Created log for partition __consumer_offsets-14 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\__consumer_offsets-14 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 16:10:04,447] INFO [Partition __consumer_offsets-14 broker=4] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2022-05-12 16:10:04,461] INFO [LogLoader partition=__consumer_offsets-5, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:10:04,418] INFO [Partition __consumer_offsets-21 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2022-05-12 16:10:04,426] INFO [Partition __consumer_offsets-34 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2022-05-12 16:10:04,471] INFO [Partition __consumer_offsets-21 broker=1] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:10:04,486] INFO [Partition __consumer_offsets-34 broker=2] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:10:04,495] INFO [LogLoader partition=__consumer_offsets-30, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:10:04,464] INFO [Partition __consumer_offsets-14 broker=4] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:10:04,475] INFO Created log for partition __consumer_offsets-5 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\__consumer_offsets-5 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 16:10:04,538] INFO Created log for partition __consumer_offsets-30 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-30 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 16:10:04,558] INFO [Partition __consumer_offsets-5 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2022-05-12 16:10:04,548] INFO [LogLoader partition=__consumer_offsets-43, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:10:04,560] INFO [Partition __consumer_offsets-30 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2022-05-12 16:10:04,572] INFO [Partition __consumer_offsets-5 broker=3] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:10:04,580] INFO [Partition __consumer_offsets-30 broker=0] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:10:04,584] INFO Created log for partition __consumer_offsets-43 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\__consumer_offsets-43 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 16:10:04,629] INFO [LogLoader partition=__consumer_offsets-15, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:10:04,631] INFO [Partition __consumer_offsets-43 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2022-05-12 16:10:04,632] INFO [Partition __consumer_offsets-43 broker=5] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:10:04,641] INFO Created log for partition __consumer_offsets-15 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\__consumer_offsets-15 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 16:10:04,656] INFO [Partition __consumer_offsets-15 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2022-05-12 16:10:04,659] INFO [Partition __consumer_offsets-15 broker=1] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:10:04,744] INFO [LogLoader partition=__consumer_offsets-8, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:10:04,748] INFO [LogLoader partition=__consumer_offsets-24, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:10:04,765] INFO [LogLoader partition=__consumer_offsets-28, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:10:04,757] INFO Created log for partition __consumer_offsets-24 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-24 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 16:10:04,757] INFO Created log for partition __consumer_offsets-8 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\__consumer_offsets-8 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 16:10:04,778] INFO [LogLoader partition=__consumer_offsets-9, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:10:04,783] INFO [LogLoader partition=__consumer_offsets-47, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:10:04,786] INFO [Partition __consumer_offsets-8 broker=4] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2022-05-12 16:10:04,775] INFO [Partition __consumer_offsets-24 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2022-05-12 16:10:04,798] INFO Created log for partition __consumer_offsets-9 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\__consumer_offsets-9 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 16:10:04,826] INFO Created log for partition __consumer_offsets-47 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\__consumer_offsets-47 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 16:10:04,781] INFO Created log for partition __consumer_offsets-28 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\__consumer_offsets-28 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 16:10:04,812] INFO [Partition __consumer_offsets-24 broker=0] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:10:04,825] INFO [Partition __consumer_offsets-9 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2022-05-12 16:10:04,830] INFO [Partition __consumer_offsets-47 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2022-05-12 16:10:04,844] INFO [Partition __consumer_offsets-9 broker=1] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:10:04,871] INFO [LogLoader partition=__consumer_offsets-37, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:10:04,831] INFO [Partition __consumer_offsets-28 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2022-05-12 16:10:04,811] INFO [Partition __consumer_offsets-8 broker=4] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:10:04,921] INFO [Partition __consumer_offsets-28 broker=2] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:10:04,887] INFO Created log for partition __consumer_offsets-37 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\__consumer_offsets-37 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 16:10:04,872] INFO [Partition __consumer_offsets-47 broker=3] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:10:04,967] INFO [Partition __consumer_offsets-37 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2022-05-12 16:10:05,015] INFO [Partition __consumer_offsets-37 broker=5] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:10:05,039] INFO [LogLoader partition=__consumer_offsets-3, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:10:05,049] INFO [LogLoader partition=__consumer_offsets-18, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:10:05,078] INFO [LogLoader partition=__consumer_offsets-2, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:10:05,063] INFO Created log for partition __consumer_offsets-3 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 16:10:05,102] INFO Created log for partition __consumer_offsets-18 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-18 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 16:10:05,100] INFO [Partition __consumer_offsets-3 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2022-05-12 16:10:05,105] INFO Created log for partition __consumer_offsets-2 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 16:10:05,113] INFO [Partition __consumer_offsets-18 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2022-05-12 16:10:05,121] INFO [Partition __consumer_offsets-3 broker=1] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:10:05,121] INFO [Partition __consumer_offsets-2 broker=4] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2022-05-12 16:10:05,123] INFO [Partition __consumer_offsets-18 broker=0] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:10:05,172] INFO [Partition __consumer_offsets-2 broker=4] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:10:05,170] INFO [LogLoader partition=__consumer_offsets-16, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:10:05,170] INFO [LogLoader partition=__consumer_offsets-35, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:10:05,179] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 3 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:05,228] INFO Created log for partition __consumer_offsets-35 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\__consumer_offsets-35 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 16:10:05,244] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:05,244] INFO [Partition __consumer_offsets-35 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2022-05-12 16:10:05,239] INFO Created log for partition __consumer_offsets-16 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\__consumer_offsets-16 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 16:10:05,254] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 9 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:05,268] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:05,278] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 15 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:05,251] INFO [Partition __consumer_offsets-35 broker=3] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:10:05,286] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:05,303] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 21 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:05,268] INFO [Partition __consumer_offsets-16 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2022-05-12 16:10:05,298] INFO [LogLoader partition=__consumer_offsets-31, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:10:05,318] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:05,385] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 27 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:05,349] INFO [LogLoader partition=__consumer_offsets-12, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:10:05,392] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:05,378] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 120 milliseconds for epoch 0, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:05,421] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 33 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:05,388] INFO Created log for partition __consumer_offsets-31 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\__consumer_offsets-31 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 16:10:05,433] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:05,432] INFO [LogLoader partition=__consumer_offsets-38, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:10:05,428] INFO Created log for partition __consumer_offsets-12 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-12 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 16:10:05,321] INFO [Partition __consumer_offsets-16 broker=2] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:10:05,446] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 39 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:05,445] INFO [Partition __consumer_offsets-31 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2022-05-12 16:10:05,453] INFO [Partition __consumer_offsets-12 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2022-05-12 16:10:05,469] INFO Created log for partition __consumer_offsets-38 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\__consumer_offsets-38 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 16:10:05,487] INFO [LogLoader partition=__consumer_offsets-41, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:10:05,493] INFO [Partition __consumer_offsets-38 broker=4] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2022-05-12 16:10:05,487] INFO [Partition __consumer_offsets-31 broker=5] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:10:05,492] INFO [Partition __consumer_offsets-12 broker=0] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:10:05,527] INFO Created log for partition __consumer_offsets-41 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\__consumer_offsets-41 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 16:10:05,436] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 159 milliseconds for epoch 0, of which 157 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:05,469] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:05,537] INFO [Partition __consumer_offsets-38 broker=4] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:10:05,559] INFO [Partition __consumer_offsets-41 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2022-05-12 16:10:05,578] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 45 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:05,626] INFO [Partition __consumer_offsets-41 broker=3] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:10:05,642] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:05,574] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 270 milliseconds for epoch 0, of which 267 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:05,657] INFO [LogLoader partition=__consumer_offsets-22, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:10:05,655] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 271 milliseconds for epoch 0, of which 269 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:05,675] INFO Created log for partition __consumer_offsets-22 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\__consumer_offsets-22 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 16:10:05,684] INFO [Partition __consumer_offsets-22 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2022-05-12 16:10:05,688] INFO [Partition __consumer_offsets-22 broker=2] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:10:05,672] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 252 milliseconds for epoch 0, of which 251 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:05,676] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 41 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:05,694] INFO [LogLoader partition=__consumer_offsets-19, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:10:05,696] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 251 milliseconds for epoch 0, of which 249 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:05,717] INFO [LogLoader partition=__consumer_offsets-44, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:10:05,716] INFO [LogLoader partition=__consumer_offsets-6, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:10:05,721] INFO Created log for partition __consumer_offsets-19 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\__consumer_offsets-19 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 16:10:05,702] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:05,753] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 47 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:05,737] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 22 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:05,742] INFO [Partition __consumer_offsets-19 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2022-05-12 16:10:05,754] INFO Created log for partition __consumer_offsets-6 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-6 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 16:10:05,733] INFO Created log for partition __consumer_offsets-44 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\__consumer_offsets-44 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 16:10:05,717] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 138 milliseconds for epoch 0, of which 137 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:05,758] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:05,766] INFO [Partition __consumer_offsets-19 broker=5] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:10:05,793] INFO [Partition __consumer_offsets-6 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2022-05-12 16:10:05,796] INFO [Partition __consumer_offsets-44 broker=4] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2022-05-12 16:10:05,775] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:05,800] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 5 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:05,801] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 153 milliseconds for epoch 0, of which 152 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:05,841] INFO [Partition __consumer_offsets-6 broker=0] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:10:05,820] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-41 in 70 milliseconds for epoch 0, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:05,869] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 28 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:05,867] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:05,848] INFO [Partition __consumer_offsets-44 broker=4] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:10:05,910] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 6 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:05,941] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:05,904] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:05,891] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-47 in 92 milliseconds for epoch 0, of which 91 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:05,918] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 11 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:05,948] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-22 in 76 milliseconds for epoch 0, of which 21 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,022] INFO [LogLoader partition=__consumer_offsets-25, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:10:05,989] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-5 in 70 milliseconds for epoch 0, of which 69 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:05,965] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 34 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:05,985] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 12 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:06,071] INFO Created log for partition __consumer_offsets-25 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\__consumer_offsets-25 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 16:10:06,006] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,027] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-28 in 62 milliseconds for epoch 0, of which 61 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,049] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,102] INFO [LogLoader partition=__consumer_offsets-32, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:10:06,085] INFO [Partition __consumer_offsets-25 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2022-05-12 16:10:06,092] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 17 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:06,042] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,119] INFO Created log for partition __consumer_offsets-32 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\__consumer_offsets-32 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 16:10:06,102] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 18 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:06,123] INFO [Partition __consumer_offsets-25 broker=5] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:10:06,160] INFO [Partition __consumer_offsets-32 broker=4] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2022-05-12 16:10:06,161] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 40 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:06,094] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-11 in 3 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,189] INFO [Partition __consumer_offsets-32 broker=4] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:10:06,162] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,190] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,146] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,165] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-34 in 10 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,260] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 44 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:06,119] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 152 milliseconds for epoch 0, of which 42 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,240] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 23 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:06,237] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 46 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:06,253] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-40 in 16 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,290] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,241] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-17 in 3 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,319] INFO [LogLoader partition=__consumer_offsets-13, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 16:10:06,231] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 24 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:06,273] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 171 milliseconds for epoch 0, of which 168 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,276] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,323] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 2 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:06,270] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,322] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,332] INFO Created log for partition __consumer_offsets-13 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\__consumer_offsets-13 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 16:10:06,378] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,393] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 29 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:06,326] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 96 milliseconds for epoch 0, of which 94 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,396] INFO [Partition __consumer_offsets-13 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2022-05-12 16:10:06,341] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 4 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:06,343] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-46 in 3 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,385] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-44 in 61 milliseconds for epoch 0, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,396] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 8 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:06,395] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-23 in 2 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,395] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 30 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:06,414] INFO [Partition __consumer_offsets-13 broker=5] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 16:10:06,435] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,481] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-2 in 85 milliseconds for epoch 0, of which 84 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,406] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,545] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 25 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:06,415] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 21 milliseconds for epoch 0, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,502] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,526] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 10 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:06,492] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,583] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,566] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 35 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:06,588] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 36 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:06,568] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-29 in 2 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,527] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-4 in 2 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,601] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,626] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 14 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:06,636] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,641] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 31 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:06,590] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 3 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,701] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-25 in 58 milliseconds for epoch 0, of which 16 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,673] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 16 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:06,674] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-10 in 2 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,629] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-8 in 3 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,713] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-35 in 2 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,713] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,646] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,734] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,792] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 37 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:06,703] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,867] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 20 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:06,794] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-31 in 2 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,795] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 42 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:06,805] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,797] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 2 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,800] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-16 in 1 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,869] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-14 in 2 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,894] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 43 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:06,877] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,885] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,896] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-37 in 3 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,974] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 48 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:06,971] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 26 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:06,969] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,976] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 2 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:06,974] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-20 in 3 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:07,027] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 49 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:06,989] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:07,028] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:07,029] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-43 in 4 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:07,093] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 0 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:07,137] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 32 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:07,095] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 2 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:07,087] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:07,138] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-26 in 2 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:07,143] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:07,170] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 1 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:07,161] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:07,205] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:07,202] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 2 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:07,206] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 38 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:07,172] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-49 in 3 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:07,231] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 7 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:07,209] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-32 in 3 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:07,277] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-1 in 46 milliseconds for epoch 0, of which 45 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:07,238] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:07,289] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:07,363] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-38 in 2 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:07,427] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 13 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:07,429] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-7 in 2 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:07,488] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:07,527] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 19 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:07,528] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-13 in 2 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:07,552] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:07,643] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-19 in 3 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 16:10:07,684] INFO [GroupCoordinator 5]: Dynamic member with unknown member id joins group Group in Empty state. Created a new member id consumer-Group-1-2caa5db5-0948-4d49-86ee-98638ff8c334 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:07,804] INFO [GroupCoordinator 5]: Preparing to rebalance group Group in state PreparingRebalance with old generation 0 (__consumer_offsets-25) (reason: Adding new member consumer-Group-1-2caa5db5-0948-4d49-86ee-98638ff8c334 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:07,918] INFO [GroupCoordinator 5]: Stabilized group Group generation 1 (__consumer_offsets-25) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:10:08,039] INFO [GroupCoordinator 5]: Assignment received from leader consumer-Group-1-2caa5db5-0948-4d49-86ee-98638ff8c334 for group Group for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:15:08,912] INFO [GroupCoordinator 5]: Member consumer-Group-1-2caa5db5-0948-4d49-86ee-98638ff8c334 in group Group has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:15:08,913] INFO [GroupCoordinator 5]: Preparing to rebalance group Group in state PreparingRebalance with old generation 1 (__consumer_offsets-25) (reason: removing member consumer-Group-1-2caa5db5-0948-4d49-86ee-98638ff8c334 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:15:08,914] INFO [GroupCoordinator 5]: Group Group with generation 2 is now empty (__consumer_offsets-25) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:15:45,228] INFO [GroupCoordinator 5]: Dynamic member with unknown member id joins group Group in Empty state. Created a new member id consumer-Group-1-7f220c2d-e19c-4fd9-8c3c-e9e61e891efc and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:15:45,232] INFO [GroupCoordinator 5]: Preparing to rebalance group Group in state PreparingRebalance with old generation 2 (__consumer_offsets-25) (reason: Adding new member consumer-Group-1-7f220c2d-e19c-4fd9-8c3c-e9e61e891efc with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:15:45,233] INFO [GroupCoordinator 5]: Stabilized group Group generation 3 (__consumer_offsets-25) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:15:45,242] INFO [GroupCoordinator 5]: Assignment received from leader consumer-Group-1-7f220c2d-e19c-4fd9-8c3c-e9e61e891efc for group Group for generation 3. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:17:05,454] INFO [GroupCoordinator 5]: Dynamic member with unknown member id joins group Group in Stable state. Created a new member id consumer-Group-1-11ea577e-8401-4d11-8d41-4e9b8536710c and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:17:05,456] INFO [GroupCoordinator 5]: Preparing to rebalance group Group in state PreparingRebalance with old generation 3 (__consumer_offsets-25) (reason: Adding new member consumer-Group-1-11ea577e-8401-4d11-8d41-4e9b8536710c with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:17:44,738] INFO [GroupCoordinator 5]: Member consumer-Group-1-7f220c2d-e19c-4fd9-8c3c-e9e61e891efc in group Group has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:17:44,740] INFO [GroupCoordinator 5]: Stabilized group Group generation 4 (__consumer_offsets-25) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:17:44,746] INFO [GroupCoordinator 5]: Assignment received from leader consumer-Group-1-11ea577e-8401-4d11-8d41-4e9b8536710c for group Group for generation 4. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:21:22,595] INFO [GroupCoordinator 5]: Dynamic member with unknown member id joins group Group in Stable state. Created a new member id consumer-Group-1-22c0d8b0-06fb-4ee1-b6e6-97a18c6a5f41 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:21:22,597] INFO [GroupCoordinator 5]: Preparing to rebalance group Group in state PreparingRebalance with old generation 4 (__consumer_offsets-25) (reason: Adding new member consumer-Group-1-22c0d8b0-06fb-4ee1-b6e6-97a18c6a5f41 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:22:02,888] INFO [GroupCoordinator 5]: Member consumer-Group-1-11ea577e-8401-4d11-8d41-4e9b8536710c in group Group has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:22:02,889] INFO [GroupCoordinator 5]: Stabilized group Group generation 5 (__consumer_offsets-25) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:22:02,899] INFO [GroupCoordinator 5]: Assignment received from leader consumer-Group-1-22c0d8b0-06fb-4ee1-b6e6-97a18c6a5f41 for group Group for generation 5. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:23:17,857] INFO [GroupCoordinator 5]: Member consumer-Group-1-22c0d8b0-06fb-4ee1-b6e6-97a18c6a5f41 in group Group has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:23:17,858] INFO [GroupCoordinator 5]: Preparing to rebalance group Group in state PreparingRebalance with old generation 5 (__consumer_offsets-25) (reason: removing member consumer-Group-1-22c0d8b0-06fb-4ee1-b6e6-97a18c6a5f41 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:23:17,859] INFO [GroupCoordinator 5]: Group Group with generation 6 is now empty (__consumer_offsets-25) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:41:48,497] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group ConsumerGroup in Empty state. Created a new member id consumer-ConsumerGroup-3-023b8a44-9923-4b05-8d18-63b4d2770a16 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:41:48,502] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group ConsumerGroup in Empty state. Created a new member id consumer-ConsumerGroup-2-5e66f5d4-b1a7-4308-ab74-0012e6a33004 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:41:48,504] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group ConsumerGroup in Empty state. Created a new member id consumer-ConsumerGroup-1-1b7dd352-e50c-4d8f-a67d-335f110ba304 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:41:48,510] INFO [GroupCoordinator 1]: Preparing to rebalance group ConsumerGroup in state PreparingRebalance with old generation 0 (__consumer_offsets-45) (reason: Adding new member consumer-ConsumerGroup-3-023b8a44-9923-4b05-8d18-63b4d2770a16 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:41:48,519] INFO [GroupCoordinator 1]: Stabilized group ConsumerGroup generation 1 (__consumer_offsets-45) with 3 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:41:48,530] INFO [GroupCoordinator 1]: Assignment received from leader consumer-ConsumerGroup-3-023b8a44-9923-4b05-8d18-63b4d2770a16 for group ConsumerGroup for generation 1. The group has 3 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:42:37,503] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group ConsumerGroup in Stable state. Created a new member id consumer-ConsumerGroup-2-68b9fdba-7b9d-4f3e-9b98-95c701114ed1 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:42:37,507] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group ConsumerGroup in Stable state. Created a new member id consumer-ConsumerGroup-3-cc32c706-fb8a-4464-98aa-26969898a5e6 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:42:37,517] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group ConsumerGroup in Stable state. Created a new member id consumer-ConsumerGroup-1-27edc7b5-8657-4975-9160-5891d134d6a1 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:42:37,523] INFO [GroupCoordinator 1]: Preparing to rebalance group ConsumerGroup in state PreparingRebalance with old generation 1 (__consumer_offsets-45) (reason: Adding new member consumer-ConsumerGroup-2-68b9fdba-7b9d-4f3e-9b98-95c701114ed1 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:43:16,190] INFO [GroupCoordinator 1]: Member consumer-ConsumerGroup-2-5e66f5d4-b1a7-4308-ab74-0012e6a33004 in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:43:16,235] INFO [GroupCoordinator 1]: Member consumer-ConsumerGroup-1-1b7dd352-e50c-4d8f-a67d-335f110ba304 in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:43:16,251] INFO [GroupCoordinator 1]: Member consumer-ConsumerGroup-3-023b8a44-9923-4b05-8d18-63b4d2770a16 in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:43:16,252] INFO [GroupCoordinator 1]: Stabilized group ConsumerGroup generation 2 (__consumer_offsets-45) with 3 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:43:16,260] INFO [GroupCoordinator 1]: Assignment received from leader consumer-ConsumerGroup-2-68b9fdba-7b9d-4f3e-9b98-95c701114ed1 for group ConsumerGroup for generation 2. The group has 3 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:44:32,211] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group ConsumerGroup in Stable state. Created a new member id consumer-ConsumerGroup-3-97ab8a2e-e76a-444e-9d49-7fc34caeff2f and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:44:32,211] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group ConsumerGroup in Stable state. Created a new member id consumer-ConsumerGroup-1-6cbdb512-e49f-48e7-bc23-ed4fd8ba47f5 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:44:32,213] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group ConsumerGroup in Stable state. Created a new member id consumer-ConsumerGroup-2-9ce72809-cdec-475e-94e9-ffaa0c7d031b and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:44:32,215] INFO [GroupCoordinator 1]: Preparing to rebalance group ConsumerGroup in state PreparingRebalance with old generation 2 (__consumer_offsets-45) (reason: Adding new member consumer-ConsumerGroup-3-97ab8a2e-e76a-444e-9d49-7fc34caeff2f with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:44:46,724] INFO [GroupCoordinator 1]: Member consumer-ConsumerGroup-2-68b9fdba-7b9d-4f3e-9b98-95c701114ed1 in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:44:46,725] INFO [GroupCoordinator 1]: Member consumer-ConsumerGroup-3-cc32c706-fb8a-4464-98aa-26969898a5e6 in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:44:46,726] INFO [GroupCoordinator 1]: Member consumer-ConsumerGroup-1-27edc7b5-8657-4975-9160-5891d134d6a1 in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:44:46,728] INFO [GroupCoordinator 1]: Stabilized group ConsumerGroup generation 3 (__consumer_offsets-45) with 3 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:44:46,735] INFO [GroupCoordinator 1]: Assignment received from leader consumer-ConsumerGroup-3-97ab8a2e-e76a-444e-9d49-7fc34caeff2f for group ConsumerGroup for generation 3. The group has 3 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:45:42,693] INFO [GroupCoordinator 1]: Member consumer-ConsumerGroup-3-97ab8a2e-e76a-444e-9d49-7fc34caeff2f in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:45:42,693] INFO [GroupCoordinator 1]: Preparing to rebalance group ConsumerGroup in state PreparingRebalance with old generation 3 (__consumer_offsets-45) (reason: removing member consumer-ConsumerGroup-3-97ab8a2e-e76a-444e-9d49-7fc34caeff2f on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:45:42,694] INFO [GroupCoordinator 1]: Member consumer-ConsumerGroup-2-9ce72809-cdec-475e-94e9-ffaa0c7d031b in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:45:42,697] INFO [GroupCoordinator 1]: Member consumer-ConsumerGroup-1-6cbdb512-e49f-48e7-bc23-ed4fd8ba47f5 in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:45:42,698] INFO [GroupCoordinator 1]: Group ConsumerGroup with generation 4 is now empty (__consumer_offsets-45) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:46:00,506] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group ConsumerGroup in Empty state. Created a new member id consumer-ConsumerGroup-2-10e07967-dbe5-4126-a818-07acf363abc7 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:46:00,507] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group ConsumerGroup in Empty state. Created a new member id consumer-ConsumerGroup-1-d5be023f-fb1c-4266-b099-3315a68c834f and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:46:00,508] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group ConsumerGroup in Empty state. Created a new member id consumer-ConsumerGroup-3-f732dc78-19d3-4ae7-a71d-ab72e0f46914 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:46:00,509] INFO [GroupCoordinator 1]: Preparing to rebalance group ConsumerGroup in state PreparingRebalance with old generation 4 (__consumer_offsets-45) (reason: Adding new member consumer-ConsumerGroup-2-10e07967-dbe5-4126-a818-07acf363abc7 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:46:00,511] INFO [GroupCoordinator 1]: Stabilized group ConsumerGroup generation 5 (__consumer_offsets-45) with 3 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:46:00,520] INFO [GroupCoordinator 1]: Assignment received from leader consumer-ConsumerGroup-2-10e07967-dbe5-4126-a818-07acf363abc7 for group ConsumerGroup for generation 5. The group has 3 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:47:39,478] INFO [GroupCoordinator 1]: Member consumer-ConsumerGroup-3-f732dc78-19d3-4ae7-a71d-ab72e0f46914 in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:47:39,479] INFO [GroupCoordinator 1]: Preparing to rebalance group ConsumerGroup in state PreparingRebalance with old generation 5 (__consumer_offsets-45) (reason: removing member consumer-ConsumerGroup-3-f732dc78-19d3-4ae7-a71d-ab72e0f46914 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:47:39,480] INFO [GroupCoordinator 1]: Member consumer-ConsumerGroup-1-d5be023f-fb1c-4266-b099-3315a68c834f in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:47:39,525] INFO [GroupCoordinator 1]: Member consumer-ConsumerGroup-2-10e07967-dbe5-4126-a818-07acf363abc7 in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:47:39,525] INFO [GroupCoordinator 1]: Group ConsumerGroup with generation 6 is now empty (__consumer_offsets-45) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:58:00,663] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group 5 in Empty state. Created a new member id consumer-5-6-49845dd9-0cfb-4f94-8c37-dbdacc75d554 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:58:00,663] INFO [GroupCoordinator 5]: Dynamic member with unknown member id joins group 3 in Empty state. Created a new member id consumer-3-4-622094d9-63ab-4bb4-9c5c-9a4686ffbd57 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:58:00,663] INFO [GroupCoordinator 5]: Dynamic member with unknown member id joins group 1 in Empty state. Created a new member id consumer-1-2-cdf2920d-0f6c-4f03-9765-3084d5f9d66e and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:58:00,667] INFO [GroupCoordinator 1]: Preparing to rebalance group 5 in state PreparingRebalance with old generation 0 (__consumer_offsets-3) (reason: Adding new member consumer-5-6-49845dd9-0cfb-4f94-8c37-dbdacc75d554 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:58:00,668] INFO [GroupCoordinator 5]: Preparing to rebalance group 3 in state PreparingRebalance with old generation 0 (__consumer_offsets-1) (reason: Adding new member consumer-3-4-622094d9-63ab-4bb4-9c5c-9a4686ffbd57 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:58:00,669] INFO [GroupCoordinator 1]: Stabilized group 5 generation 1 (__consumer_offsets-3) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:58:00,670] INFO [GroupCoordinator 5]: Stabilized group 3 generation 1 (__consumer_offsets-1) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:58:00,671] INFO [GroupCoordinator 5]: Preparing to rebalance group 1 in state PreparingRebalance with old generation 0 (__consumer_offsets-49) (reason: Adding new member consumer-1-2-cdf2920d-0f6c-4f03-9765-3084d5f9d66e with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:58:00,674] INFO [GroupCoordinator 5]: Stabilized group 1 generation 1 (__consumer_offsets-49) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:58:00,681] INFO [GroupCoordinator 1]: Assignment received from leader consumer-5-6-49845dd9-0cfb-4f94-8c37-dbdacc75d554 for group 5 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:58:00,681] INFO [GroupCoordinator 5]: Assignment received from leader consumer-3-4-622094d9-63ab-4bb4-9c5c-9a4686ffbd57 for group 3 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:58:00,681] INFO [GroupCoordinator 4]: Dynamic member with unknown member id joins group 4 in Empty state. Created a new member id consumer-4-5-3a7772c3-5e4d-4cde-a747-598811bf4692 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:58:00,683] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group 0 in Empty state. Created a new member id consumer-0-1-9a330b97-d69e-4e80-91e9-20ca3457db5e and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:58:00,681] INFO [GroupCoordinator 5]: Assignment received from leader consumer-1-2-cdf2920d-0f6c-4f03-9765-3084d5f9d66e for group 1 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:58:00,683] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group 2 in Empty state. Created a new member id consumer-2-3-1bcbf626-e938-45b4-9d3f-a7595c28c9a6 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:58:00,701] INFO [GroupCoordinator 4]: Preparing to rebalance group 4 in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member consumer-4-5-3a7772c3-5e4d-4cde-a747-598811bf4692 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:58:00,703] INFO [GroupCoordinator 0]: Preparing to rebalance group 0 in state PreparingRebalance with old generation 0 (__consumer_offsets-48) (reason: Adding new member consumer-0-1-9a330b97-d69e-4e80-91e9-20ca3457db5e with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:58:00,703] INFO [GroupCoordinator 0]: Preparing to rebalance group 2 in state PreparingRebalance with old generation 0 (__consumer_offsets-0) (reason: Adding new member consumer-2-3-1bcbf626-e938-45b4-9d3f-a7595c28c9a6 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:58:00,724] INFO [GroupCoordinator 4]: Stabilized group 4 generation 1 (__consumer_offsets-2) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:58:00,724] INFO [GroupCoordinator 0]: Stabilized group 0 generation 1 (__consumer_offsets-48) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:58:00,732] INFO [GroupCoordinator 0]: Stabilized group 2 generation 1 (__consumer_offsets-0) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:58:00,745] INFO [GroupCoordinator 0]: Assignment received from leader consumer-0-1-9a330b97-d69e-4e80-91e9-20ca3457db5e for group 0 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:58:00,745] INFO [GroupCoordinator 0]: Assignment received from leader consumer-2-3-1bcbf626-e938-45b4-9d3f-a7595c28c9a6 for group 2 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:58:00,750] INFO [GroupCoordinator 4]: Assignment received from leader consumer-4-5-3a7772c3-5e4d-4cde-a747-598811bf4692 for group 4 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:59:07,863] INFO [GroupCoordinator 5]: Member consumer-3-4-622094d9-63ab-4bb4-9c5c-9a4686ffbd57 in group 3 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:59:07,864] INFO [GroupCoordinator 5]: Preparing to rebalance group 3 in state PreparingRebalance with old generation 1 (__consumer_offsets-1) (reason: removing member consumer-3-4-622094d9-63ab-4bb4-9c5c-9a4686ffbd57 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:59:07,865] INFO [GroupCoordinator 0]: Member consumer-2-3-1bcbf626-e938-45b4-9d3f-a7595c28c9a6 in group 2 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:59:07,865] INFO [GroupCoordinator 5]: Group 3 with generation 2 is now empty (__consumer_offsets-1) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:59:07,866] INFO [GroupCoordinator 0]: Preparing to rebalance group 2 in state PreparingRebalance with old generation 1 (__consumer_offsets-0) (reason: removing member consumer-2-3-1bcbf626-e938-45b4-9d3f-a7595c28c9a6 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:59:07,881] INFO [GroupCoordinator 0]: Group 2 with generation 2 is now empty (__consumer_offsets-0) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:59:07,971] INFO [GroupCoordinator 1]: Member consumer-5-6-49845dd9-0cfb-4f94-8c37-dbdacc75d554 in group 5 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:59:07,971] INFO [GroupCoordinator 5]: Member consumer-1-2-cdf2920d-0f6c-4f03-9765-3084d5f9d66e in group 1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:59:07,971] INFO [GroupCoordinator 0]: Member consumer-0-1-9a330b97-d69e-4e80-91e9-20ca3457db5e in group 0 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:59:07,971] INFO [GroupCoordinator 0]: Preparing to rebalance group 0 in state PreparingRebalance with old generation 1 (__consumer_offsets-48) (reason: removing member consumer-0-1-9a330b97-d69e-4e80-91e9-20ca3457db5e on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:59:07,973] INFO [GroupCoordinator 4]: Member consumer-4-5-3a7772c3-5e4d-4cde-a747-598811bf4692 in group 4 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:59:07,971] INFO [GroupCoordinator 1]: Preparing to rebalance group 5 in state PreparingRebalance with old generation 1 (__consumer_offsets-3) (reason: removing member consumer-5-6-49845dd9-0cfb-4f94-8c37-dbdacc75d554 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:59:07,971] INFO [GroupCoordinator 5]: Preparing to rebalance group 1 in state PreparingRebalance with old generation 1 (__consumer_offsets-49) (reason: removing member consumer-1-2-cdf2920d-0f6c-4f03-9765-3084d5f9d66e on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:59:07,973] INFO [GroupCoordinator 0]: Group 0 with generation 2 is now empty (__consumer_offsets-48) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:59:07,974] INFO [GroupCoordinator 4]: Preparing to rebalance group 4 in state PreparingRebalance with old generation 1 (__consumer_offsets-2) (reason: removing member consumer-4-5-3a7772c3-5e4d-4cde-a747-598811bf4692 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:59:07,976] INFO [GroupCoordinator 1]: Group 5 with generation 2 is now empty (__consumer_offsets-3) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:59:07,977] INFO [GroupCoordinator 5]: Group 1 with generation 2 is now empty (__consumer_offsets-49) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:59:07,979] INFO [GroupCoordinator 4]: Group 4 with generation 2 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:59:31,448] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group 0 in Empty state. Created a new member id consumer-0-1-673dac48-6041-4fcb-8733-9e9885fc0c56 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:59:31,451] INFO [GroupCoordinator 4]: Dynamic member with unknown member id joins group 4 in Empty state. Created a new member id consumer-4-5-c03be527-28ff-49fa-865c-8b7df4bc792f and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:59:31,454] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group 5 in Empty state. Created a new member id consumer-5-6-ae17c5e3-36e1-447d-ab3b-efda0543a7c3 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:59:31,455] INFO [GroupCoordinator 5]: Dynamic member with unknown member id joins group 3 in Empty state. Created a new member id consumer-3-4-0cd22e24-0ed7-4c00-ade7-471a8c43de37 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:59:31,474] INFO [GroupCoordinator 4]: Preparing to rebalance group 4 in state PreparingRebalance with old generation 2 (__consumer_offsets-2) (reason: Adding new member consumer-4-5-c03be527-28ff-49fa-865c-8b7df4bc792f with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:59:31,453] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group 2 in Empty state. Created a new member id consumer-2-3-9e25af89-776d-4d7a-9d9e-570e83b3d0ad and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:59:31,472] INFO [GroupCoordinator 1]: Preparing to rebalance group 5 in state PreparingRebalance with old generation 2 (__consumer_offsets-3) (reason: Adding new member consumer-5-6-ae17c5e3-36e1-447d-ab3b-efda0543a7c3 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:59:31,455] INFO [GroupCoordinator 5]: Dynamic member with unknown member id joins group 1 in Empty state. Created a new member id consumer-1-2-83fd9ce8-8fe7-4d6d-b419-c265f03f845e and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:59:31,497] INFO [GroupCoordinator 4]: Stabilized group 4 generation 3 (__consumer_offsets-2) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:59:31,505] INFO [GroupCoordinator 1]: Stabilized group 5 generation 3 (__consumer_offsets-3) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:59:31,472] INFO [GroupCoordinator 0]: Preparing to rebalance group 0 in state PreparingRebalance with old generation 2 (__consumer_offsets-48) (reason: Adding new member consumer-0-1-673dac48-6041-4fcb-8733-9e9885fc0c56 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:59:31,477] INFO [GroupCoordinator 5]: Preparing to rebalance group 3 in state PreparingRebalance with old generation 2 (__consumer_offsets-1) (reason: Adding new member consumer-3-4-0cd22e24-0ed7-4c00-ade7-471a8c43de37 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:59:31,511] INFO [GroupCoordinator 0]: Preparing to rebalance group 2 in state PreparingRebalance with old generation 2 (__consumer_offsets-0) (reason: Adding new member consumer-2-3-9e25af89-776d-4d7a-9d9e-570e83b3d0ad with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:59:31,519] INFO [GroupCoordinator 5]: Preparing to rebalance group 1 in state PreparingRebalance with old generation 2 (__consumer_offsets-49) (reason: Adding new member consumer-1-2-83fd9ce8-8fe7-4d6d-b419-c265f03f845e with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:59:31,542] INFO [GroupCoordinator 0]: Stabilized group 0 generation 3 (__consumer_offsets-48) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:59:31,548] INFO [GroupCoordinator 5]: Stabilized group 3 generation 3 (__consumer_offsets-1) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:59:31,584] INFO [GroupCoordinator 0]: Stabilized group 2 generation 3 (__consumer_offsets-0) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:59:31,594] INFO [GroupCoordinator 5]: Stabilized group 1 generation 3 (__consumer_offsets-49) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:59:31,612] INFO [GroupCoordinator 1]: Assignment received from leader consumer-5-6-ae17c5e3-36e1-447d-ab3b-efda0543a7c3 for group 5 for generation 3. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:59:31,618] INFO [GroupCoordinator 4]: Assignment received from leader consumer-4-5-c03be527-28ff-49fa-865c-8b7df4bc792f for group 4 for generation 3. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:59:31,614] INFO [GroupCoordinator 0]: Assignment received from leader consumer-0-1-673dac48-6041-4fcb-8733-9e9885fc0c56 for group 0 for generation 3. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:59:31,648] INFO [GroupCoordinator 5]: Assignment received from leader consumer-3-4-0cd22e24-0ed7-4c00-ade7-471a8c43de37 for group 3 for generation 3. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:59:31,646] INFO [GroupCoordinator 0]: Assignment received from leader consumer-2-3-9e25af89-776d-4d7a-9d9e-570e83b3d0ad for group 2 for generation 3. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 16:59:31,650] INFO [GroupCoordinator 5]: Assignment received from leader consumer-1-2-83fd9ce8-8fe7-4d6d-b419-c265f03f845e for group 1 for generation 3. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:00:34,010] INFO [GroupCoordinator 4]: Dynamic member with unknown member id joins group 4 in Stable state. Created a new member id consumer-4-5-e46043e3-6ca3-4459-af62-e00a286e681a and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:00:34,001] INFO [GroupCoordinator 5]: Dynamic member with unknown member id joins group 1 in Stable state. Created a new member id consumer-1-1-29af3ddc-216e-4443-bbaa-a802e2260f18 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:00:34,006] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group 2 in Stable state. Created a new member id consumer-2-3-1f09853b-bf92-483d-8a4a-ff4da1ef370a and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:00:34,002] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group 5 in Stable state. Created a new member id consumer-5-6-63e45eec-ecfd-4b34-bfe8-ba55849720c0 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:00:34,073] INFO [GroupCoordinator 4]: Preparing to rebalance group 4 in state PreparingRebalance with old generation 3 (__consumer_offsets-2) (reason: Adding new member consumer-4-5-e46043e3-6ca3-4459-af62-e00a286e681a with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:00:34,004] INFO [GroupCoordinator 5]: Dynamic member with unknown member id joins group 3 in Stable state. Created a new member id consumer-3-4-2bcbb499-6d22-4e08-a493-2f31d8e29907 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:00:34,100] INFO [GroupCoordinator 1]: Preparing to rebalance group 5 in state PreparingRebalance with old generation 3 (__consumer_offsets-3) (reason: Adding new member consumer-5-6-63e45eec-ecfd-4b34-bfe8-ba55849720c0 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:00:34,006] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group 0 in Stable state. Created a new member id consumer-0-2-4ac5bf44-8f99-437b-bd19-3c68c8623cf6 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:00:34,092] INFO [GroupCoordinator 5]: Preparing to rebalance group 1 in state PreparingRebalance with old generation 3 (__consumer_offsets-49) (reason: Adding new member consumer-1-1-29af3ddc-216e-4443-bbaa-a802e2260f18 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:00:34,103] INFO [GroupCoordinator 0]: Preparing to rebalance group 2 in state PreparingRebalance with old generation 3 (__consumer_offsets-0) (reason: Adding new member consumer-2-3-1f09853b-bf92-483d-8a4a-ff4da1ef370a with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:00:34,132] INFO [GroupCoordinator 5]: Preparing to rebalance group 3 in state PreparingRebalance with old generation 3 (__consumer_offsets-1) (reason: Adding new member consumer-3-4-2bcbb499-6d22-4e08-a493-2f31d8e29907 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:00:34,144] INFO [GroupCoordinator 0]: Preparing to rebalance group 0 in state PreparingRebalance with old generation 3 (__consumer_offsets-48) (reason: Adding new member consumer-0-2-4ac5bf44-8f99-437b-bd19-3c68c8623cf6 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:00:41,873] INFO [GroupCoordinator 5]: Member consumer-1-2-83fd9ce8-8fe7-4d6d-b419-c265f03f845e in group 1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:00:41,873] INFO [GroupCoordinator 0]: Member consumer-0-1-673dac48-6041-4fcb-8733-9e9885fc0c56 in group 0 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:00:41,873] INFO [GroupCoordinator 1]: Member consumer-5-6-ae17c5e3-36e1-447d-ab3b-efda0543a7c3 in group 5 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:00:41,873] INFO [GroupCoordinator 4]: Member consumer-4-5-c03be527-28ff-49fa-865c-8b7df4bc792f in group 4 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:00:41,875] INFO [GroupCoordinator 0]: Stabilized group 0 generation 4 (__consumer_offsets-48) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:00:41,874] INFO [GroupCoordinator 5]: Stabilized group 1 generation 4 (__consumer_offsets-49) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:00:41,874] INFO [GroupCoordinator 1]: Stabilized group 5 generation 4 (__consumer_offsets-3) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:00:41,875] INFO [GroupCoordinator 4]: Stabilized group 4 generation 4 (__consumer_offsets-2) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:00:41,882] INFO [GroupCoordinator 0]: Member consumer-2-3-9e25af89-776d-4d7a-9d9e-570e83b3d0ad in group 2 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:00:41,882] INFO [GroupCoordinator 5]: Member consumer-3-4-0cd22e24-0ed7-4c00-ade7-471a8c43de37 in group 3 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:00:41,886] INFO [GroupCoordinator 5]: Stabilized group 3 generation 4 (__consumer_offsets-1) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:00:41,886] INFO [GroupCoordinator 0]: Stabilized group 2 generation 4 (__consumer_offsets-0) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:00:41,892] INFO [GroupCoordinator 1]: Assignment received from leader consumer-5-6-63e45eec-ecfd-4b34-bfe8-ba55849720c0 for group 5 for generation 4. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:00:41,892] INFO [GroupCoordinator 4]: Assignment received from leader consumer-4-5-e46043e3-6ca3-4459-af62-e00a286e681a for group 4 for generation 4. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:00:41,892] INFO [GroupCoordinator 5]: Assignment received from leader consumer-1-1-29af3ddc-216e-4443-bbaa-a802e2260f18 for group 1 for generation 4. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:00:41,892] INFO [GroupCoordinator 0]: Assignment received from leader consumer-0-2-4ac5bf44-8f99-437b-bd19-3c68c8623cf6 for group 0 for generation 4. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:00:41,892] INFO [GroupCoordinator 5]: Assignment received from leader consumer-3-4-2bcbb499-6d22-4e08-a493-2f31d8e29907 for group 3 for generation 4. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:00:41,892] INFO [GroupCoordinator 0]: Assignment received from leader consumer-2-3-1f09853b-bf92-483d-8a4a-ff4da1ef370a for group 2 for generation 4. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:02:15,576] INFO [GroupCoordinator 5]: Dynamic member with unknown member id joins group Group in Empty state. Created a new member id consumer-Group-6-138b61ef-0447-4290-a76e-6657c5570c2e and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:02:15,581] INFO [GroupCoordinator 5]: Dynamic member with unknown member id joins group Group in Empty state. Created a new member id consumer-Group-3-3b20c02d-8672-49c3-853a-4d3f0be8087f and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:02:15,590] INFO [GroupCoordinator 5]: Dynamic member with unknown member id joins group Group in Empty state. Created a new member id consumer-Group-4-71af094f-bcc1-4f48-8f1c-ddb32ed1b9e7 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:02:15,594] INFO [GroupCoordinator 5]: Dynamic member with unknown member id joins group Group in Empty state. Created a new member id consumer-Group-5-5ca7dc65-2c68-4552-a1af-6a5c4190a3bf and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:02:15,601] INFO [GroupCoordinator 5]: Dynamic member with unknown member id joins group Group in Empty state. Created a new member id consumer-Group-1-a9ad700d-4c89-470f-a3c3-b3884bab5a29 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:02:15,616] INFO [GroupCoordinator 5]: Dynamic member with unknown member id joins group Group in Empty state. Created a new member id consumer-Group-2-68a315a8-16ec-4477-94fe-1ab62e336298 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:02:15,620] INFO [GroupCoordinator 5]: Preparing to rebalance group Group in state PreparingRebalance with old generation 6 (__consumer_offsets-25) (reason: Adding new member consumer-Group-6-138b61ef-0447-4290-a76e-6657c5570c2e with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:02:15,633] INFO [GroupCoordinator 5]: Stabilized group Group generation 7 (__consumer_offsets-25) with 4 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:02:15,645] INFO [GroupCoordinator 5]: Preparing to rebalance group Group in state PreparingRebalance with old generation 7 (__consumer_offsets-25) (reason: Adding new member consumer-Group-1-a9ad700d-4c89-470f-a3c3-b3884bab5a29 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:02:15,716] INFO [GroupCoordinator 5]: Stabilized group Group generation 8 (__consumer_offsets-25) with 6 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:02:15,746] INFO [GroupCoordinator 5]: Assignment received from leader consumer-Group-6-138b61ef-0447-4290-a76e-6657c5570c2e for group Group for generation 8. The group has 6 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:02:47,832] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:02:47,834] INFO [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:02:47,837] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Cancelled in-flight FETCH request with correlation id 6263 due to node 5 being disconnected (elapsed time since creation: 515ms, elapsed time since send: 515ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:02:47,837] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:02:47,838] INFO [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Cancelled in-flight FETCH request with correlation id 6264 due to node 5 being disconnected (elapsed time since creation: 516ms, elapsed time since send: 516ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:02:47,838] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Error sending fetch request (sessionId=1521728938, epoch=6263) to node 5: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to 5 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:99)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-12 17:02:47,839] INFO [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:02:47,832] WARN Close of session 0x10066f1e1f10003 (org.apache.zookeeper.server.NIOServerCnxn)
java.io.IOException: An existing connection was forcibly closed by the remote host
	at java.base/sun.nio.ch.SocketDispatcher.read0(Native Method)
	at java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:245)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:324)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:522)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:154)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
[2022-05-12 17:02:47,846] WARN [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=4, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=1521728938, epoch=6263), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 5 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:99)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-12 17:02:47,844] INFO [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Error sending fetch request (sessionId=890675640, epoch=6262) to node 5: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to 5 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:99)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-12 17:02:47,850] WARN [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=0, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=890675640, epoch=6262), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 5 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:99)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-12 17:02:49,177] INFO [ReplicaFetcher replicaId=1, leaderId=4, fetcherId=0] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:02:49,181] INFO [ReplicaFetcher replicaId=1, leaderId=4, fetcherId=0] Cancelled in-flight FETCH request with correlation id 6268 due to node 4 being disconnected (elapsed time since creation: 287ms, elapsed time since send: 287ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:02:49,177] WARN Close of session 0x10066f1e1f10005 (org.apache.zookeeper.server.NIOServerCnxn)
java.io.IOException: An existing connection was forcibly closed by the remote host
	at java.base/sun.nio.ch.SocketDispatcher.read0(Native Method)
	at java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:245)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:324)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:522)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:154)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
[2022-05-12 17:02:49,181] INFO [ReplicaFetcher replicaId=1, leaderId=4, fetcherId=0] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:02:49,186] INFO [ReplicaFetcher replicaId=1, leaderId=4, fetcherId=0] Error sending fetch request (sessionId=1566761934, epoch=6266) to node 4: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to 4 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:99)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-12 17:02:49,192] WARN [ReplicaFetcher replicaId=1, leaderId=4, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=1566761934, epoch=6266), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 4 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:99)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-12 17:02:50,254] WARN Close of session 0x10066f1e1f10004 (org.apache.zookeeper.server.NIOServerCnxn)
java.io.IOException: An existing connection was forcibly closed by the remote host
	at java.base/sun.nio.ch.SocketDispatcher.read0(Native Method)
	at java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:245)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:324)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:522)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:154)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
[2022-05-12 17:02:50,255] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:02:50,256] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Cancelled in-flight FETCH request with correlation id 6273 due to node 3 being disconnected (elapsed time since creation: 350ms, elapsed time since send: 350ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:02:50,264] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:02:50,255] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:02:50,266] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=1669046446, epoch=6271) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to 3 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:99)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-12 17:02:50,267] WARN [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=0, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=1669046446, epoch=6271), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 3 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:99)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-12 17:02:50,269] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Cancelled in-flight FETCH request with correlation id 6273 due to node 3 being disconnected (elapsed time since creation: 319ms, elapsed time since send: 319ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:02:50,269] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:02:50,270] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=1322871473, epoch=6271) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to 3 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:99)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-12 17:02:50,273] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=1322871473, epoch=6271), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 3 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:99)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-12 17:02:50,851] INFO [GroupCoordinator 1]: Member consumer-5-6-63e45eec-ecfd-4b34-bfe8-ba55849720c0 in group 5 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:02:50,851] INFO [GroupCoordinator 0]: Member consumer-0-2-4ac5bf44-8f99-437b-bd19-3c68c8623cf6 in group 0 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:02:50,851] INFO [GroupCoordinator 1]: Preparing to rebalance group 5 in state PreparingRebalance with old generation 4 (__consumer_offsets-3) (reason: removing member consumer-5-6-63e45eec-ecfd-4b34-bfe8-ba55849720c0 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:02:50,854] INFO [GroupCoordinator 1]: Group 5 with generation 5 is now empty (__consumer_offsets-3) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:02:50,851] INFO [GroupCoordinator 0]: Preparing to rebalance group 0 in state PreparingRebalance with old generation 4 (__consumer_offsets-48) (reason: removing member consumer-0-2-4ac5bf44-8f99-437b-bd19-3c68c8623cf6 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:02:50,855] INFO [GroupCoordinator 0]: Group 0 with generation 5 is now empty (__consumer_offsets-48) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:02:50,857] INFO [GroupCoordinator 0]: Member consumer-2-3-1f09853b-bf92-483d-8a4a-ff4da1ef370a in group 2 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:02:50,857] INFO [GroupCoordinator 0]: Preparing to rebalance group 2 in state PreparingRebalance with old generation 4 (__consumer_offsets-0) (reason: removing member consumer-2-3-1f09853b-bf92-483d-8a4a-ff4da1ef370a on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:02:50,858] INFO [GroupCoordinator 0]: Group 2 with generation 5 is now empty (__consumer_offsets-0) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:02:50,899] INFO [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:02:50,899] WARN [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Connection to node 5 (LAPTOP-S01N1QNU.mshome.net/172.22.144.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:02:50,900] INFO [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:02:50,903] INFO [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Error sending fetch request (sessionId=890675640, epoch=INITIAL) to node 5: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to LAPTOP-S01N1QNU.mshome.net:9097 (id: 5 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:104)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-12 17:02:50,904] WARN [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=0, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={Sensor-2=PartitionData(topicId=0MnGw21FSROwsA7IuGeqYQ, fetchOffset=6, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=890675640, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to LAPTOP-S01N1QNU.mshome.net:9097 (id: 5 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:104)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-12 17:02:51,187] WARN Close of session 0x10066f1e1f10000 (org.apache.zookeeper.server.NIOServerCnxn)
java.io.IOException: An existing connection was forcibly closed by the remote host
	at java.base/sun.nio.ch.SocketDispatcher.read0(Native Method)
	at java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:245)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:324)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:522)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:154)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
[2022-05-12 17:02:51,190] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:02:51,190] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Cancelled in-flight FETCH request with correlation id 6270 due to node 2 being disconnected (elapsed time since creation: 261ms, elapsed time since send: 261ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:02:51,194] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:02:51,194] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=1620531324, epoch=6268) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to 2 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:99)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-12 17:02:51,195] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=1620531324, epoch=6268), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 2 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:99)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-12 17:02:52,228] INFO [ReplicaFetcher replicaId=1, leaderId=4, fetcherId=0] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:02:52,228] WARN [ReplicaFetcher replicaId=1, leaderId=4, fetcherId=0] Connection to node 4 (LAPTOP-S01N1QNU.mshome.net/172.22.144.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:02:52,230] INFO [ReplicaFetcher replicaId=1, leaderId=4, fetcherId=0] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:02:52,230] INFO [ReplicaFetcher replicaId=1, leaderId=4, fetcherId=0] Error sending fetch request (sessionId=1566761934, epoch=INITIAL) to node 4: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to LAPTOP-S01N1QNU.mshome.net:9096 (id: 4 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:104)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-12 17:02:52,239] WARN [ReplicaFetcher replicaId=1, leaderId=4, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={Sensor-3=PartitionData(topicId=0MnGw21FSROwsA7IuGeqYQ, fetchOffset=13, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=1566761934, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to LAPTOP-S01N1QNU.mshome.net:9096 (id: 4 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:104)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-12 17:02:53,320] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:02:53,320] WARN [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Connection to node 3 (LAPTOP-S01N1QNU.mshome.net/172.22.144.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:02:53,322] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:02:53,322] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=1669046446, epoch=INITIAL) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to LAPTOP-S01N1QNU.mshome.net:9095 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:104)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-12 17:02:53,323] WARN [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=0, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={Sensor-0=PartitionData(topicId=0MnGw21FSROwsA7IuGeqYQ, fetchOffset=25, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=1669046446, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to LAPTOP-S01N1QNU.mshome.net:9095 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:104)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-12 17:02:53,973] INFO [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:02:53,974] WARN [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Connection to node 5 (LAPTOP-S01N1QNU.mshome.net/172.22.144.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:02:53,975] INFO [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:02:53,977] INFO [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Error sending fetch request (sessionId=890675640, epoch=INITIAL) to node 5: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to LAPTOP-S01N1QNU.mshome.net:9097 (id: 5 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:104)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-12 17:02:53,978] WARN [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=0, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={Sensor-2=PartitionData(topicId=0MnGw21FSROwsA7IuGeqYQ, fetchOffset=6, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=890675640, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to LAPTOP-S01N1QNU.mshome.net:9097 (id: 5 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:104)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-12 17:02:53,979] WARN Close of session 0x10066f1e1f10002 (org.apache.zookeeper.server.NIOServerCnxn)
java.io.IOException: An existing connection was forcibly closed by the remote host
	at java.base/sun.nio.ch.SocketDispatcher.read0(Native Method)
	at java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:245)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:324)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:522)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:154)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
[2022-05-12 17:02:56,392] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:02:56,393] WARN [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Connection to node 3 (LAPTOP-S01N1QNU.mshome.net/172.22.144.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:02:56,394] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:02:56,395] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=1669046446, epoch=INITIAL) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to LAPTOP-S01N1QNU.mshome.net:9095 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:104)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-12 17:02:56,397] WARN [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=0, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={Sensor-0=PartitionData(topicId=0MnGw21FSROwsA7IuGeqYQ, fetchOffset=25, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=1669046446, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to LAPTOP-S01N1QNU.mshome.net:9095 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:104)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-12 17:02:56,415] WARN Close of session 0x10066f1e1f10001 (org.apache.zookeeper.server.NIOServerCnxn)
java.io.IOException: An existing connection was forcibly closed by the remote host
	at java.base/sun.nio.ch.SocketDispatcher.read0(Native Method)
	at java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:245)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:324)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:522)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:154)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
[2022-05-12 17:03:08,231] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-12 17:03:08,233] WARN config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-12 17:03:08,241] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-12 17:03:08,241] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-12 17:03:08,241] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-12 17:03:08,241] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-12 17:03:08,244] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-12 17:03:08,244] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-12 17:03:08,244] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-12 17:03:08,244] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2022-05-12 17:03:08,247] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2022-05-12 17:03:08,258] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-12 17:03:08,258] WARN config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-12 17:03:08,260] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-12 17:03:08,260] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-12 17:03:08,260] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-12 17:03:08,260] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-12 17:03:08,260] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2022-05-12 17:03:08,270] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@2cd2a21f (org.apache.zookeeper.server.ServerMetrics)
[2022-05-12 17:03:08,272] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-12 17:03:08,284] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 17:03:08,284] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 17:03:08,285] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 17:03:08,285] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 17:03:08,285] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 17:03:08,285] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 17:03:08,286] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 17:03:08,286] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 17:03:08,287] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 17:03:08,287] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 17:03:08,293] INFO Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 17:03:08,293] INFO Server environment:host.name=LAPTOP-S01N1QNU.mshome.net (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 17:03:08,294] INFO Server environment:java.version=11.0.10 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 17:03:08,294] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 17:03:08,295] INFO Server environment:java.home=C:\Program Files\Java\jdk-11.0.10 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 17:03:08,295] INFO Server environment:java.class.path=C:\Users\joaoc\Documents\kafka\kfk\libs\activation-1.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\aopalliance-repackaged-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\argparse4j-0.7.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\audience-annotations-0.5.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-cli-1.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-lang3-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-basic-auth-extension-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-file-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-json-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-client-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-runtime-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-transforms-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-api-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-locator-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-utils-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-core-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-databind-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-dataformat-csv-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-datatype-jdk8-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-base-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-json-provider-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-jaxb-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-scala_2.12-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.activation-api-1.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.annotation-api-1.3.5.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.inject-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.validation-api-2.0.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javassist-3.27.0-GA.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.servlet-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jaxb-api-2.3.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-client-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-common-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-core-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-hk2-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-server-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-client-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-continuation-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-http-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-io-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-security-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-server-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlet-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlets-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-ajax-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jline-3.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jopt-simple-5.0.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jose4j-0.7.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-clients-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-log4j-appender-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-metadata-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-raft-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-server-common-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-shell-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-examples-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-scala_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-test-utils-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-tools-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\log4j-1.2.17.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\lz4-java-1.8.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\maven-artifact-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-2.2.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-4.1.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-buffer-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-codec-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-handler-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-resolver-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-epoll-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-unix-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\osgi-resource-locator-1.0.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\paranamer-2.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\plexus-utils-3.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\reflections-0.9.12.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\rocksdbjni-6.22.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-collection-compat_2.12-2.4.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-java8-compat_2.12-1.0.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-library-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-logging_2.12-3.9.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-reflect-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-api-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-log4j12-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\snappy-java-1.1.8.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\trogdor-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-jute-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 17:03:08,297] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-11.0.10\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.10\bin;C:\Program Files\apache-maven-3.6.3\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\sox-14-4-2;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\dotnet\;C:\Users\joaoc\Downloads\apache-zookeeper-3.8.0-bin\bin;C:\Program Files\swipl\bin;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\Scripts\;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\;C:\Users\joaoc\AppData\Local\Microsoft\WindowsApps;C:\Users\joaoc\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\joaoc\AppData\Local\Programs\Julia-1.6.0\bin;C:\Users\joaoc\.dotnet\tools;. (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 17:03:08,297] INFO Server environment:java.io.tmpdir=C:\Users\joaoc\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 17:03:08,298] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 17:03:08,298] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 17:03:08,298] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 17:03:08,299] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 17:03:08,299] INFO Server environment:user.name=joaoc (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 17:03:08,300] INFO Server environment:user.home=C:\Users\joaoc (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 17:03:08,300] INFO Server environment:user.dir=C:\Users\joaoc\Documents\kafka\kfk (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 17:03:08,300] INFO Server environment:os.memory.free=489MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 17:03:08,301] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 17:03:08,301] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 17:03:08,301] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 17:03:08,302] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 17:03:08,302] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 17:03:08,302] INFO zookeeper.flushDelay=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 17:03:08,303] INFO zookeeper.maxWriteQueuePollTime=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 17:03:08,303] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 17:03:08,303] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 17:03:08,305] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2022-05-12 17:03:08,306] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 17:03:08,308] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 17:03:08,311] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-12 17:03:08,311] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-12 17:03:08,312] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-12 17:03:08,313] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-12 17:03:08,313] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-12 17:03:08,313] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-12 17:03:08,314] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-12 17:03:08,314] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-12 17:03:08,316] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 17:03:08,316] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 17:03:08,317] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 clientPortListenBacklog -1 datadir C:\Users\joaoc\Documents\kafka\kfk\zookeeper\version-2 snapdir C:\Users\joaoc\Documents\kafka\kfk\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 17:03:08,331] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-12 17:03:08,332] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-12 17:03:08,333] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-12 17:03:08,336] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-12 17:03:08,356] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2022-05-12 17:03:08,356] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2022-05-12 17:03:08,358] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-12 17:03:08,358] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-12 17:03:08,364] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2022-05-12 17:03:08,365] INFO Snapshotting: 0x0 to C:\Users\joaoc\Documents\kafka\kfk\zookeeper\version-2\snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-12 17:03:08,369] INFO Snapshot loaded in 10 ms, highest zxid is 0x0, digest is 1371985504 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-12 17:03:08,369] INFO Snapshotting: 0x0 to C:\Users\joaoc\Documents\kafka\kfk\zookeeper\version-2\snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-12 17:03:08,371] INFO Snapshot taken in 1 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-12 17:03:08,379] INFO zookeeper.request_throttler.shutdownTimeout = 10000 (org.apache.zookeeper.server.RequestThrottler)
[2022-05-12 17:03:08,380] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2022-05-12 17:03:08,393] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2022-05-12 17:03:08,395] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2022-05-12 17:03:14,541] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-12 17:03:14,576] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-12 17:03:14,634] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-12 17:03:14,642] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-12 17:03:14,664] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-12 17:03:14,688] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-12 17:03:15,069] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-12 17:03:15,093] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-12 17:03:15,125] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-12 17:03:15,165] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-12 17:03:15,170] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-12 17:03:15,208] INFO starting (kafka.server.KafkaServer)
[2022-05-12 17:03:15,209] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-12 17:03:15,221] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-12 17:03:15,227] INFO starting (kafka.server.KafkaServer)
[2022-05-12 17:03:15,228] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-12 17:03:15,236] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-12 17:03:15,247] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,247] INFO Client environment:host.name=LAPTOP-S01N1QNU.mshome.net (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,247] INFO Client environment:java.version=11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,247] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,247] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,248] INFO Client environment:java.class.path=C:\Users\joaoc\Documents\kafka\kfk\libs\activation-1.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\aopalliance-repackaged-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\argparse4j-0.7.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\audience-annotations-0.5.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-cli-1.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-lang3-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-basic-auth-extension-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-file-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-json-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-client-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-runtime-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-transforms-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-api-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-locator-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-utils-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-core-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-databind-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-dataformat-csv-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-datatype-jdk8-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-base-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-json-provider-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-jaxb-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-scala_2.12-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.activation-api-1.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.annotation-api-1.3.5.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.inject-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.validation-api-2.0.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javassist-3.27.0-GA.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.servlet-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jaxb-api-2.3.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-client-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-common-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-core-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-hk2-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-server-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-client-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-continuation-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-http-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-io-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-security-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-server-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlet-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlets-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-ajax-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jline-3.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jopt-simple-5.0.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jose4j-0.7.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-clients-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-log4j-appender-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-metadata-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-raft-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-server-common-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-shell-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-examples-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-scala_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-test-utils-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-tools-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\log4j-1.2.17.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\lz4-java-1.8.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\maven-artifact-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-2.2.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-4.1.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-buffer-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-codec-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-handler-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-resolver-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-epoll-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-unix-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\osgi-resource-locator-1.0.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\paranamer-2.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\plexus-utils-3.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\reflections-0.9.12.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\rocksdbjni-6.22.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-collection-compat_2.12-2.4.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-java8-compat_2.12-1.0.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-library-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-logging_2.12-3.9.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-reflect-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-api-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-log4j12-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\snappy-java-1.1.8.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\trogdor-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-jute-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,249] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.10\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.10\bin;C:\Program Files\apache-maven-3.6.3\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\sox-14-4-2;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\dotnet\;C:\Users\joaoc\Downloads\apache-zookeeper-3.8.0-bin\bin;C:\Program Files\swipl\bin;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\Scripts\;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\;C:\Users\joaoc\AppData\Local\Microsoft\WindowsApps;C:\Users\joaoc\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\joaoc\AppData\Local\Programs\Julia-1.6.0\bin;C:\Users\joaoc\.dotnet\tools;. (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,250] INFO Client environment:java.io.tmpdir=C:\Users\joaoc\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,250] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,251] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,254] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-12 17:03:15,251] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,257] INFO starting (kafka.server.KafkaServer)
[2022-05-12 17:03:15,258] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-12 17:03:15,255] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,259] INFO Client environment:user.name=joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,260] INFO Client environment:user.home=C:\Users\joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,260] INFO Client environment:user.dir=C:\Users\joaoc\Documents\kafka\kfk (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,261] INFO Client environment:os.memory.free=1009MB (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,261] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,261] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,263] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,263] INFO Client environment:host.name=LAPTOP-S01N1QNU.mshome.net (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,263] INFO Client environment:java.version=11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,264] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,264] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,264] INFO Client environment:java.class.path=C:\Users\joaoc\Documents\kafka\kfk\libs\activation-1.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\aopalliance-repackaged-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\argparse4j-0.7.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\audience-annotations-0.5.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-cli-1.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-lang3-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-basic-auth-extension-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-file-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-json-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-client-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-runtime-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-transforms-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-api-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-locator-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-utils-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-core-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-databind-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-dataformat-csv-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-datatype-jdk8-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-base-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-json-provider-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-jaxb-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-scala_2.12-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.activation-api-1.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.annotation-api-1.3.5.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.inject-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.validation-api-2.0.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javassist-3.27.0-GA.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.servlet-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jaxb-api-2.3.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-client-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-common-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-core-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-hk2-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-server-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-client-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-continuation-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-http-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-io-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-security-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-server-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlet-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlets-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-ajax-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jline-3.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jopt-simple-5.0.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jose4j-0.7.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-clients-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-log4j-appender-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-metadata-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-raft-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-server-common-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-shell-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-examples-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-scala_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-test-utils-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-tools-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\log4j-1.2.17.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\lz4-java-1.8.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\maven-artifact-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-2.2.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-4.1.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-buffer-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-codec-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-handler-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-resolver-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-epoll-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-unix-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\osgi-resource-locator-1.0.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\paranamer-2.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\plexus-utils-3.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\reflections-0.9.12.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\rocksdbjni-6.22.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-collection-compat_2.12-2.4.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-java8-compat_2.12-1.0.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-library-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-logging_2.12-3.9.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-reflect-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-api-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-log4j12-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\snappy-java-1.1.8.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\trogdor-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-jute-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,266] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.10\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.10\bin;C:\Program Files\apache-maven-3.6.3\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\sox-14-4-2;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\dotnet\;C:\Users\joaoc\Downloads\apache-zookeeper-3.8.0-bin\bin;C:\Program Files\swipl\bin;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\Scripts\;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\;C:\Users\joaoc\AppData\Local\Microsoft\WindowsApps;C:\Users\joaoc\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\joaoc\AppData\Local\Programs\Julia-1.6.0\bin;C:\Users\joaoc\.dotnet\tools;. (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,266] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2c5529ab (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,266] INFO Client environment:java.io.tmpdir=C:\Users\joaoc\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,280] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-12 17:03:15,275] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,281] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,281] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,282] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,282] INFO Client environment:user.name=joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,283] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-12 17:03:15,283] INFO Client environment:user.home=C:\Users\joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,295] INFO starting (kafka.server.KafkaServer)
[2022-05-12 17:03:15,296] INFO starting (kafka.server.KafkaServer)
[2022-05-12 17:03:15,287] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,297] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-12 17:03:15,296] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-12 17:03:15,299] INFO Client environment:host.name=LAPTOP-S01N1QNU.mshome.net (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,285] INFO Client environment:user.dir=C:\Users\joaoc\Documents\kafka\kfk (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,300] INFO Client environment:java.version=11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,300] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,300] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,290] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-12 17:03:15,300] INFO Client environment:java.class.path=C:\Users\joaoc\Documents\kafka\kfk\libs\activation-1.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\aopalliance-repackaged-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\argparse4j-0.7.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\audience-annotations-0.5.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-cli-1.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-lang3-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-basic-auth-extension-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-file-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-json-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-client-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-runtime-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-transforms-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-api-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-locator-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-utils-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-core-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-databind-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-dataformat-csv-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-datatype-jdk8-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-base-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-json-provider-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-jaxb-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-scala_2.12-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.activation-api-1.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.annotation-api-1.3.5.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.inject-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.validation-api-2.0.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javassist-3.27.0-GA.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.servlet-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jaxb-api-2.3.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-client-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-common-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-core-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-hk2-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-server-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-client-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-continuation-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-http-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-io-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-security-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-server-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlet-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlets-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-ajax-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jline-3.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jopt-simple-5.0.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jose4j-0.7.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-clients-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-log4j-appender-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-metadata-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-raft-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-server-common-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-shell-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-examples-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-scala_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-test-utils-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-tools-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\log4j-1.2.17.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\lz4-java-1.8.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\maven-artifact-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-2.2.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-4.1.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-buffer-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-codec-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-handler-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-resolver-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-epoll-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-unix-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\osgi-resource-locator-1.0.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\paranamer-2.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\plexus-utils-3.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\reflections-0.9.12.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\rocksdbjni-6.22.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-collection-compat_2.12-2.4.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-java8-compat_2.12-1.0.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-library-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-logging_2.12-3.9.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-reflect-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-api-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-log4j12-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\snappy-java-1.1.8.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\trogdor-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-jute-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,300] INFO Client environment:os.memory.free=1010MB (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,302] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-12 17:03:15,302] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.10\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.10\bin;C:\Program Files\apache-maven-3.6.3\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\sox-14-4-2;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\dotnet\;C:\Users\joaoc\Downloads\apache-zookeeper-3.8.0-bin\bin;C:\Program Files\swipl\bin;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\Scripts\;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\;C:\Users\joaoc\AppData\Local\Microsoft\WindowsApps;C:\Users\joaoc\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\joaoc\AppData\Local\Programs\Julia-1.6.0\bin;C:\Users\joaoc\.dotnet\tools;. (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,303] INFO Client environment:java.io.tmpdir=C:\Users\joaoc\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,303] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,328] INFO starting (kafka.server.KafkaServer)
[2022-05-12 17:03:15,318] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-12 17:03:15,329] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-12 17:03:15,319] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-12 17:03:15,324] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-12 17:03:15,305] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,305] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,332] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-12 17:03:15,337] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,337] INFO Client environment:host.name=LAPTOP-S01N1QNU.mshome.net (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,338] INFO Client environment:java.version=11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,338] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,338] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,338] INFO Client environment:host.name=LAPTOP-S01N1QNU.mshome.net (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,338] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,338] INFO Client environment:java.version=11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,338] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,338] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,338] INFO Client environment:java.class.path=C:\Users\joaoc\Documents\kafka\kfk\libs\activation-1.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\aopalliance-repackaged-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\argparse4j-0.7.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\audience-annotations-0.5.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-cli-1.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-lang3-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-basic-auth-extension-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-file-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-json-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-client-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-runtime-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-transforms-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-api-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-locator-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-utils-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-core-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-databind-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-dataformat-csv-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-datatype-jdk8-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-base-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-json-provider-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-jaxb-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-scala_2.12-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.activation-api-1.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.annotation-api-1.3.5.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.inject-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.validation-api-2.0.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javassist-3.27.0-GA.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.servlet-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jaxb-api-2.3.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-client-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-common-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-core-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-hk2-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-server-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-client-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-continuation-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-http-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-io-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-security-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-server-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlet-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlets-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-ajax-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jline-3.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jopt-simple-5.0.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jose4j-0.7.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-clients-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-log4j-appender-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-metadata-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-raft-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-server-common-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-shell-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-examples-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-scala_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-test-utils-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-tools-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\log4j-1.2.17.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\lz4-java-1.8.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\maven-artifact-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-2.2.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-4.1.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-buffer-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-codec-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-handler-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-resolver-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-epoll-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-unix-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\osgi-resource-locator-1.0.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\paranamer-2.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\plexus-utils-3.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\reflections-0.9.12.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\rocksdbjni-6.22.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-collection-compat_2.12-2.4.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-java8-compat_2.12-1.0.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-library-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-logging_2.12-3.9.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-reflect-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-api-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-log4j12-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\snappy-java-1.1.8.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\trogdor-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-jute-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,335] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2c5529ab (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,338] INFO Client environment:java.class.path=C:\Users\joaoc\Documents\kafka\kfk\libs\activation-1.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\aopalliance-repackaged-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\argparse4j-0.7.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\audience-annotations-0.5.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-cli-1.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-lang3-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-basic-auth-extension-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-file-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-json-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-client-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-runtime-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-transforms-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-api-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-locator-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-utils-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-core-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-databind-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-dataformat-csv-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-datatype-jdk8-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-base-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-json-provider-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-jaxb-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-scala_2.12-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.activation-api-1.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.annotation-api-1.3.5.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.inject-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.validation-api-2.0.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javassist-3.27.0-GA.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.servlet-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jaxb-api-2.3.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-client-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-common-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-core-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-hk2-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-server-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-client-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-continuation-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-http-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-io-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-security-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-server-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlet-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlets-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-ajax-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jline-3.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jopt-simple-5.0.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jose4j-0.7.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-clients-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-log4j-appender-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-metadata-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-raft-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-server-common-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-shell-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-examples-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-scala_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-test-utils-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-tools-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\log4j-1.2.17.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\lz4-java-1.8.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\maven-artifact-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-2.2.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-4.1.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-buffer-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-codec-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-handler-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-resolver-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-epoll-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-unix-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\osgi-resource-locator-1.0.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\paranamer-2.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\plexus-utils-3.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\reflections-0.9.12.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\rocksdbjni-6.22.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-collection-compat_2.12-2.4.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-java8-compat_2.12-1.0.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-library-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-logging_2.12-3.9.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-reflect-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-api-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-log4j12-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\snappy-java-1.1.8.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\trogdor-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-jute-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,332] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,339] INFO Socket connection established, initiating session, client: /127.0.0.1:52377, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-12 17:03:15,339] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.10\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.10\bin;C:\Program Files\apache-maven-3.6.3\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\sox-14-4-2;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\dotnet\;C:\Users\joaoc\Downloads\apache-zookeeper-3.8.0-bin\bin;C:\Program Files\swipl\bin;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\Scripts\;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\;C:\Users\joaoc\AppData\Local\Microsoft\WindowsApps;C:\Users\joaoc\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\joaoc\AppData\Local\Programs\Julia-1.6.0\bin;C:\Users\joaoc\.dotnet\tools;. (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,340] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.10\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.10\bin;C:\Program Files\apache-maven-3.6.3\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\sox-14-4-2;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\dotnet\;C:\Users\joaoc\Downloads\apache-zookeeper-3.8.0-bin\bin;C:\Program Files\swipl\bin;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\Scripts\;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\;C:\Users\joaoc\AppData\Local\Microsoft\WindowsApps;C:\Users\joaoc\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\joaoc\AppData\Local\Programs\Julia-1.6.0\bin;C:\Users\joaoc\.dotnet\tools;. (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,352] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2022-05-12 17:03:15,340] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,351] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-12 17:03:15,353] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-12 17:03:15,341] INFO Client environment:java.io.tmpdir=C:\Users\joaoc\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,343] INFO Client environment:java.io.tmpdir=C:\Users\joaoc\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,366] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,366] INFO Client environment:host.name=LAPTOP-S01N1QNU.mshome.net (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,366] INFO Client environment:java.version=11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,367] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,367] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.10 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,359] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,367] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-12 17:03:15,367] INFO Client environment:java.class.path=C:\Users\joaoc\Documents\kafka\kfk\libs\activation-1.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\aopalliance-repackaged-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\argparse4j-0.7.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\audience-annotations-0.5.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-cli-1.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\commons-lang3-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-basic-auth-extension-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-file-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-json-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-mirror-client-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-runtime-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\connect-transforms-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-api-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-locator-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\hk2-utils-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-core-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-databind-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-dataformat-csv-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-datatype-jdk8-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-base-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-jaxrs-json-provider-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-jaxb-annotations-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jackson-module-scala_2.12-2.12.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.activation-api-1.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.annotation-api-1.3.5.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.inject-2.6.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.validation-api-2.0.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.ws.rs-api-2.1.6.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jakarta.xml.bind-api-2.3.2.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javassist-3.27.0-GA.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.servlet-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jaxb-api-2.3.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-client-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-common-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-container-servlet-core-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-hk2-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jersey-server-2.34.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-client-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-continuation-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-http-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-io-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-security-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-server-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlet-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-servlets-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jetty-util-ajax-9.4.43.v20210629.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jline-3.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jopt-simple-5.0.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\jose4j-0.7.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-clients-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-log4j-appender-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-metadata-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-raft-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-server-common-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-shell-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-storage-api-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-examples-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-scala_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-streams-test-utils-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka-tools-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\kafka_2.12-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\log4j-1.2.17.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\lz4-java-1.8.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\maven-artifact-3.8.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-2.2.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\metrics-core-4.1.12.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-buffer-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-codec-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-handler-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-resolver-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-epoll-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\netty-transport-native-unix-common-4.1.68.Final.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\osgi-resource-locator-1.0.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\paranamer-2.8.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\plexus-utils-3.2.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\reflections-0.9.12.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\rocksdbjni-6.22.1.1.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-collection-compat_2.12-2.4.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-java8-compat_2.12-1.0.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-library-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-logging_2.12-3.9.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\scala-reflect-2.12.14.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-api-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\slf4j-log4j12-1.7.30.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\snappy-java-1.1.8.4.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\trogdor-3.1.0.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zookeeper-jute-3.6.3.jar;C:\Users\joaoc\Documents\kafka\kfk\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,369] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100672354ce0000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-12 17:03:15,367] INFO Client environment:user.name=joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,369] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-12 17:03:15,361] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,361] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,372] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-12 17:03:15,368] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.10\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Java\jdk-11.0.10\bin;C:\Program Files\apache-maven-3.6.3\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\sox-14-4-2;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\dotnet\;C:\Users\joaoc\Downloads\apache-zookeeper-3.8.0-bin\bin;C:\Program Files\swipl\bin;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\Scripts\;C:\Users\joaoc\AppData\Local\Programs\Python\Python37\;C:\Users\joaoc\AppData\Local\Microsoft\WindowsApps;C:\Users\joaoc\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\joaoc\AppData\Local\Programs\Julia-1.6.0\bin;C:\Users\joaoc\.dotnet\tools;. (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,375] INFO Client environment:user.home=C:\Users\joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,378] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,378] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,379] INFO Client environment:user.dir=C:\Users\joaoc\Documents\kafka\kfk (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,386] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,383] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,388] INFO Client environment:os.memory.free=1009MB (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,379] INFO Client environment:java.io.tmpdir=C:\Users\joaoc\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,392] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,392] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,393] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,393] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,396] INFO Client environment:user.name=joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,396] INFO Client environment:user.name=joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,400] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,402] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-12 17:03:15,401] INFO Client environment:user.home=C:\Users\joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,401] INFO Client environment:user.home=C:\Users\joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,400] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,402] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,408] INFO Client environment:user.dir=C:\Users\joaoc\Documents\kafka\kfk (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,404] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-12 17:03:15,409] INFO Client environment:user.dir=C:\Users\joaoc\Documents\kafka\kfk (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,409] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,414] INFO Client environment:os.memory.free=1009MB (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,412] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@39a8312f (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,417] INFO Socket connection established, initiating session, client: /127.0.0.1:52380, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-12 17:03:15,415] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,413] INFO Client environment:os.memory.free=1010MB (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,414] INFO Client environment:user.name=joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,422] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,422] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,422] INFO Client environment:user.home=C:\Users\joaoc (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,431] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-12 17:03:15,428] INFO Client environment:user.dir=C:\Users\joaoc\Documents\kafka\kfk (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,436] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100672354ce0001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-12 17:03:15,428] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,432] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2c5529ab (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,432] INFO Client environment:os.memory.free=1009MB (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,439] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-12 17:03:15,441] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-12 17:03:15,441] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2c5529ab (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,438] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,444] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,455] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-12 17:03:15,442] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-12 17:03:15,455] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2c5529ab (org.apache.zookeeper.ZooKeeper)
[2022-05-12 17:03:15,462] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-12 17:03:15,465] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-12 17:03:15,468] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-12 17:03:15,469] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-12 17:03:15,470] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-12 17:03:15,471] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-12 17:03:15,475] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-12 17:03:15,475] INFO Socket connection established, initiating session, client: /127.0.0.1:52389, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-12 17:03:15,477] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-12 17:03:15,480] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-12 17:03:15,481] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-12 17:03:15,485] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:52390, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-12 17:03:15,485] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-12 17:03:15,486] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-12 17:03:15,487] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100672354ce0002, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-12 17:03:15,486] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-12 17:03:15,495] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, session id = 0x100672354ce0003, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-12 17:03:15,493] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-12 17:03:15,491] INFO Socket connection established, initiating session, client: /127.0.0.1:52391, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-12 17:03:15,504] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-12 17:03:15,489] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-12 17:03:15,509] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100672354ce0004, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-12 17:03:15,516] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-12 17:03:15,517] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-12 17:03:15,521] INFO Socket connection established, initiating session, client: /127.0.0.1:52392, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-12 17:03:15,523] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-12 17:03:15,533] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100672354ce0005, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-12 17:03:15,539] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-12 17:03:15,556] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-12 17:03:15,572] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
[2022-05-12 17:03:15,574] INFO Cleared cache (kafka.server.FinalizedFeatureCache)
[2022-05-12 17:03:15,576] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-12 17:03:15,591] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
[2022-05-12 17:03:15,592] INFO Cleared cache (kafka.server.FinalizedFeatureCache)
[2022-05-12 17:03:15,622] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-12 17:03:15,626] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-12 17:03:15,636] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
[2022-05-12 17:03:15,637] INFO Cleared cache (kafka.server.FinalizedFeatureCache)
[2022-05-12 17:03:15,640] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
[2022-05-12 17:03:15,644] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-12 17:03:15,641] INFO Cleared cache (kafka.server.FinalizedFeatureCache)
[2022-05-12 17:03:15,653] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-12 17:03:15,657] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
[2022-05-12 17:03:15,658] INFO Cleared cache (kafka.server.FinalizedFeatureCache)
[2022-05-12 17:03:15,668] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
[2022-05-12 17:03:15,669] INFO Cleared cache (kafka.server.FinalizedFeatureCache)
[2022-05-12 17:03:15,772] INFO Cluster ID = wyICmCjJRxigCROfxVDdGw (kafka.server.KafkaServer)
[2022-05-12 17:03:15,777] WARN No meta.properties file under dir C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-05-12 17:03:15,807] INFO Cluster ID = wyICmCjJRxigCROfxVDdGw (kafka.server.KafkaServer)
[2022-05-12 17:03:15,813] WARN No meta.properties file under dir C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-05-12 17:03:15,860] INFO Cluster ID = wyICmCjJRxigCROfxVDdGw (kafka.server.KafkaServer)
[2022-05-12 17:03:15,866] WARN No meta.properties file under dir C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-05-12 17:03:15,876] INFO Cluster ID = wyICmCjJRxigCROfxVDdGw (kafka.server.KafkaServer)
[2022-05-12 17:03:15,883] WARN No meta.properties file under dir C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-05-12 17:03:15,892] INFO Cluster ID = wyICmCjJRxigCROfxVDdGw (kafka.server.KafkaServer)
[2022-05-12 17:03:15,899] WARN No meta.properties file under dir C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-05-12 17:03:15,895] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-12 17:03:15,925] INFO Cluster ID = wyICmCjJRxigCROfxVDdGw (kafka.server.KafkaServer)
[2022-05-12 17:03:15,932] WARN No meta.properties file under dir C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-05-12 17:03:15,928] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-12 17:03:15,936] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-12 17:03:15,967] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-12 17:03:16,001] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-12 17:03:16,004] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-12 17:03:16,006] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-12 17:03:16,000] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs6
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-12 17:03:16,009] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-12 17:03:16,017] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-12 17:03:16,023] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs6
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-12 17:03:16,030] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 4
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-12 17:03:16,044] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-12 17:03:16,045] INFO Log directory C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3 not found, creating it. (kafka.log.LogManager)
[2022-05-12 17:03:16,073] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-12 17:03:16,081] INFO Loading logs from log dirs ArrayBuffer(C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3) (kafka.log.LogManager)
[2022-05-12 17:03:16,038] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.serv[2022-05-12 17:03:16,085] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
er.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-12 17:03:16,074] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-12 17:03:16,085] INFO Attempting recovery for all logs in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3 since no clean shutdown file was found (kafka.log.LogManager)
[2022-05-12 17:03:16,051] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 4
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.serv[2022-05-12 17:03:16,069] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 3
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
er.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-12 17:03:16,104] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-12 17:03:16,074] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-12 17:03:16,104] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-12 17:03:16,122] INFO Loaded 0 logs in 41ms. (kafka.log.LogManager)
[2022-05-12 17:03:16,074] INFO Log directory C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2 not found, creating it. (kafka.log.LogManager)
[2022-05-12 17:03:16,104] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-12 17:03:16,116] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/Users/joaoc/Documents/kafka/kfk/kafka-logs4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 3
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-12 17:03:16,123] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-12 17:03:16,108] INFO Log directory C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6 not found, creating it. (kafka.log.LogManager)
[2022-05-12 17:03:16,130] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-12 17:03:16,133] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-12 17:03:16,135] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-12 17:03:16,151] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-12 17:03:16,153] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-12 17:03:16,159] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-12 17:03:16,160] INFO Loading logs from log dirs ArrayBuffer(C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2) (kafka.log.LogManager)
[2022-05-12 17:03:16,163] INFO Loading logs from log dirs ArrayBuffer(C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6) (kafka.log.LogManager)
[2022-05-12 17:03:16,166] INFO Attempting recovery for all logs in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2 since no clean shutdown file was found (kafka.log.LogManager)
[2022-05-12 17:03:16,168] INFO Attempting recovery for all logs in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6 since no clean shutdown file was found (kafka.log.LogManager)
[2022-05-12 17:03:16,176] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-12 17:03:16,177] INFO Log directory C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1 not found, creating it. (kafka.log.LogManager)
[2022-05-12 17:03:16,193] INFO Loaded 0 logs in 32ms. (kafka.log.LogManager)
[2022-05-12 17:03:16,194] INFO Loaded 0 logs in 31ms. (kafka.log.LogManager)
[2022-05-12 17:03:16,195] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-12 17:03:16,188] INFO Log directory C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5 not found, creating it. (kafka.log.LogManager)
[2022-05-12 17:03:16,194] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-12 17:03:16,195] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-12 17:03:16,195] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-12 17:03:16,199] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-12 17:03:16,215] INFO Loading logs from log dirs ArrayBuffer(C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1) (kafka.log.LogManager)
[2022-05-12 17:03:16,216] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-12 17:03:16,195] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-12 17:03:16,218] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-12 17:03:16,199] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-12 17:03:16,226] INFO Attempting recovery for all logs in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1 since no clean shutdown file was found (kafka.log.LogManager)
[2022-05-12 17:03:16,208] INFO Log directory C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4 not found, creating it. (kafka.log.LogManager)
[2022-05-12 17:03:16,199] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-12 17:03:16,243] INFO Loading logs from log dirs ArrayBuffer(C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5) (kafka.log.LogManager)
[2022-05-12 17:03:16,252] INFO Attempting recovery for all logs in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5 since no clean shutdown file was found (kafka.log.LogManager)
[2022-05-12 17:03:16,257] INFO Loaded 0 logs in 41ms. (kafka.log.LogManager)
[2022-05-12 17:03:16,258] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-12 17:03:16,265] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-12 17:03:16,279] INFO Loaded 0 logs in 36ms. (kafka.log.LogManager)
[2022-05-12 17:03:16,281] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-12 17:03:16,283] INFO Loading logs from log dirs ArrayBuffer(C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4) (kafka.log.LogManager)
[2022-05-12 17:03:16,287] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-12 17:03:16,293] INFO Attempting recovery for all logs in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4 since no clean shutdown file was found (kafka.log.LogManager)
[2022-05-12 17:03:16,329] INFO Loaded 0 logs in 45ms. (kafka.log.LogManager)
[2022-05-12 17:03:16,330] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-12 17:03:16,353] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-12 17:03:16,653] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-12 17:03:16,718] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-12 17:03:16,719] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-12 17:03:16,774] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-12 17:03:16,804] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-12 17:03:16,841] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-12 17:03:17,027] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-12 17:03:17,047] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2022-05-12 17:03:17,139] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-12 17:03:17,171] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-12 17:03:17,171] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-12 17:03:17,183] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-12 17:03:17,184] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2022-05-12 17:03:17,198] INFO Awaiting socket connections on 0.0.0.0:9097. (kafka.network.Acceptor)
[2022-05-12 17:03:17,228] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 17:03:17,247] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 17:03:17,247] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 17:03:17,247] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 17:03:17,263] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-12 17:03:17,268] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-12 17:03:17,273] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-12 17:03:17,284] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-12 17:03:17,288] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-12 17:03:17,305] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-12 17:03:17,315] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-05-12 17:03:17,326] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-12 17:03:17,338] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-12 17:03:17,337] INFO [ExpirationReaper-5-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 17:03:17,340] INFO [ExpirationReaper-5-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 17:03:17,344] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 17:03:17,343] INFO [ExpirationReaper-5-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 17:03:17,349] INFO Awaiting socket connections on 0.0.0.0:9096. (kafka.network.Acceptor)
[2022-05-12 17:03:17,369] INFO [ExpirationReaper-5-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 17:03:17,369] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-12 17:03:17,378] INFO Stat of the created znode at /brokers/ids/2 is: 107,107,1652371397357,1652371397357,1,0,0,72170995482230785,236,0,107
 (kafka.zk.KafkaZkClient)
[2022-05-12 17:03:17,385] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-12 17:03:17,386] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 17:03:17,387] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-12 17:03:17,389] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-12 17:03:17,393] INFO Awaiting socket connections on 0.0.0.0:9095. (kafka.network.Acceptor)
[2022-05-12 17:03:17,412] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-12 17:03:17,380] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://LAPTOP-S01N1QNU.mshome.net:9094, czxid (broker epoch): 107 (kafka.zk.KafkaZkClient)
[2022-05-12 17:03:17,425] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 17:03:17,426] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-12 17:03:17,432] INFO Creating /brokers/ids/5 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-12 17:03:17,437] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-12 17:03:17,457] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-12 17:03:17,459] INFO Stat of the created znode at /brokers/ids/5 is: 108,108,1652371397449,1652371397449,1,0,0,72170995482230786,236,0,108
 (kafka.zk.KafkaZkClient)
[2022-05-12 17:03:17,463] INFO [ExpirationReaper-4-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 17:03:17,386] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 17:03:17,464] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 17:03:17,386] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 17:03:17,461] INFO Registered broker 5 at path /brokers/ids/5 with addresses: PLAINTEXT://LAPTOP-S01N1QNU.mshome.net:9097, czxid (broker epoch): 108 (kafka.zk.KafkaZkClient)
[2022-05-12 17:03:17,492] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 17:03:17,495] INFO [ExpirationReaper-4-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 17:03:17,465] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-12 17:03:17,465] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 17:03:17,494] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 17:03:17,495] INFO [ExpirationReaper-4-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 17:03:17,512] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-12 17:03:17,495] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-12 17:03:17,523] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 17:03:17,494] INFO [ExpirationReaper-3-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 17:03:17,465] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-12 17:03:17,495] INFO [ExpirationReaper-4-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 17:03:17,548] INFO Stat of the created znode at /brokers/ids/1 is: 110,110,1652371397537,1652371397537,1,0,0,72170995482230784,236,0,110
 (kafka.zk.KafkaZkClient)
[2022-05-12 17:03:17,542] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2022-05-12 17:03:17,465] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 17:03:17,555] INFO Creating /brokers/ids/4 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-12 17:03:17,556] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 17:03:17,549] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://LAPTOP-S01N1QNU.mshome.net:9093, czxid (broker epoch): 110 (kafka.zk.KafkaZkClient)
[2022-05-12 17:03:17,494] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 17:03:17,572] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-12 17:03:17,587] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
[2022-05-12 17:03:17,588] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
[2022-05-12 17:03:17,522] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-12 17:03:17,556] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 17:03:17,587] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
[2022-05-12 17:03:17,587] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
[2022-05-12 17:03:17,598] INFO Stat of the created znode at /brokers/ids/4 is: 113,113,1652371397585,1652371397585,1,0,0,72170995482230788,236,0,113
 (kafka.zk.KafkaZkClient)
[2022-05-12 17:03:17,587] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
[2022-05-12 17:03:17,583] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
[2022-05-12 17:03:17,618] INFO [ExpirationReaper-5-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 17:03:17,626] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-12 17:03:17,571] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:03:17,606] INFO Registered broker 4 at path /brokers/ids/4 with addresses: PLAINTEXT://LAPTOP-S01N1QNU.mshome.net:9096, czxid (broker epoch): 113 (kafka.zk.KafkaZkClient)
[2022-05-12 17:03:17,619] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-12 17:03:17,619] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-12 17:03:17,640] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-12 17:03:17,629] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-12 17:03:17,617] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-12 17:03:17,647] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:03:17,662] INFO [ExpirationReaper-5-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 17:03:17,651] INFO Stat of the created znode at /brokers/ids/0 is: 114,114,1652371397630,1652371397630,1,0,0,72170995482230787,236,0,114
 (kafka.zk.KafkaZkClient)
[2022-05-12 17:03:17,667] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-12 17:03:17,671] INFO Stat of the created znode at /brokers/ids/3 is: 115,115,1652371397657,1652371397657,1,0,0,72170995482230789,236,0,115
 (kafka.zk.KafkaZkClient)
[2022-05-12 17:03:17,663] INFO [ExpirationReaper-5-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 17:03:17,687] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://LAPTOP-S01N1QNU.mshome.net:9092, czxid (broker epoch): 114 (kafka.zk.KafkaZkClient)
[2022-05-12 17:03:17,692] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-12 17:03:17,668] INFO [GroupCoordinator 5]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:03:17,687] INFO Registered broker 3 at path /brokers/ids/3 with addresses: PLAINTEXT://LAPTOP-S01N1QNU.mshome.net:9095, czxid (broker epoch): 115 (kafka.zk.KafkaZkClient)
[2022-05-12 17:03:17,715] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-12 17:03:17,717] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 17:03:17,720] INFO [GroupCoordinator 5]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:03:17,736] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-12 17:03:17,757] INFO [TransactionCoordinator id=5] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-12 17:03:17,759] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 17:03:17,760] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 17:03:17,772] INFO [ExpirationReaper-4-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 17:03:17,772] INFO [TransactionCoordinator id=5] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-12 17:03:17,779] INFO [Transaction Marker Channel Manager 5]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-12 17:03:17,779] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:03:17,789] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 17:03:17,796] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:03:17,803] INFO [ExpirationReaper-4-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 17:03:17,807] INFO [ExpirationReaper-4-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 17:03:17,823] INFO [GroupCoordinator 4]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:03:17,858] INFO [ExpirationReaper-5-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 17:03:17,840] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-12 17:03:17,851] INFO [GroupCoordinator 4]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:03:17,876] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-12 17:03:17,879] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-12 17:03:17,887] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 17:03:17,892] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-12 17:03:17,888] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 17:03:17,888] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 17:03:17,910] INFO [TransactionCoordinator id=4] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-12 17:03:17,917] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-12 17:03:17,906] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:03:17,920] INFO [TransactionCoordinator id=4] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-12 17:03:17,912] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-12 17:03:17,953] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-12 17:03:17,946] INFO [ExpirationReaper-3-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 17:03:17,937] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:03:17,954] INFO [ExpirationReaper-3-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 17:03:17,962] INFO [Transaction Marker Channel Manager 4]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-12 17:03:17,954] INFO [ExpirationReaper-3-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 17:03:17,969] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-12 17:03:17,967] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 17:03:17,988] INFO [GroupCoordinator 3]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:03:17,977] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-12 17:03:17,998] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-12 17:03:18,005] INFO [ExpirationReaper-4-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 17:03:18,024] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-12 17:03:18,018] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-12 17:03:18,004] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-12 17:03:18,030] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-12 17:03:18,032] INFO Kafka startTimeMs: 1652371397998 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-12 17:03:18,015] INFO [GroupCoordinator 3]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:03:18,031] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-12 17:03:18,063] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-12 17:03:18,037] INFO [KafkaServer id=5] started (kafka.server.KafkaServer)
[2022-05-12 17:03:18,081] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-12 17:03:18,087] INFO [TransactionCoordinator id=3] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-12 17:03:18,093] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-12 17:03:18,050] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-12 17:03:18,090] INFO Kafka startTimeMs: 1652371398031 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-12 17:03:18,113] INFO [TransactionCoordinator id=3] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-12 17:03:18,118] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-12 17:03:18,135] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-12 17:03:18,099] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2022-05-12 17:03:18,135] INFO [Transaction Marker Channel Manager 3]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-12 17:03:18,155] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-12 17:03:18,157] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-12 17:03:18,163] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU.mshome.net:9094 (id: 2 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-12 17:03:18,158] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-12 17:03:18,181] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-12 17:03:18,182] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-12 17:03:18,204] INFO [ExpirationReaper-3-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 17:03:18,197] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-12 17:03:18,205] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU.mshome.net:9094 (id: 2 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-12 17:03:18,213] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-12 17:03:18,225] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-12 17:03:18,224] INFO Kafka startTimeMs: 1652371398174 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-12 17:03:18,227] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-12 17:03:18,242] INFO Kafka startTimeMs: 1652371398200 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-12 17:03:18,243] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2022-05-12 17:03:18,253] INFO [KafkaServer id=4] started (kafka.server.KafkaServer)
[2022-05-12 17:03:18,257] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU.mshome.net:9094 (id: 2 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-12 17:03:18,271] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU.mshome.net:9094 (id: 2 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-12 17:03:18,268] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-12 17:03:18,272] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-12 17:03:18,308] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-12 17:03:18,325] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-12 17:03:18,326] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-12 17:03:18,334] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU.mshome.net:9094 (id: 2 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-12 17:03:18,334] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU.mshome.net:9094 (id: 2 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-12 17:03:18,342] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-12 17:03:18,351] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU.mshome.net:9094 (id: 2 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-12 17:03:18,357] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-12 17:03:18,359] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-12 17:03:18,376] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-12 17:03:18,377] INFO Kafka startTimeMs: 1652371398327 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-12 17:03:18,401] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-12 17:03:18,402] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-12 17:03:18,400] INFO [KafkaServer id=3] started (kafka.server.KafkaServer)
[2022-05-12 17:03:18,412] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU.mshome.net:9094 (id: 2 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-12 17:03:18,413] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-12 17:03:18,444] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-12 17:03:18,445] INFO Kafka startTimeMs: 1652371398404 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-12 17:03:18,467] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2022-05-12 17:03:18,493] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU.mshome.net:9094 (id: 2 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-12 17:03:18,553] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU.mshome.net:9094 (id: 2 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-12 17:03:18,602] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU.mshome.net:9094 (id: 2 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-12 17:03:18,602] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use broker LAPTOP-S01N1QNU.mshome.net:9094 (id: 2 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-12 17:03:19,931] INFO Creating topic Sensor with configuration {min.insync.replicas=2} and initial partition assignment Map(2 -> ArrayBuffer(2, 0, 5), 5 -> ArrayBuffer(5, 1, 2), 4 -> ArrayBuffer(0, 4, 1), 1 -> ArrayBuffer(1, 3, 0), 3 -> ArrayBuffer(3, 5, 4), 0 -> ArrayBuffer(4, 2, 3)) (kafka.zk.AdminZkClient)
[2022-05-12 17:03:20,035] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-2) (kafka.server.ReplicaFetcherManager)
[2022-05-12 17:03:20,043] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-12 17:03:20,048] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-12 17:03:20,050] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-4) (kafka.server.ReplicaFetcherManager)
[2022-05-12 17:03:20,056] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-5) (kafka.server.ReplicaFetcherManager)
[2022-05-12 17:03:20,057] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-12 17:03:20,147] INFO [LogLoader partition=Sensor-2, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:03:20,154] INFO [LogLoader partition=Sensor-3, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:03:20,158] INFO [LogLoader partition=Sensor-4, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:03:20,158] INFO [LogLoader partition=Sensor-0, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:03:20,160] INFO [LogLoader partition=Sensor-1, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:03:20,161] INFO [LogLoader partition=Sensor-5, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:03:20,172] INFO Created log for partition Sensor-2 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-12 17:03:20,176] INFO [Partition Sensor-2 broker=2] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-12 17:03:20,177] INFO Created log for partition Sensor-3 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-12 17:03:20,178] INFO [Partition Sensor-2 broker=2] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:03:20,182] INFO [Partition Sensor-3 broker=3] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-12 17:03:20,184] INFO [Partition Sensor-3 broker=3] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:03:20,185] INFO Created log for partition Sensor-0 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-12 17:03:20,186] INFO Created log for partition Sensor-4 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-12 17:03:20,190] INFO Created log for partition Sensor-5 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-12 17:03:20,193] INFO Created log for partition Sensor-1 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-12 17:03:20,194] INFO [Partition Sensor-5 broker=5] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-12 17:03:20,192] INFO [Partition Sensor-0 broker=4] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-12 17:03:20,195] INFO [Partition Sensor-1 broker=1] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-12 17:03:20,192] INFO [Partition Sensor-4 broker=0] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-12 17:03:20,211] INFO [Partition Sensor-0 broker=4] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:03:20,212] INFO [Partition Sensor-1 broker=1] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:03:20,214] INFO [Partition Sensor-4 broker=0] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:03:20,238] INFO [LogLoader partition=Sensor-5, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:03:20,210] INFO [Partition Sensor-5 broker=5] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:03:20,240] INFO [LogLoader partition=Sensor-1, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:03:20,240] INFO Created log for partition Sensor-5 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-12 17:03:20,243] INFO Created log for partition Sensor-1 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-12 17:03:20,271] INFO [LogLoader partition=Sensor-4, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:03:20,275] INFO [LogLoader partition=Sensor-4, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:03:20,279] INFO [LogLoader partition=Sensor-1, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:03:20,270] INFO [Partition Sensor-1 broker=3] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-12 17:03:20,270] INFO [Partition Sensor-5 broker=2] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-12 17:03:20,281] INFO Created log for partition Sensor-1 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-12 17:03:20,294] INFO [LogLoader partition=Sensor-2, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:03:20,277] INFO Created log for partition Sensor-4 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-12 17:03:20,273] INFO Created log for partition Sensor-4 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-12 17:03:20,288] INFO [Partition Sensor-1 broker=3] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:03:20,288] INFO [Partition Sensor-5 broker=2] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:03:20,290] INFO [Partition Sensor-1 broker=0] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-12 17:03:20,295] INFO Created log for partition Sensor-2 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-12 17:03:20,307] INFO [Partition Sensor-1 broker=0] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:03:20,305] INFO [Partition Sensor-4 broker=1] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-12 17:03:20,319] INFO [LogLoader partition=Sensor-0, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:03:20,319] INFO [LogLoader partition=Sensor-0, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:03:20,305] INFO [Partition Sensor-4 broker=4] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-12 17:03:20,321] INFO Created log for partition Sensor-0 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-12 17:03:20,321] INFO Created log for partition Sensor-0 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-12 17:03:20,309] INFO [Partition Sensor-2 broker=5] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-12 17:03:20,313] INFO [Partition Sensor-4 broker=1] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:03:20,323] INFO [LogLoader partition=Sensor-2, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:03:20,335] INFO [Partition Sensor-0 broker=2] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-12 17:03:20,334] INFO [Partition Sensor-4 broker=4] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:03:20,337] INFO Created log for partition Sensor-2 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-12 17:03:20,336] INFO [Partition Sensor-0 broker=3] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-12 17:03:20,337] INFO [Partition Sensor-0 broker=2] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:03:20,336] INFO [Partition Sensor-2 broker=5] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:03:20,351] INFO [LogLoader partition=Sensor-5, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:03:20,346] INFO [Partition Sensor-2 broker=0] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-12 17:03:20,347] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-0, Sensor-5) (kafka.server.ReplicaFetcherManager)
[2022-05-12 17:03:20,346] INFO [Partition Sensor-0 broker=3] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:03:20,353] INFO Created log for partition Sensor-5 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-12 17:03:20,353] INFO [Partition Sensor-2 broker=0] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:03:20,359] INFO [LogLoader partition=Sensor-3, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:03:20,362] INFO [LogLoader partition=Sensor-3, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:03:20,355] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-12 17:03:20,355] INFO [Partition Sensor-5 broker=1] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-12 17:03:20,365] INFO Created log for partition Sensor-3 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-12 17:03:20,365] INFO Created log for partition Sensor-3 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-12 17:03:20,363] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-1, Sensor-2) (kafka.server.ReplicaFetcherManager)
[2022-05-12 17:03:20,380] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-12 17:03:20,364] INFO [Partition Sensor-5 broker=1] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:03:20,392] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-12 17:03:20,377] INFO [Partition Sensor-3 broker=5] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-12 17:03:20,376] INFO [Partition Sensor-3 broker=4] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-12 17:03:20,383] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-4, Sensor-5) (kafka.server.ReplicaFetcherManager)
[2022-05-12 17:03:20,396] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 1 for partitions Map(Sensor-1 -> InitialFetchState(Some(uRASlC4lRCGDI0SN1ufO9w),BrokerEndPoint(id=1, host=LAPTOP-S01N1QNU.mshome.net:9093),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-12 17:03:20,397] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Truncating partition Sensor-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-12 17:03:20,404] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-12 17:03:20,399] INFO [Partition Sensor-3 broker=4] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:03:20,383] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 4 for partitions Map(Sensor-0 -> InitialFetchState(Some(uRASlC4lRCGDI0SN1ufO9w),BrokerEndPoint(id=4, host=LAPTOP-S01N1QNU.mshome.net:9096),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-12 17:03:20,399] INFO [Partition Sensor-3 broker=5] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:03:20,411] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 1 for partitions Map(Sensor-1 -> InitialFetchState(Some(uRASlC4lRCGDI0SN1ufO9w),BrokerEndPoint(id=1, host=LAPTOP-S01N1QNU.mshome.net:9093),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-12 17:03:20,406] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-4, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-12 17:03:20,406] INFO [UnifiedLog partition=Sensor-1, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-12 17:03:20,386] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Truncating partition Sensor-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-12 17:03:20,406] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 4 for partitions Map(Sensor-0 -> InitialFetchState(Some(uRASlC4lRCGDI0SN1ufO9w),BrokerEndPoint(id=4, host=LAPTOP-S01N1QNU.mshome.net:9096),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-12 17:03:20,412] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition Sensor-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-12 17:03:20,419] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-3, Sensor-2) (kafka.server.ReplicaFetcherManager)
[2022-05-12 17:03:20,438] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-12 17:03:20,422] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-12 17:03:20,426] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 2 for partitions Map(Sensor-2 -> InitialFetchState(Some(uRASlC4lRCGDI0SN1ufO9w),BrokerEndPoint(id=2, host=LAPTOP-S01N1QNU.mshome.net:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-12 17:03:20,457] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-12 17:03:20,446] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 0 for partitions Map(Sensor-4 -> InitialFetchState(Some(uRASlC4lRCGDI0SN1ufO9w),BrokerEndPoint(id=0, host=LAPTOP-S01N1QNU.mshome.net:9092),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-12 17:03:20,423] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 5 for partitions Map(Sensor-5 -> InitialFetchState(Some(uRASlC4lRCGDI0SN1ufO9w),BrokerEndPoint(id=5, host=LAPTOP-S01N1QNU.mshome.net:9097),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-12 17:03:20,440] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Truncating partition Sensor-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-12 17:03:20,441] INFO [UnifiedLog partition=Sensor-1, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-12 17:03:20,477] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-12 17:03:20,465] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-12 17:03:20,463] INFO [ReplicaFetcherManager on broker 4] Added fetcher to broker 3 for partitions Map(Sensor-3 -> InitialFetchState(Some(uRASlC4lRCGDI0SN1ufO9w),BrokerEndPoint(id=3, host=LAPTOP-S01N1QNU.mshome.net:9095),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-12 17:03:20,466] INFO [UnifiedLog partition=Sensor-0, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-12 17:03:20,440] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-12 17:03:20,481] INFO [ReplicaFetcherManager on broker 5] Added fetcher to broker 3 for partitions Map(Sensor-3 -> InitialFetchState(Some(uRASlC4lRCGDI0SN1ufO9w),BrokerEndPoint(id=3, host=LAPTOP-S01N1QNU.mshome.net:9095),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-12 17:03:20,447] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition Sensor-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-12 17:03:20,471] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 5 for partitions Map(Sensor-5 -> InitialFetchState(Some(uRASlC4lRCGDI0SN1ufO9w),BrokerEndPoint(id=5, host=LAPTOP-S01N1QNU.mshome.net:9097),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-12 17:03:20,426] INFO [UnifiedLog partition=Sensor-0, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-12 17:03:20,489] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition Sensor-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-12 17:03:20,482] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Truncating partition Sensor-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-12 17:03:20,496] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-12 17:03:20,486] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Truncating partition Sensor-5 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-12 17:03:20,528] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-1. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-12 17:03:20,498] INFO [ReplicaFetcherManager on broker 5] Added fetcher to broker 2 for partitions Map(Sensor-2 -> InitialFetchState(Some(uRASlC4lRCGDI0SN1ufO9w),BrokerEndPoint(id=2, host=LAPTOP-S01N1QNU.mshome.net:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-12 17:03:20,518] INFO [UnifiedLog partition=Sensor-2, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-12 17:03:20,499] INFO [UnifiedLog partition=Sensor-4, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-12 17:03:20,465] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Truncating partition Sensor-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-12 17:03:20,524] INFO [UnifiedLog partition=Sensor-5, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-12 17:03:20,494] INFO [ReplicaFetcherManager on broker 4] Added fetcher to broker 0 for partitions Map(Sensor-4 -> InitialFetchState(Some(uRASlC4lRCGDI0SN1ufO9w),BrokerEndPoint(id=0, host=LAPTOP-S01N1QNU.mshome.net:9092),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-12 17:03:20,522] INFO [UnifiedLog partition=Sensor-3, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-12 17:03:20,529] WARN [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-1. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-12 17:03:20,521] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Truncating partition Sensor-5 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-12 17:03:20,543] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-12 17:03:20,521] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-12 17:03:20,551] INFO [UnifiedLog partition=Sensor-3, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-12 17:03:20,573] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Truncating partition Sensor-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-12 17:03:20,552] INFO [UnifiedLog partition=Sensor-5, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-12 17:03:20,599] WARN [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-0. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-12 17:03:20,606] WARN [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-0. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-12 17:03:20,579] INFO [UnifiedLog partition=Sensor-2, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-12 17:03:20,613] WARN [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-2. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-12 17:03:20,552] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Truncating partition Sensor-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-12 17:03:20,645] WARN [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-5. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-12 17:03:20,635] INFO [UnifiedLog partition=Sensor-4, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-12 17:04:08,843] INFO Creating topic __consumer_offsets with configuration {compression.type=producer, cleanup.policy=compact, segment.bytes=104857600} and initial partition assignment Map(23 -> ArrayBuffer(4), 32 -> ArrayBuffer(3), 41 -> ArrayBuffer(4), 17 -> ArrayBuffer(4), 8 -> ArrayBuffer(3), 35 -> ArrayBuffer(4), 44 -> ArrayBuffer(3), 26 -> ArrayBuffer(3), 11 -> ArrayBuffer(4), 29 -> ArrayBuffer(4), 38 -> ArrayBuffer(3), 47 -> ArrayBuffer(4), 20 -> ArrayBuffer(3), 2 -> ArrayBuffer(3), 5 -> ArrayBuffer(4), 14 -> ArrayBuffer(3), 46 -> ArrayBuffer(5), 49 -> ArrayBuffer(2), 40 -> ArrayBuffer(5), 13 -> ArrayBuffer(2), 4 -> ArrayBuffer(5), 22 -> ArrayBuffer(5), 31 -> ArrayBuffer(2), 16 -> ArrayBuffer(5), 7 -> ArrayBuffer(2), 43 -> ArrayBuffer(2), 25 -> ArrayBuffer(2), 34 -> ArrayBuffer(5), 10 -> ArrayBuffer(5), 37 -> ArrayBuffer(2), 1 -> ArrayBuffer(2), 19 -> ArrayBuffer(2), 28 -> ArrayBuffer(5), 45 -> ArrayBuffer(0), 27 -> ArrayBuffer(0), 36 -> ArrayBuffer(1), 18 -> ArrayBuffer(1), 9 -> ArrayBuffer(0), 21 -> ArrayBuffer(0), 48 -> ArrayBuffer(1), 3 -> ArrayBuffer(0), 12 -> ArrayBuffer(1), 30 -> ArrayBuffer(1), 39 -> ArrayBuffer(0), 15 -> ArrayBuffer(0), 42 -> ArrayBuffer(1), 24 -> ArrayBuffer(1), 6 -> ArrayBuffer(1), 33 -> ArrayBuffer(0), 0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2022-05-12 17:04:10,297] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(__consumer_offsets-7, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1) (kafka.server.ReplicaFetcherManager)
[2022-05-12 17:04:10,362] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(__consumer_offsets-30, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-18, __consumer_offsets-24, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-12) (kafka.server.ReplicaFetcherManager)
[2022-05-12 17:04:10,322] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(__consumer_offsets-8, __consumer_offsets-38, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44, __consumer_offsets-26, __consumer_offsets-32) (kafka.server.ReplicaFetcherManager)
[2022-05-12 17:04:10,373] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(__consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-23, __consumer_offsets-47, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-5, __consumer_offsets-29) (kafka.server.ReplicaFetcherManager)
[2022-05-12 17:04:10,400] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-46, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2022-05-12 17:04:10,679] INFO [LogLoader partition=__consumer_offsets-7, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:04:10,694] INFO Created log for partition __consumer_offsets-7 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\__consumer_offsets-7 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 17:04:10,692] INFO [LogLoader partition=__consumer_offsets-29, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:04:10,715] INFO Created log for partition __consumer_offsets-29 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\__consumer_offsets-29 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 17:04:10,731] INFO [LogLoader partition=__consumer_offsets-26, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:04:10,755] INFO Created log for partition __consumer_offsets-26 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\__consumer_offsets-26 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 17:04:10,756] INFO [Partition __consumer_offsets-29 broker=4] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2022-05-12 17:04:10,709] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-21, __consumer_offsets-27, __consumer_offsets-9, __consumer_offsets-33, __consumer_offsets-3, __consumer_offsets-15, __consumer_offsets-39, __consumer_offsets-45) (kafka.server.ReplicaFetcherManager)
[2022-05-12 17:04:10,775] INFO [Partition __consumer_offsets-29 broker=4] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:04:10,799] INFO [Partition __consumer_offsets-7 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2022-05-12 17:04:10,823] INFO [Partition __consumer_offsets-7 broker=2] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:04:10,789] INFO [LogLoader partition=__consumer_offsets-0, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:04:11,051] INFO [LogLoader partition=__consumer_offsets-23, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:04:11,042] INFO [Partition __consumer_offsets-26 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2022-05-12 17:04:11,060] INFO [LogLoader partition=__consumer_offsets-1, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:04:11,096] INFO [Partition __consumer_offsets-26 broker=3] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:04:11,108] INFO Created log for partition __consumer_offsets-1 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 17:04:11,120] INFO [Partition __consumer_offsets-1 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2022-05-12 17:04:11,052] INFO Created log for partition __consumer_offsets-0 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 17:04:11,125] INFO Created log for partition __consumer_offsets-23 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\__consumer_offsets-23 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 17:04:11,133] INFO [Partition __consumer_offsets-1 broker=2] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:04:11,151] INFO [Partition __consumer_offsets-23 broker=4] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2022-05-12 17:04:11,249] INFO [Partition __consumer_offsets-23 broker=4] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:04:11,246] INFO [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2022-05-12 17:04:11,349] INFO [Partition __consumer_offsets-0 broker=1] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:04:11,403] INFO [LogLoader partition=__consumer_offsets-20, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:04:11,422] INFO Created log for partition __consumer_offsets-20 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\__consumer_offsets-20 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 17:04:11,432] INFO [Partition __consumer_offsets-20 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2022-05-12 17:04:11,457] INFO [Partition __consumer_offsets-20 broker=3] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:04:10,877] INFO [LogLoader partition=__consumer_offsets-10, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:04:11,491] INFO [LogLoader partition=__consumer_offsets-49, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:04:11,520] INFO Created log for partition __consumer_offsets-49 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\__consumer_offsets-49 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 17:04:11,529] INFO [Partition __consumer_offsets-49 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2022-05-12 17:04:11,664] INFO [LogLoader partition=__consumer_offsets-48, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:04:11,617] INFO [LogLoader partition=__consumer_offsets-14, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:04:11,720] INFO Created log for partition __consumer_offsets-48 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\__consumer_offsets-48 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 17:04:11,696] INFO [LogLoader partition=__consumer_offsets-17, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:04:11,685] INFO [Partition __consumer_offsets-49 broker=2] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:04:11,793] INFO Created log for partition __consumer_offsets-14 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\__consumer_offsets-14 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 17:04:11,779] INFO Created log for partition __consumer_offsets-17 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\__consumer_offsets-17 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 17:04:11,805] INFO [Partition __consumer_offsets-17 broker=4] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2022-05-12 17:04:11,800] INFO [Partition __consumer_offsets-14 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2022-05-12 17:04:11,844] INFO [Partition __consumer_offsets-14 broker=3] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:04:11,503] INFO Created log for partition __consumer_offsets-10 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\__consumer_offsets-10 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 17:04:11,762] INFO [Partition __consumer_offsets-48 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2022-05-12 17:04:11,843] INFO [Partition __consumer_offsets-17 broker=4] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:04:11,619] INFO [LogLoader partition=__consumer_offsets-45, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:04:11,911] INFO [Partition __consumer_offsets-48 broker=1] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:04:12,015] INFO [LogLoader partition=__consumer_offsets-43, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:04:12,026] INFO [LogLoader partition=__consumer_offsets-8, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:04:12,056] INFO Created log for partition __consumer_offsets-43 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\__consumer_offsets-43 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 17:04:12,046] INFO Created log for partition __consumer_offsets-8 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\__consumer_offsets-8 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 17:04:12,065] INFO [Partition __consumer_offsets-43 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2022-05-12 17:04:12,064] INFO [Partition __consumer_offsets-8 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2022-05-12 17:04:12,076] INFO [Partition __consumer_offsets-43 broker=2] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:04:12,077] INFO [Partition __consumer_offsets-8 broker=3] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:04:12,020] INFO Created log for partition __consumer_offsets-45 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-45 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 17:04:11,912] INFO [Partition __consumer_offsets-10 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2022-05-12 17:04:12,112] INFO [Partition __consumer_offsets-10 broker=5] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:04:12,198] INFO [Partition __consumer_offsets-45 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2022-05-12 17:04:12,224] INFO [LogLoader partition=__consumer_offsets-11, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:04:12,225] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:04:12,237] INFO Created log for partition __consumer_offsets-11 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\__consumer_offsets-11 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 17:04:12,270] INFO [Partition __consumer_offsets-11 broker=4] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2022-05-12 17:04:12,294] INFO [LogLoader partition=__consumer_offsets-37, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:04:12,284] INFO [Partition __consumer_offsets-11 broker=4] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:04:12,324] INFO Created log for partition __consumer_offsets-37 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\__consumer_offsets-37 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 17:04:12,336] INFO [LogLoader partition=__consumer_offsets-2, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:04:12,327] INFO [Partition __consumer_offsets-37 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2022-05-12 17:04:12,348] INFO Created log for partition __consumer_offsets-2 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 17:04:12,339] INFO [Partition __consumer_offsets-37 broker=2] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:04:12,364] INFO [Partition __consumer_offsets-2 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2022-05-12 17:04:12,370] INFO [Partition __consumer_offsets-2 broker=3] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:04:12,455] INFO [LogLoader partition=__consumer_offsets-42, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:04:12,466] INFO [LogLoader partition=__consumer_offsets-39, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:04:12,516] INFO Created log for partition __consumer_offsets-39 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-39 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 17:04:12,527] INFO Created log for partition __consumer_offsets-42 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\__consumer_offsets-42 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 17:04:12,526] INFO [LogLoader partition=__consumer_offsets-5, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:04:12,530] INFO [Partition __consumer_offsets-39 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2022-05-12 17:04:12,531] INFO [Partition __consumer_offsets-42 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2022-05-12 17:04:12,543] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:04:12,538] INFO Created log for partition __consumer_offsets-5 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\__consumer_offsets-5 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 17:04:12,567] INFO [LogLoader partition=__consumer_offsets-31, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:04:12,584] INFO [LogLoader partition=__consumer_offsets-38, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:04:12,584] INFO Created log for partition __consumer_offsets-31 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\__consumer_offsets-31 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 17:04:12,603] INFO Created log for partition __consumer_offsets-38 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\__consumer_offsets-38 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 17:04:12,567] INFO [Partition __consumer_offsets-5 broker=4] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2022-05-12 17:04:12,545] INFO [Partition __consumer_offsets-42 broker=1] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:04:12,614] INFO [Partition __consumer_offsets-31 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2022-05-12 17:04:12,624] INFO [Partition __consumer_offsets-5 broker=4] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:04:12,622] INFO [Partition __consumer_offsets-38 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2022-05-12 17:04:12,476] INFO [LogLoader partition=__consumer_offsets-4, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:04:12,662] INFO [Partition __consumer_offsets-38 broker=3] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:04:12,644] INFO [Partition __consumer_offsets-31 broker=2] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:04:12,832] INFO [LogLoader partition=__consumer_offsets-47, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:04:12,735] INFO Created log for partition __consumer_offsets-4 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 17:04:12,836] INFO [LogLoader partition=__consumer_offsets-19, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:04:12,846] INFO [Partition __consumer_offsets-4 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2022-05-12 17:04:12,867] INFO Created log for partition __consumer_offsets-19 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\__consumer_offsets-19 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 17:04:12,874] INFO [LogLoader partition=__consumer_offsets-44, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:04:12,846] INFO Created log for partition __consumer_offsets-47 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\__consumer_offsets-47 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 17:04:12,883] INFO [Partition __consumer_offsets-19 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2022-05-12 17:04:12,910] INFO Created log for partition __consumer_offsets-44 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\__consumer_offsets-44 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 17:04:12,894] INFO [Partition __consumer_offsets-47 broker=4] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2022-05-12 17:04:12,890] INFO [Partition __consumer_offsets-4 broker=5] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:04:12,937] INFO [Partition __consumer_offsets-19 broker=2] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:04:12,949] INFO [Partition __consumer_offsets-44 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2022-05-12 17:04:12,954] INFO [Partition __consumer_offsets-47 broker=4] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:04:13,003] INFO [Partition __consumer_offsets-44 broker=3] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:04:13,062] INFO [LogLoader partition=__consumer_offsets-36, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:04:13,088] INFO Created log for partition __consumer_offsets-36 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\__consumer_offsets-36 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 17:04:13,104] INFO [Partition __consumer_offsets-36 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2022-05-12 17:04:13,119] INFO [Partition __consumer_offsets-36 broker=1] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:04:13,026] INFO [LogLoader partition=__consumer_offsets-33, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:04:13,199] INFO [LogLoader partition=__consumer_offsets-35, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:04:13,200] INFO [LogLoader partition=__consumer_offsets-25, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:04:13,213] INFO Created log for partition __consumer_offsets-33 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-33 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 17:04:13,222] INFO Created log for partition __consumer_offsets-35 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\__consumer_offsets-35 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 17:04:13,238] INFO Created log for partition __consumer_offsets-25 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\__consumer_offsets-25 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 17:04:13,253] INFO [Partition __consumer_offsets-25 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2022-05-12 17:04:13,228] INFO [Partition __consumer_offsets-35 broker=4] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2022-05-12 17:04:13,254] INFO [Partition __consumer_offsets-25 broker=2] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:04:13,258] INFO [Partition __consumer_offsets-35 broker=4] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:04:13,225] INFO [Partition __consumer_offsets-33 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2022-05-12 17:04:13,283] INFO [LogLoader partition=__consumer_offsets-32, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:04:13,285] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:04:13,276] INFO [LogLoader partition=__consumer_offsets-46, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:04:13,319] INFO Created log for partition __consumer_offsets-32 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs4\__consumer_offsets-32 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 17:04:13,350] INFO [Partition __consumer_offsets-32 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2022-05-12 17:04:13,353] INFO [Partition __consumer_offsets-32 broker=3] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:04:13,409] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 44 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:13,422] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:13,432] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 2 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:13,437] INFO [LogLoader partition=__consumer_offsets-41, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:04:13,441] INFO [LogLoader partition=__consumer_offsets-13, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:04:13,446] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:13,467] INFO Created log for partition __consumer_offsets-41 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs5\__consumer_offsets-41 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 17:04:13,476] INFO [Partition __consumer_offsets-41 broker=4] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2022-05-12 17:04:13,404] INFO Created log for partition __consumer_offsets-46 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\__consumer_offsets-46 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 17:04:13,474] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 8 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:13,468] INFO Created log for partition __consumer_offsets-13 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs3\__consumer_offsets-13 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 17:04:13,487] INFO [Partition __consumer_offsets-41 broker=4] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:04:13,485] INFO [LogLoader partition=__consumer_offsets-30, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:04:13,490] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:13,489] INFO [Partition __consumer_offsets-46 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2022-05-12 17:04:13,506] INFO [Partition __consumer_offsets-13 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2022-05-12 17:04:13,532] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 14 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:13,542] INFO Created log for partition __consumer_offsets-30 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\__consumer_offsets-30 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 17:04:13,520] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-44 in 73 milliseconds for epoch 0, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:13,559] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 41 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:13,552] INFO [Partition __consumer_offsets-46 broker=5] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:04:13,572] INFO [Partition __consumer_offsets-13 broker=2] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:04:13,585] INFO [Partition __consumer_offsets-30 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2022-05-12 17:04:13,634] INFO [LogLoader partition=__consumer_offsets-27, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:04:13,609] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:13,650] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 25 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:13,614] INFO [Partition __consumer_offsets-30 broker=1] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:04:13,572] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:13,655] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 47 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:13,651] INFO Created log for partition __consumer_offsets-27 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-27 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 17:04:13,608] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-2 in 135 milliseconds for epoch 0, of which 124 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:13,673] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:13,691] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:13,719] INFO [Partition __consumer_offsets-27 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2022-05-12 17:04:13,730] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 5 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:13,755] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:04:13,776] INFO [LogLoader partition=__consumer_offsets-40, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:04:13,733] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-41 in 74 milliseconds for epoch 0, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:13,756] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 31 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:13,677] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 20 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:13,789] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:13,758] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:13,722] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-8 in 191 milliseconds for epoch 0, of which 189 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:13,797] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-47 in 66 milliseconds for epoch 0, of which 61 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:13,806] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:13,842] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 37 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:13,833] INFO Created log for partition __consumer_offsets-40 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\__consumer_offsets-40 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 17:04:13,875] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 26 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:13,853] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 11 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:13,864] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-14 in 188 milliseconds for epoch 0, of which 187 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:13,886] INFO [LogLoader partition=__consumer_offsets-24, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:04:13,828] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 99 milliseconds for epoch 0, of which 46 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:13,891] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:13,896] INFO [Partition __consumer_offsets-40 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2022-05-12 17:04:13,898] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:13,867] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-5 in 15 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:13,971] INFO Created log for partition __consumer_offsets-24 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\__consumer_offsets-24 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 17:04:13,987] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 32 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:13,899] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:13,974] INFO [Partition __consumer_offsets-40 broker=5] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:04:13,923] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 79 milliseconds for epoch 0, of which 78 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:14,005] INFO [Partition __consumer_offsets-24 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2022-05-12 17:04:14,011] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 17 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:14,005] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:13,961] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 43 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:14,141] INFO [LogLoader partition=__consumer_offsets-21, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:04:14,013] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-11 in 3 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:14,088] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 38 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:14,088] INFO [Partition __consumer_offsets-24 broker=1] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:04:14,052] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 92 milliseconds for epoch 0, of which 70 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:14,177] INFO Created log for partition __consumer_offsets-21 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-21 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 17:04:14,087] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:14,220] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 23 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:14,211] INFO [Partition __consumer_offsets-21 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2022-05-12 17:04:14,234] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:04:14,120] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:14,165] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:14,241] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 49 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:14,221] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-17 in 3 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:13,904] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-20 in 29 milliseconds for epoch 0, of which 28 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:14,233] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:14,326] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 29 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:14,300] INFO [LogLoader partition=__consumer_offsets-18, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:04:14,287] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:14,331] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-26 in 344 milliseconds for epoch 0, of which 341 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:14,295] INFO [LogLoader partition=__consumer_offsets-34, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:04:14,328] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:14,347] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-32 in 260 milliseconds for epoch 0, of which 255 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:14,245] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 2 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:14,336] INFO Created log for partition __consumer_offsets-18 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\__consumer_offsets-18 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 17:04:14,381] INFO [LogLoader partition=__consumer_offsets-15, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:04:14,400] INFO Created log for partition __consumer_offsets-34 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\__consumer_offsets-34 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 17:04:14,335] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 1 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:14,329] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-23 in 4 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:14,405] INFO Created log for partition __consumer_offsets-15 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-15 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 17:04:14,386] INFO [Partition __consumer_offsets-18 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2022-05-12 17:04:14,394] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-38 in 143 milliseconds for epoch 0, of which 126 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:14,414] INFO [Partition __consumer_offsets-34 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2022-05-12 17:04:14,368] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 35 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:14,390] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 57 milliseconds for epoch 0, of which 56 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:14,447] INFO [Partition __consumer_offsets-18 broker=1] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:04:14,448] INFO [Partition __consumer_offsets-15 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2022-05-12 17:04:14,466] INFO [Partition __consumer_offsets-34 broker=5] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:04:14,423] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:14,432] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-29 in 64 milliseconds for epoch 0, of which 62 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:14,508] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:04:14,479] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:14,550] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 7 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:14,601] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-35 in 2 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:14,626] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:14,647] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 13 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:14,652] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:14,553] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 3 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:14,665] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 18 milliseconds for epoch 0, of which 17 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:14,665] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 19 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:14,690] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 30 milliseconds for epoch 0, of which 27 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:14,690] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:14,713] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 2 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:14,750] INFO [LogLoader partition=__consumer_offsets-9, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:04:14,759] INFO [LogLoader partition=__consumer_offsets-12, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:04:14,776] INFO Created log for partition __consumer_offsets-9 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-9 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 17:04:14,780] INFO [GroupCoordinator 3]: Dynamic member with unknown member id joins group 4 in Empty state. Created a new member id consumer-4-5-7d2e8b85-728c-45aa-97c5-70a18db5f8bf and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:14,782] INFO [Partition __consumer_offsets-9 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2022-05-12 17:04:14,790] INFO Created log for partition __consumer_offsets-12 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\__consumer_offsets-12 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 17:04:14,848] INFO [Partition __consumer_offsets-12 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2022-05-12 17:04:14,845] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:04:14,877] INFO [LogLoader partition=__consumer_offsets-28, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:04:14,845] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group 3 in Empty state. Created a new member id consumer-3-4-c664ee07-b3c9-4b3a-9aee-da0dfaa0bf08 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:14,879] INFO [Partition __consumer_offsets-12 broker=1] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:04:14,892] INFO [GroupCoordinator 3]: Preparing to rebalance group 4 in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member consumer-4-5-7d2e8b85-728c-45aa-97c5-70a18db5f8bf with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:14,923] INFO Created log for partition __consumer_offsets-28 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\__consumer_offsets-28 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 17:04:14,871] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group 1 in Empty state. Created a new member id consumer-1-1-7c21748c-fe03-4ffd-a798-3c540b848e8e and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:14,925] INFO [Partition __consumer_offsets-28 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2022-05-12 17:04:14,989] INFO [Partition __consumer_offsets-28 broker=5] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:04:15,083] INFO [GroupCoordinator 2]: Preparing to rebalance group 3 in state PreparingRebalance with old generation 0 (__consumer_offsets-1) (reason: Adding new member consumer-3-4-c664ee07-b3c9-4b3a-9aee-da0dfaa0bf08 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:15,090] INFO [LogLoader partition=__consumer_offsets-3, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:04:15,083] INFO [GroupCoordinator 2]: Preparing to rebalance group 1 in state PreparingRebalance with old generation 0 (__consumer_offsets-49) (reason: Adding new member consumer-1-1-7c21748c-fe03-4ffd-a798-3c540b848e8e with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:15,107] INFO Created log for partition __consumer_offsets-3 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs1\__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 17:04:15,112] INFO [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2022-05-12 17:04:15,117] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:04:15,149] INFO [GroupCoordinator 3]: Stabilized group 4 generation 1 (__consumer_offsets-2) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:15,159] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:15,180] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:15,178] INFO [LogLoader partition=__consumer_offsets-6, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:04:15,192] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 9 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:15,199] INFO [GroupCoordinator 2]: Stabilized group 3 generation 1 (__consumer_offsets-1) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:15,199] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:15,206] INFO Created log for partition __consumer_offsets-6 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs2\__consumer_offsets-6 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 17:04:15,206] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 15 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:15,217] INFO [Partition __consumer_offsets-6 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2022-05-12 17:04:15,241] INFO [GroupCoordinator 2]: Stabilized group 1 generation 1 (__consumer_offsets-49) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:15,245] INFO [Partition __consumer_offsets-6 broker=1] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:04:15,238] INFO [LogLoader partition=__consumer_offsets-16, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:04:15,235] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:15,287] INFO [GroupCoordinator 2]: Assignment received from leader consumer-3-4-c664ee07-b3c9-4b3a-9aee-da0dfaa0bf08 for group 3 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:15,279] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 87 milliseconds for epoch 0, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:15,324] INFO Created log for partition __consumer_offsets-16 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\__consumer_offsets-16 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 17:04:15,326] INFO [GroupCoordinator 3]: Assignment received from leader consumer-4-5-7d2e8b85-728c-45aa-97c5-70a18db5f8bf for group 4 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:15,348] INFO [Partition __consumer_offsets-16 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2022-05-12 17:04:15,298] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 21 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:15,288] INFO [GroupCoordinator 2]: Assignment received from leader consumer-1-1-7c21748c-fe03-4ffd-a798-3c540b848e8e for group 1 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:15,313] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 6 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:15,393] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:15,342] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 137 milliseconds for epoch 0, of which 136 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:15,420] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 12 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:15,369] INFO [Partition __consumer_offsets-16 broker=5] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:04:15,370] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:15,428] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:15,423] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 125 milliseconds for epoch 0, of which 123 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:15,451] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 18 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:15,469] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:15,471] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 26 milliseconds for epoch 0, of which 25 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:15,482] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 24 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:15,446] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 27 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:15,497] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:15,486] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:15,512] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 30 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:15,514] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:15,512] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 33 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:15,522] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 12 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:15,523] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:15,521] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 36 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:15,538] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 39 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:15,543] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 125 milliseconds for epoch 0, of which 33 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:15,561] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:15,554] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:15,582] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 45 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:15,590] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 139 milliseconds for epoch 0, of which 138 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:15,592] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:15,592] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 42 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:15,608] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:15,541] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 4 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:15,644] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 61 milliseconds for epoch 0, of which 55 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:15,654] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 52 milliseconds for epoch 0, of which 51 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:15,625] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 48 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:15,680] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:15,684] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 0 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:15,696] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:15,644] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 142 milliseconds for epoch 0, of which 137 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:15,769] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 249 milliseconds for epoch 0, of which 246 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:15,781] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 260 milliseconds for epoch 0, of which 259 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:15,785] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 194 milliseconds for epoch 0, of which 193 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:15,800] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 175 milliseconds for epoch 0, of which 174 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:15,804] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 120 milliseconds for epoch 0, of which 119 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:15,815] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 95 milliseconds for epoch 0, of which 94 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:15,886] INFO [LogLoader partition=__consumer_offsets-22, dir=C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-12 17:04:15,994] INFO Created log for partition __consumer_offsets-22 in C:\Users\joaoc\Documents\kafka\kfk\kafka-logs6\__consumer_offsets-22 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2022-05-12 17:04:16,047] INFO [Partition __consumer_offsets-22 broker=5] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2022-05-12 17:04:16,171] INFO [Partition __consumer_offsets-22 broker=5] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-12 17:04:16,159] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group 5 in Empty state. Created a new member id consumer-5-6-b1391f43-11a5-4d9c-90ae-8e19dc95fdc8 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:16,142] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group 2 in Empty state. Created a new member id consumer-2-3-bfc656ab-02c9-4565-a075-3418e3a3af5d and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:16,144] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group 0 in Empty state. Created a new member id consumer-0-2-d54143b7-b39f-42fb-852b-90a7e5fd98cd and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:16,326] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 22 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:16,342] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:16,359] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 28 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:16,389] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:16,398] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 34 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:16,401] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:16,409] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 40 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:16,414] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:16,420] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 46 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:16,402] INFO [GroupCoordinator 0]: Preparing to rebalance group 5 in state PreparingRebalance with old generation 0 (__consumer_offsets-3) (reason: Adding new member consumer-5-6-b1391f43-11a5-4d9c-90ae-8e19dc95fdc8 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:16,372] INFO [GroupCoordinator 1]: Preparing to rebalance group 2 in state PreparingRebalance with old generation 0 (__consumer_offsets-0) (reason: Adding new member consumer-2-3-bfc656ab-02c9-4565-a075-3418e3a3af5d with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:16,373] INFO [GroupCoordinator 1]: Preparing to rebalance group 0 in state PreparingRebalance with old generation 0 (__consumer_offsets-48) (reason: Adding new member consumer-0-2-d54143b7-b39f-42fb-852b-90a7e5fd98cd with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:16,434] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:16,486] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 4 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:16,469] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-22 in 94 milliseconds for epoch 0, of which 31 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:16,503] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:16,529] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-28 in 132 milliseconds for epoch 0, of which 121 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:16,537] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 10 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:16,547] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:16,558] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 16 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:16,566] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:16,541] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-34 in 132 milliseconds for epoch 0, of which 131 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:16,578] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-40 in 158 milliseconds for epoch 0, of which 156 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:16,642] INFO [GroupCoordinator 1]: Stabilized group 2 generation 1 (__consumer_offsets-0) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:16,597] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-46 in 111 milliseconds for epoch 0, of which 106 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:16,697] INFO [GroupCoordinator 0]: Stabilized group 5 generation 1 (__consumer_offsets-3) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:16,712] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-4 in 175 milliseconds for epoch 0, of which 173 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:16,748] INFO [GroupCoordinator 1]: Stabilized group 0 generation 1 (__consumer_offsets-48) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:16,747] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-10 in 189 milliseconds for epoch 0, of which 187 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:16,756] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-16 in 189 milliseconds for epoch 0, of which 188 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-12 17:04:16,782] INFO [GroupCoordinator 1]: Assignment received from leader consumer-2-3-bfc656ab-02c9-4565-a075-3418e3a3af5d for group 2 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:16,782] INFO [GroupCoordinator 1]: Assignment received from leader consumer-0-2-d54143b7-b39f-42fb-852b-90a7e5fd98cd for group 0 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:04:16,964] INFO [GroupCoordinator 0]: Assignment received from leader consumer-5-6-b1391f43-11a5-4d9c-90ae-8e19dc95fdc8 for group 5 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:09:51,455] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group 5 in Stable state. Created a new member id consumer-5-6-27fb6f46-55b1-475a-91de-b93bfe87f8dd and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:09:51,455] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group 2 in Stable state. Created a new member id consumer-2-3-1f6ac5de-1eb5-413f-bb9d-540273914544 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:09:51,455] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group 1 in Stable state. Created a new member id consumer-1-1-24bbeab1-d06e-4790-a5b0-2e5abfc45103 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:09:51,455] INFO [GroupCoordinator 3]: Dynamic member with unknown member id joins group 4 in Stable state. Created a new member id consumer-4-5-9a66da50-61d8-4fb3-ba55-08127c92c05f and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:09:51,455] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group 0 in Stable state. Created a new member id consumer-0-2-f9d676ba-94eb-4477-a3b4-8eced3bb31c2 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:09:51,460] INFO [GroupCoordinator 0]: Preparing to rebalance group 5 in state PreparingRebalance with old generation 1 (__consumer_offsets-3) (reason: Adding new member consumer-5-6-27fb6f46-55b1-475a-91de-b93bfe87f8dd with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:09:51,455] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group 3 in Stable state. Created a new member id consumer-3-4-5d99fec5-4cce-47f4-bf11-b5edbef0a3be and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:09:51,461] INFO [GroupCoordinator 3]: Preparing to rebalance group 4 in state PreparingRebalance with old generation 1 (__consumer_offsets-2) (reason: Adding new member consumer-4-5-9a66da50-61d8-4fb3-ba55-08127c92c05f with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:09:51,461] INFO [GroupCoordinator 1]: Preparing to rebalance group 2 in state PreparingRebalance with old generation 1 (__consumer_offsets-0) (reason: Adding new member consumer-2-3-1f6ac5de-1eb5-413f-bb9d-540273914544 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:09:51,460] INFO [GroupCoordinator 2]: Preparing to rebalance group 1 in state PreparingRebalance with old generation 1 (__consumer_offsets-49) (reason: Adding new member consumer-1-1-24bbeab1-d06e-4790-a5b0-2e5abfc45103 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:09:51,470] INFO [GroupCoordinator 1]: Preparing to rebalance group 0 in state PreparingRebalance with old generation 1 (__consumer_offsets-48) (reason: Adding new member consumer-0-2-f9d676ba-94eb-4477-a3b4-8eced3bb31c2 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:09:51,471] INFO [GroupCoordinator 2]: Preparing to rebalance group 3 in state PreparingRebalance with old generation 1 (__consumer_offsets-1) (reason: Adding new member consumer-3-4-5d99fec5-4cce-47f4-bf11-b5edbef0a3be with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:09:57,826] INFO [GroupCoordinator 2]: Member consumer-1-1-7c21748c-fe03-4ffd-a798-3c540b848e8e in group 1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:09:57,828] INFO [GroupCoordinator 2]: Stabilized group 1 generation 2 (__consumer_offsets-49) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:09:57,835] INFO [GroupCoordinator 2]: Assignment received from leader consumer-1-1-24bbeab1-d06e-4790-a5b0-2e5abfc45103 for group 1 for generation 2. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:09:57,856] INFO [GroupCoordinator 1]: Member consumer-0-2-d54143b7-b39f-42fb-852b-90a7e5fd98cd in group 0 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:09:57,858] INFO [GroupCoordinator 1]: Stabilized group 0 generation 2 (__consumer_offsets-48) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:09:57,861] INFO [GroupCoordinator 1]: Assignment received from leader consumer-0-2-f9d676ba-94eb-4477-a3b4-8eced3bb31c2 for group 0 for generation 2. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:09:57,870] INFO [GroupCoordinator 2]: Member consumer-3-4-c664ee07-b3c9-4b3a-9aee-da0dfaa0bf08 in group 3 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:09:57,870] INFO [GroupCoordinator 1]: Member consumer-2-3-bfc656ab-02c9-4565-a075-3418e3a3af5d in group 2 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:09:57,872] INFO [GroupCoordinator 2]: Stabilized group 3 generation 2 (__consumer_offsets-1) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:09:57,872] INFO [GroupCoordinator 1]: Stabilized group 2 generation 2 (__consumer_offsets-0) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:09:57,873] INFO [GroupCoordinator 3]: Member consumer-4-5-7d2e8b85-728c-45aa-97c5-70a18db5f8bf in group 4 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:09:57,876] INFO [GroupCoordinator 2]: Assignment received from leader consumer-3-4-5d99fec5-4cce-47f4-bf11-b5edbef0a3be for group 3 for generation 2. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:09:57,876] INFO [GroupCoordinator 3]: Stabilized group 4 generation 2 (__consumer_offsets-2) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:09:57,877] INFO [GroupCoordinator 1]: Assignment received from leader consumer-2-3-1f6ac5de-1eb5-413f-bb9d-540273914544 for group 2 for generation 2. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:09:57,884] INFO [GroupCoordinator 3]: Assignment received from leader consumer-4-5-9a66da50-61d8-4fb3-ba55-08127c92c05f for group 4 for generation 2. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:09:57,909] INFO [GroupCoordinator 0]: Member consumer-5-6-b1391f43-11a5-4d9c-90ae-8e19dc95fdc8 in group 5 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:09:57,915] INFO [GroupCoordinator 0]: Stabilized group 5 generation 2 (__consumer_offsets-3) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:09:57,925] INFO [GroupCoordinator 0]: Assignment received from leader consumer-5-6-27fb6f46-55b1-475a-91de-b93bfe87f8dd for group 5 for generation 2. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:11:09,180] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group ConsumerGroup in Empty state. Created a new member id consumer-ConsumerGroup-4-979a9c10-42b8-4d01-b692-f4e4ec44fb52 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:11:09,181] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group ConsumerGroup in Empty state. Created a new member id consumer-ConsumerGroup-5-790b9cd9-f27a-4ced-928a-9a49b6ff7cba and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:11:09,182] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group ConsumerGroup in Empty state. Created a new member id consumer-ConsumerGroup-6-ab2f6767-6b7d-44f5-982f-796ba2d6ae4b and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:11:09,183] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group ConsumerGroup in Empty state. Created a new member id consumer-ConsumerGroup-2-d76e4a80-7b7b-4a2f-b10d-4406c78893f8 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:11:09,184] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group ConsumerGroup in Empty state. Created a new member id consumer-ConsumerGroup-3-b4aee79d-78f2-40d8-9de3-39d23252c63b and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:11:09,185] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group ConsumerGroup in Empty state. Created a new member id consumer-ConsumerGroup-1-e60106a3-42f2-44b7-a734-1428fbab220b and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:11:09,186] INFO [GroupCoordinator 0]: Preparing to rebalance group ConsumerGroup in state PreparingRebalance with old generation 0 (__consumer_offsets-45) (reason: Adding new member consumer-ConsumerGroup-4-979a9c10-42b8-4d01-b692-f4e4ec44fb52 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:11:09,188] INFO [GroupCoordinator 0]: Stabilized group ConsumerGroup generation 1 (__consumer_offsets-45) with 6 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:11:09,198] INFO [GroupCoordinator 0]: Assignment received from leader consumer-ConsumerGroup-4-979a9c10-42b8-4d01-b692-f4e4ec44fb52 for group ConsumerGroup for generation 1. The group has 6 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:11:34,939] INFO [GroupCoordinator 3]: Member consumer-4-5-9a66da50-61d8-4fb3-ba55-08127c92c05f in group 4 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:11:34,939] INFO [GroupCoordinator 3]: Preparing to rebalance group 4 in state PreparingRebalance with old generation 2 (__consumer_offsets-2) (reason: removing member consumer-4-5-9a66da50-61d8-4fb3-ba55-08127c92c05f on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:11:34,944] INFO [GroupCoordinator 3]: Group 4 with generation 3 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:11:34,970] INFO [GroupCoordinator 0]: Member consumer-5-6-27fb6f46-55b1-475a-91de-b93bfe87f8dd in group 5 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:11:34,971] INFO [GroupCoordinator 0]: Preparing to rebalance group 5 in state PreparingRebalance with old generation 2 (__consumer_offsets-3) (reason: removing member consumer-5-6-27fb6f46-55b1-475a-91de-b93bfe87f8dd on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:11:34,973] INFO [GroupCoordinator 0]: Group 5 with generation 3 is now empty (__consumer_offsets-3) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:11:35,499] INFO [GroupCoordinator 2]: Member consumer-1-1-24bbeab1-d06e-4790-a5b0-2e5abfc45103 in group 1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:11:35,499] INFO [GroupCoordinator 2]: Preparing to rebalance group 1 in state PreparingRebalance with old generation 2 (__consumer_offsets-49) (reason: removing member consumer-1-1-24bbeab1-d06e-4790-a5b0-2e5abfc45103 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:11:35,502] INFO [GroupCoordinator 2]: Group 1 with generation 3 is now empty (__consumer_offsets-49) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:11:35,514] INFO [GroupCoordinator 1]: Member consumer-0-2-f9d676ba-94eb-4477-a3b4-8eced3bb31c2 in group 0 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:11:35,515] INFO [GroupCoordinator 1]: Preparing to rebalance group 0 in state PreparingRebalance with old generation 2 (__consumer_offsets-48) (reason: removing member consumer-0-2-f9d676ba-94eb-4477-a3b4-8eced3bb31c2 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:11:35,517] INFO [GroupCoordinator 1]: Group 0 with generation 3 is now empty (__consumer_offsets-48) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:11:35,530] INFO [GroupCoordinator 2]: Member consumer-3-4-5d99fec5-4cce-47f4-bf11-b5edbef0a3be in group 3 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:11:35,530] INFO [GroupCoordinator 1]: Member consumer-2-3-1f6ac5de-1eb5-413f-bb9d-540273914544 in group 2 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:11:35,531] INFO [GroupCoordinator 2]: Preparing to rebalance group 3 in state PreparingRebalance with old generation 2 (__consumer_offsets-1) (reason: removing member consumer-3-4-5d99fec5-4cce-47f4-bf11-b5edbef0a3be on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:11:35,532] INFO [GroupCoordinator 1]: Preparing to rebalance group 2 in state PreparingRebalance with old generation 2 (__consumer_offsets-0) (reason: removing member consumer-2-3-1f6ac5de-1eb5-413f-bb9d-540273914544 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:11:35,536] INFO [GroupCoordinator 2]: Group 3 with generation 3 is now empty (__consumer_offsets-1) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:11:35,536] INFO [GroupCoordinator 1]: Group 2 with generation 3 is now empty (__consumer_offsets-0) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:12:13,461] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group ConsumerGroup in Stable state. Created a new member id consumer-ConsumerGroup-5-c9d4790a-1598-41b8-a2a3-37aba06f0be5 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:12:13,465] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group ConsumerGroup in Stable state. Created a new member id consumer-ConsumerGroup-2-a3e6356b-0553-41c7-a98d-7c649da3112d and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:12:13,475] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group ConsumerGroup in Stable state. Created a new member id consumer-ConsumerGroup-4-7e8b964b-3b21-4550-99cb-7f8211b5630a and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:12:13,480] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group ConsumerGroup in Stable state. Created a new member id consumer-ConsumerGroup-3-0cb9d994-285c-4060-a143-33e261f74e43 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:12:13,484] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group ConsumerGroup in Stable state. Created a new member id consumer-ConsumerGroup-1-760f283e-ec02-4250-adad-647ce8ad5c15 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:12:13,488] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group ConsumerGroup in Stable state. Created a new member id consumer-ConsumerGroup-6-e26f5309-aeb7-4a44-bc0e-f310be7312a2 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:12:13,503] INFO [GroupCoordinator 0]: Preparing to rebalance group ConsumerGroup in state PreparingRebalance with old generation 1 (__consumer_offsets-45) (reason: Adding new member consumer-ConsumerGroup-5-c9d4790a-1598-41b8-a2a3-37aba06f0be5 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:12:20,190] INFO [GroupCoordinator 0]: Member consumer-ConsumerGroup-6-ab2f6767-6b7d-44f5-982f-796ba2d6ae4b in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:12:20,206] INFO [GroupCoordinator 0]: Member consumer-ConsumerGroup-1-e60106a3-42f2-44b7-a734-1428fbab220b in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:12:20,238] INFO [GroupCoordinator 0]: Member consumer-ConsumerGroup-2-d76e4a80-7b7b-4a2f-b10d-4406c78893f8 in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:12:20,238] INFO [GroupCoordinator 0]: Member consumer-ConsumerGroup-3-b4aee79d-78f2-40d8-9de3-39d23252c63b in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:12:20,239] INFO [GroupCoordinator 0]: Member consumer-ConsumerGroup-5-790b9cd9-f27a-4ced-928a-9a49b6ff7cba in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:12:20,254] INFO [GroupCoordinator 0]: Member consumer-ConsumerGroup-4-979a9c10-42b8-4d01-b692-f4e4ec44fb52 in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:12:20,256] INFO [GroupCoordinator 0]: Stabilized group ConsumerGroup generation 2 (__consumer_offsets-45) with 6 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:12:20,265] INFO [GroupCoordinator 0]: Assignment received from leader consumer-ConsumerGroup-5-c9d4790a-1598-41b8-a2a3-37aba06f0be5 for group ConsumerGroup for generation 2. The group has 6 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:13:14,699] INFO [GroupCoordinator 0]: Member consumer-ConsumerGroup-3-0cb9d994-285c-4060-a143-33e261f74e43 in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:13:14,699] INFO [GroupCoordinator 0]: Preparing to rebalance group ConsumerGroup in state PreparingRebalance with old generation 2 (__consumer_offsets-45) (reason: removing member consumer-ConsumerGroup-3-0cb9d994-285c-4060-a143-33e261f74e43 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:13:14,704] INFO [GroupCoordinator 0]: Member consumer-ConsumerGroup-5-c9d4790a-1598-41b8-a2a3-37aba06f0be5 in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:13:14,708] INFO [GroupCoordinator 0]: Member consumer-ConsumerGroup-2-a3e6356b-0553-41c7-a98d-7c649da3112d in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:13:14,715] INFO [GroupCoordinator 0]: Member consumer-ConsumerGroup-1-760f283e-ec02-4250-adad-647ce8ad5c15 in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:13:14,716] INFO [GroupCoordinator 0]: Member consumer-ConsumerGroup-6-e26f5309-aeb7-4a44-bc0e-f310be7312a2 in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:13:14,718] INFO [GroupCoordinator 0]: Member consumer-ConsumerGroup-4-7e8b964b-3b21-4550-99cb-7f8211b5630a in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:13:14,719] INFO [GroupCoordinator 0]: Group ConsumerGroup with generation 3 is now empty (__consumer_offsets-45) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:15:19,555] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group ConsumerGroup in Empty state. Created a new member id consumer-ConsumerGroup-2-10b4a7b9-685c-4400-92de-83191379358e and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:15:19,558] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group ConsumerGroup in Empty state. Created a new member id consumer-ConsumerGroup-4-056d57eb-5600-402c-b7db-d5346791fde1 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:15:19,566] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group ConsumerGroup in Empty state. Created a new member id consumer-ConsumerGroup-1-aa6c71ec-17da-41ab-b1af-05375104fd78 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:15:19,570] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group ConsumerGroup in Empty state. Created a new member id consumer-ConsumerGroup-6-b3053edd-25bc-41f8-8021-778d76d8cf6c and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:15:19,582] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group ConsumerGroup in Empty state. Created a new member id consumer-ConsumerGroup-5-25cea368-0bb7-4ec1-838d-4bec295b32c5 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:15:19,586] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group ConsumerGroup in Empty state. Created a new member id consumer-ConsumerGroup-3-ac8684b2-220b-4cff-83fa-6600dbc85631 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:15:19,591] INFO [GroupCoordinator 0]: Preparing to rebalance group ConsumerGroup in state PreparingRebalance with old generation 3 (__consumer_offsets-45) (reason: Adding new member consumer-ConsumerGroup-2-10b4a7b9-685c-4400-92de-83191379358e with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:15:19,600] INFO [GroupCoordinator 0]: Stabilized group ConsumerGroup generation 4 (__consumer_offsets-45) with 3 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:15:19,610] INFO [GroupCoordinator 0]: Preparing to rebalance group ConsumerGroup in state PreparingRebalance with old generation 4 (__consumer_offsets-45) (reason: Adding new member consumer-ConsumerGroup-6-b3053edd-25bc-41f8-8021-778d76d8cf6c with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:15:19,676] INFO [GroupCoordinator 0]: Stabilized group ConsumerGroup generation 5 (__consumer_offsets-45) with 6 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:15:19,715] INFO [GroupCoordinator 0]: Assignment received from leader consumer-ConsumerGroup-2-10b4a7b9-685c-4400-92de-83191379358e for group ConsumerGroup for generation 5. The group has 6 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:16:19,421] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group ConsumerGroup in Stable state. Created a new member id consumer-ConsumerGroup-1-4ed30ee7-8016-41b5-b1f6-f52397db01ac and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:16:19,424] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group ConsumerGroup in Stable state. Created a new member id consumer-ConsumerGroup-6-0d57373e-28f2-4965-accc-f425292358e2 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:16:19,438] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group ConsumerGroup in Stable state. Created a new member id consumer-ConsumerGroup-4-c0f34b57-7b76-45ab-bb50-360852ed3056 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:16:19,444] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group ConsumerGroup in Stable state. Created a new member id consumer-ConsumerGroup-5-84bbc325-466f-4666-8b9d-c029678dcf6f and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:16:19,455] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group ConsumerGroup in Stable state. Created a new member id consumer-ConsumerGroup-3-2c282129-35a3-4edf-8ade-84e731a7dcc4 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:16:19,459] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group ConsumerGroup in Stable state. Created a new member id consumer-ConsumerGroup-2-788504dc-56e1-4b3d-b3f5-6c58de95706b and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:16:19,463] INFO [GroupCoordinator 0]: Preparing to rebalance group ConsumerGroup in state PreparingRebalance with old generation 5 (__consumer_offsets-45) (reason: Adding new member consumer-ConsumerGroup-1-4ed30ee7-8016-41b5-b1f6-f52397db01ac with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:16:43,434] INFO [GroupCoordinator 0]: Member consumer-ConsumerGroup-6-b3053edd-25bc-41f8-8021-778d76d8cf6c in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:16:43,465] INFO [GroupCoordinator 0]: Member consumer-ConsumerGroup-1-aa6c71ec-17da-41ab-b1af-05375104fd78 in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:16:43,497] INFO [GroupCoordinator 0]: Member consumer-ConsumerGroup-3-ac8684b2-220b-4cff-83fa-6600dbc85631 in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:16:43,512] INFO [GroupCoordinator 0]: Member consumer-ConsumerGroup-2-10b4a7b9-685c-4400-92de-83191379358e in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:16:43,528] INFO [GroupCoordinator 0]: Member consumer-ConsumerGroup-4-056d57eb-5600-402c-b7db-d5346791fde1 in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:16:43,529] INFO [GroupCoordinator 0]: Member consumer-ConsumerGroup-5-25cea368-0bb7-4ec1-838d-4bec295b32c5 in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:16:43,532] INFO [GroupCoordinator 0]: Stabilized group ConsumerGroup generation 6 (__consumer_offsets-45) with 6 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:16:43,540] INFO [GroupCoordinator 0]: Assignment received from leader consumer-ConsumerGroup-2-788504dc-56e1-4b3d-b3f5-6c58de95706b for group ConsumerGroup for generation 6. The group has 6 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:17:53,380] INFO [GroupCoordinator 0]: Member consumer-ConsumerGroup-6-0d57373e-28f2-4965-accc-f425292358e2 in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:17:53,380] INFO [GroupCoordinator 0]: Preparing to rebalance group ConsumerGroup in state PreparingRebalance with old generation 6 (__consumer_offsets-45) (reason: removing member consumer-ConsumerGroup-6-0d57373e-28f2-4965-accc-f425292358e2 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:17:53,381] INFO [GroupCoordinator 0]: Member consumer-ConsumerGroup-1-4ed30ee7-8016-41b5-b1f6-f52397db01ac in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:17:53,396] INFO [GroupCoordinator 0]: Member consumer-ConsumerGroup-5-84bbc325-466f-4666-8b9d-c029678dcf6f in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:17:53,396] INFO [GroupCoordinator 0]: Member consumer-ConsumerGroup-2-788504dc-56e1-4b3d-b3f5-6c58de95706b in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:17:53,489] INFO [GroupCoordinator 0]: Member consumer-ConsumerGroup-3-2c282129-35a3-4edf-8ade-84e731a7dcc4 in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:17:53,489] INFO [GroupCoordinator 0]: Member consumer-ConsumerGroup-4-c0f34b57-7b76-45ab-bb50-360852ed3056 in group ConsumerGroup has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:17:53,490] INFO [GroupCoordinator 0]: Group ConsumerGroup with generation 7 is now empty (__consumer_offsets-45) (kafka.coordinator.group.GroupCoordinator)
[2022-05-12 17:29:06,633] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:29:06,634] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:29:06,626] WARN Close of session 0x100672354ce0002 (org.apache.zookeeper.server.NIOServerCnxn)
java.io.IOException: An existing connection was forcibly closed by the remote host
	at java.base/sun.nio.ch.SocketDispatcher.read0(Native Method)
	at java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:245)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:324)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:522)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:154)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
[2022-05-12 17:29:06,657] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Cancelled in-flight FETCH request with correlation id 3027 due to node 5 being disconnected (elapsed time since creation: 426ms, elapsed time since send: 426ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:29:06,663] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Cancelled in-flight FETCH request with correlation id 3026 due to node 5 being disconnected (elapsed time since creation: 96ms, elapsed time since send: 96ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:29:06,660] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:29:06,665] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:29:06,680] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Error sending fetch request (sessionId=1374486870, epoch=3026) to node 5: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to 5 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:99)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-12 17:29:06,675] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Error sending fetch request (sessionId=827031822, epoch=3025) to node 5: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to 5 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:99)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-12 17:29:06,707] WARN [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=827031822, epoch=3025), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 5 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:99)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-12 17:29:06,704] WARN [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=1374486870, epoch=3026), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 5 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:99)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-12 17:29:08,447] WARN Close of session 0x100672354ce0004 (org.apache.zookeeper.server.NIOServerCnxn)
java.io.IOException: An existing connection was forcibly closed by the remote host
	at java.base/sun.nio.ch.SocketDispatcher.read0(Native Method)
	at java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:245)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:324)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:522)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:154)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
[2022-05-12 17:29:08,456] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:29:08,455] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:29:08,480] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Cancelled in-flight FETCH request with correlation id 3031 due to node 4 being disconnected (elapsed time since creation: 227ms, elapsed time since send: 227ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:29:08,460] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Cancelled in-flight FETCH request with correlation id 3030 due to node 4 being disconnected (elapsed time since creation: 226ms, elapsed time since send: 226ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:29:08,483] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:29:08,489] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:29:08,493] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Error sending fetch request (sessionId=276292603, epoch=3029) to node 4: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to 4 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:99)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-12 17:29:08,509] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Error sending fetch request (sessionId=1945083625, epoch=3028) to node 4: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to 4 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:99)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-12 17:29:08,521] WARN [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=276292603, epoch=3029), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 4 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:99)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-12 17:29:08,520] WARN [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=1945083625, epoch=3028), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 4 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:99)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-12 17:29:09,759] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:29:09,761] WARN [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Connection to node 5 (LAPTOP-S01N1QNU.mshome.net/172.22.144.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:29:09,775] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:29:09,770] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:29:09,778] WARN [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Connection to node 5 (LAPTOP-S01N1QNU.mshome.net/172.22.144.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:29:09,781] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Error sending fetch request (sessionId=827031822, epoch=INITIAL) to node 5: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to LAPTOP-S01N1QNU.mshome.net:9097 (id: 5 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:104)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-12 17:29:09,824] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:29:09,823] WARN [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={Sensor-5=PartitionData(topicId=uRASlC4lRCGDI0SN1ufO9w, fetchOffset=12, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=827031822, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to LAPTOP-S01N1QNU.mshome.net:9097 (id: 5 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:104)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-12 17:29:09,839] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Error sending fetch request (sessionId=1374486870, epoch=INITIAL) to node 5: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to LAPTOP-S01N1QNU.mshome.net:9097 (id: 5 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:104)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-12 17:29:09,857] WARN [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={Sensor-5=PartitionData(topicId=uRASlC4lRCGDI0SN1ufO9w, fetchOffset=12, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0], lastFetchedEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=1374486870, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to LAPTOP-S01N1QNU.mshome.net:9097 (id: 5 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:104)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-12 17:29:10,012] WARN Close of session 0x100672354ce0005 (org.apache.zookeeper.server.NIOServerCnxn)
java.io.IOException: An existing connection was forcibly closed by the remote host
	at java.base/sun.nio.ch.SocketDispatcher.read0(Native Method)
	at java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:245)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:324)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:522)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:154)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
[2022-05-12 17:29:11,201] WARN Close of session 0x100672354ce0001 (org.apache.zookeeper.server.NIOServerCnxn)
java.io.IOException: An existing connection was forcibly closed by the remote host
	at java.base/sun.nio.ch.SocketDispatcher.read0(Native Method)
	at java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:245)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:324)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:522)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:154)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
[2022-05-12 17:29:11,203] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:29:11,207] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Cancelled in-flight FETCH request with correlation id 3035 due to node 2 being disconnected (elapsed time since creation: 417ms, elapsed time since send: 417ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:29:11,209] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:29:11,210] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=801368318, epoch=3033) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to 2 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:99)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-12 17:29:11,213] WARN [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=0, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=801368318, epoch=3033), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 2 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:99)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-12 17:29:12,338] WARN Close of session 0x100672354ce0000 (org.apache.zookeeper.server.NIOServerCnxn)
java.io.IOException: An existing connection was forcibly closed by the remote host
	at java.base/sun.nio.ch.SocketDispatcher.read0(Native Method)
	at java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:245)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:324)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:522)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:154)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
[2022-05-12 17:29:12,338] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:29:12,340] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Cancelled in-flight FETCH request with correlation id 3036 due to node 1 being disconnected (elapsed time since creation: 382ms, elapsed time since send: 382ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:29:12,341] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-12 17:29:12,349] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=947890046, epoch=3034) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to 1 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:99)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-12 17:29:12,350] WARN [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=0, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, removed=, replaced=, metadata=(sessionId=947890046, epoch=3034), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 1 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:99)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-12 17:29:13,820] WARN Close of session 0x100672354ce0003 (org.apache.zookeeper.server.NIOServerCnxn)
java.io.IOException: An existing connection was forcibly closed by the remote host
	at java.base/sun.nio.ch.SocketDispatcher.read0(Native Method)
	at java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:245)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:324)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:522)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:154)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
